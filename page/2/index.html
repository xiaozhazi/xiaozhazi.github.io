<!doctype html>



  


<html class="theme-next muse use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta property="og:type" content="website">
<meta property="og:title" content="Frances Hu's Blog">
<meta property="og:url" content="http://xiaozhazi.github.io/page/2/index.html">
<meta property="og:site_name" content="Frances Hu's Blog">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Frances Hu's Blog">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: 'Author'
    }
  };
</script>




  <link rel="canonical" href="http://xiaozhazi.github.io/page/2/"/>

  <title> Frances Hu's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Frances Hu's Blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">Born to be wild!</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archiv
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/04/18/Dynamic-Programming/" itemprop="url">
                  Dynamic Programming
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2019-04-18T23:31:19+08:00" content="2019-04-18">
              2019-04-18
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>职业规划原因今年计划自学Go语言，前两个月也断断续续用Golang刷了100道左右的算法题。然而:(最近一个月工作比较忙就搁置了一段，今天看了下<a href="https://github.com/xiaozhazi/leetcode_go" target="_blank" rel="external">https://github.com/xiaozhazi/leetcode_go</a> 距上次commit已经有近一个月的时间了 - _ -#。</p>
<p>所以今天开始强制自己记录下个人解题过程以及go语言踩雷， 也便于随时复盘【其实是为了自我监督防止懒癌：）</p>
<h1 id="LeetCode真题系列"><a href="#LeetCode真题系列" class="headerlink" title="LeetCode真题系列"></a>LeetCode真题系列</h1><h2 id="Minimum-Path-Sum-64"><a href="#Minimum-Path-Sum-64" class="headerlink" title="Minimum Path Sum(64)"></a>Minimum Path Sum(64)</h2><p><a href="https://leetcode.com/problems/minimum-path-sum/" target="_blank" rel="external">64 Minumum Path Sum</a></p>
<h3 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h3><p>Given a m x n grid filled with non-negative numbers, find a path from top left to bottom right which minimizes the sum of all numbers along its path.</p>
<pre><code>Note: You can only move either down or right at any point in time.
</code></pre><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><pre><code>Input:
[
  [1,3,1],
  [1,5,1],
  [4,2,1]
]
Output: 7
Explanation: Because the path 1→3→1→1→1 minimizes the sum. 
</code></pre><h3 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h3><p>从（0，0）走到（m-1，n-1）每个阶段只能选择向右或向下两种决策，且每个阶段都会对应一个状态集合。我们把状态定义为dp[i][j]表示从起点走到（i，j）位置时的最短路径长度。 因此它是一个多阶段最优解问题符合动态规划模型。</p>
<p><code>dp[i][j] = min(dp[i-1][j],dp[i][j-1]) + grid[i][j]</code><br>直接动手上代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">func minPathSum(grid [][]int) int &#123;</div><div class="line">  if grid == nil || len(grid) == 0 &#123;</div><div class="line">	return 0</div><div class="line">  &#125;</div><div class="line">  m, n := len(grid), len(grid[0])</div><div class="line">  dp := make([][]int, m)</div><div class="line">	</div><div class="line">  for i := 0; i &lt; m; i++ &#123;</div><div class="line">	dp[i] = make([]int, n)</div><div class="line">  &#125;</div><div class="line">	</div><div class="line">  dp[0][0] = grid[0][0]</div><div class="line">  for i := 1; i &lt; m; i++ &#123;</div><div class="line">	dp[i][0] = dp[i-1][0] + grid[i][0]</div><div class="line">  &#125;</div><div class="line">  for i := 1; i &lt; n; i++ &#123;</div><div class="line">	dp[0][i] = dp[0][i-1] + grid[0][i]</div><div class="line">  &#125;</div><div class="line">  for i := 1; i &lt; m; i++ &#123;</div><div class="line">	for j := 1; j &lt; n; j++ &#123;</div><div class="line">	  dp[i][j] = min(dp[i-1][j], dp[i][j-1]) + grid[i][j]</div><div class="line">	&#125;</div><div class="line">  &#125;</div><div class="line">  return dp[m-1][n-1]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>提交后发现 <em>Runtime: 12 ms, faster than 28.57% of Go online submissions.<br>Memory Usage: 4.4 MB, less than 13.64% of Go online submissions for Minimum Path Sum</em>. 效率太低了，想办法来优化下。</p>
<p>实际上我们只需要一个长度为n-1的一维数组来存储状态集合，状态转移的过程都可以基于这个一维数组来操作。继续上代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">func minPathSum(grid [][]int) int &#123;</div><div class="line">  if grid == nil || len(grid) == 0 &#123;</div><div class="line">    return 0</div><div class="line">  &#125;</div><div class="line">  m, n := len(grid), len(grid[0])</div><div class="line">  dp := make([]int, n)</div><div class="line">   </div><div class="line">  for j, _ := range dp &#123;</div><div class="line">    dp[j] = math.MaxInt32</div><div class="line">  &#125;</div><div class="line">  dp[0] = 0</div><div class="line">  for i := 0; i &lt; m; i++ &#123;</div><div class="line">    for j := 0; j &lt; n; j++ &#123;</div><div class="line">      if j == 0 &#123;</div><div class="line">        dp[j] += grid[i][j]</div><div class="line">      &#125; else &#123;</div><div class="line">        dp[j] = min(dp[j], dp[j-1]) + grid[i][j]</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  return dp[n-1]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>再次提交后 <em>Runtime: 8 ms, faster than 100.00% of Go online submissions for Minimum Path Sum.<br>Memory Usage: 3.9 MB, less than 59.09% of Go online submissions for Minimum Path Sum.</em>  : )</p>
<h2 id="Unique-Paths-II-63"><a href="#Unique-Paths-II-63" class="headerlink" title="Unique Paths II(63)"></a>Unique Paths II(63)</h2><p><a href="https://leetcode.com/problems/unique-paths-ii/" target="_blank" rel="external">63 Unique Paths II</a></p>
<h3 id="Question-1"><a href="#Question-1" class="headerlink" title="Question"></a>Question</h3><p>A robot is located at the top-left corner of a m x n grid (marked ‘Start’ in the diagram below).</p>
<p>The robot can only move either down or right at any point in time. The robot is trying to reach the bottom-right corner of the grid (marked ‘Finish’ in the diagram below).</p>
<p>Now consider if some obstacles are added to the grids. How many unique paths would there be?</p>
<h3 id="Example-1"><a href="#Example-1" class="headerlink" title="Example"></a>Example</h3><pre><code>Input:
[
  [0,0,0],
  [0,1,0],
  [0,0,0]
]
Output: 2
Explanation:
There is one obstacle in the middle of the 3x3 grid above.
There are two ways to reach the bottom-right corner:
1. Right -&gt; Right -&gt; Down -&gt; Down
2. Down -&gt; Down -&gt; Right -&gt; Right
</code></pre><h3 id="Analysis-1"><a href="#Analysis-1" class="headerlink" title="Analysis"></a>Analysis</h3><p>第一感觉是可以用回溯来解决此问题。对每一个点先选择向右走，如果遇到障碍物或者右边无路说明此路径不通，回退到该点选择向下走，如果遇到障碍物或下边无路可走说明不存在任何一条路径可以经过该点走到终点。依次类推，每次递归向后走到终点时count加一。</p>
<p><strong>需要特别注意的是要开始OR结束点值为1的情况</strong></p>
<p>核心代码如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">func DFS(obstacleGrid [][]int, i, j int) &#123;</div><div class="line">    m, n := len(obstacleGrid), len(obstacleGrid[0])</div><div class="line">    if i == m - 1 &amp;&amp; j == n - 1  &amp;&amp; obstacleGrid[i][j] != 1&#123;</div><div class="line">        count++</div><div class="line">        return </div><div class="line">    &#125;</div><div class="line">    if i &lt; m - 1 &amp;&amp; obstacleGrid[i+1][j] == 0 &#123;</div><div class="line">        DFS(obstacleGrid, i + 1, j)</div><div class="line">    &#125;</div><div class="line">    if j &lt; n - 1 &amp;&amp; obstacleGrid[i][j+1] == 0 &#123;</div><div class="line">        DFS(obstacleGrid, i, j + 1)</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>递推算法基本类似于暴力求解，无重复又没有遗漏的穷举出所有走法。果不其然代码提交后TLE : (</p>
<p>继续分析这道题，对于图中任一个非障碍点(i,j)，从起始位置走到该点的路径个数可以通过走到该点的左边位置（i-1,j)和上方位置(i,j-1)的路径个数之和计算， 即</p>
<p><code>dp[i][j] = dp[i-1][j] + dp[i][j-1]</code> <em>if obstacleGrid[i][j] == 0</em></p>
<p>因此可以改用DP算法来解决，同样为了优化算法效率我们通过一个一维数组在存储状态集合，此时状态方程为<br><code>dp[i] += dp[i-1]</code> <em>if obstacleGrid[i][j] == 0</em></p>
<p>具体代码如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">func uniquePathsWithObstacles(obstacleGrid [][]int) int &#123;</div><div class="line">    if obstacleGrid == nil || len(obstacleGrid) == 0 &#123;</div><div class="line">        return 0</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    m, n, count := len(obstacleGrid), len(obstacleGrid[0]), 0</div><div class="line">    if (obstacleGrid[0][0] == 1 || obstacleGrid[m-1][n-1] == 1) &#123;</div><div class="line">        return count</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    dp := make([]int, n)</div><div class="line">    dp[0] = 1</div><div class="line">    for i := 0; i &lt; m; i++ &#123;</div><div class="line">        for j := 0; j &lt; n; j++ &#123;</div><div class="line">            if obstacleGrid[i][j] == 1 &#123;</div><div class="line">                dp[j] = 0 </div><div class="line">            &#125; else &#123;</div><div class="line">                if j != 0 &#123;</div><div class="line">                    dp[j] += dp[j-1]</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            </div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    return dp[n-1]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><em>Runtime: 0 ms, faster than 100.00% of Go online submissions for Unique Paths II.<br>Memory Usage: 2.6 MB, less than 66.67% of Go online submissions for Unique Paths II.</em></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/04/17/重归博客/" itemprop="url">
                  重归博客
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2019-04-17T23:38:48+08:00" content="2019-04-17">
              2019-04-17
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Hello-My-Personal-Blog"><a href="#Hello-My-Personal-Blog" class="headerlink" title="Hello, My Personal Blog"></a>Hello, My Personal Blog</h2><p>After nearly two years of work, i want to share what i have learned in my work and life.</p>
<p>Blogs can also help me to improve my ability to make things clearer and record my growth.</p>
<p>Let’s start!!!</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/12/31/AI入门之——Andrew-Ng-“Machine-Learning”课程学习笔记第十一周/" itemprop="url">
                  AI入门之——Andrew Ng “Machine Learning”课程学习笔记第十一周
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-12-31T15:54:03+08:00" content="2016-12-31">
              2016-12-31
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="11、Application-Example-Photo-OCR"><a href="#11、Application-Example-Photo-OCR" class="headerlink" title="11、Application Example: Photo OCR"></a>11、Application Example: Photo OCR</h1><h2 id="11-1、Photo-OCR"><a href="#11-1、Photo-OCR" class="headerlink" title="11.1、Photo OCR"></a>11.1、Photo OCR</h2><h3 id="11-1-1、problem-description-and-pipeline"><a href="#11-1-1、problem-description-and-pipeline" class="headerlink" title="11.1.1、problem description and pipeline"></a>11.1.1、problem description and pipeline</h3><p>photo OCR pipeline </p>
<ol>
<li>Text detection</li>
<li>Character segmentation</li>
<li>Character classification</li>
</ol>
<h3 id="11-1-2、sliding-window"><a href="#11-1-2、sliding-window" class="headerlink" title="11.1.2、sliding window"></a>11.1.2、sliding window</h3><p>对整个图片进行分别窗口化检测</p>
<h3 id="11-1-3、Getting-lots-of-data-Artificial-data-synthesis"><a href="#11-1-3、Getting-lots-of-data-Artificial-data-synthesis" class="headerlink" title="11.1.3、Getting lots of data: Artificial data synthesis"></a>11.1.3、Getting lots of data: Artificial data synthesis</h3><p>Synthesizing data by introducing distortions</p>
<ol>
<li>Distortion introduced should be representation of the type of noise/distortions in the test set.</li>
<li>Usually does not help to add purely random/meaningless noise to your data. </li>
</ol>
<h3 id="11-1-4、What-part-of-the-pipeline-to-work-on-next"><a href="#11-1-4、What-part-of-the-pipeline-to-work-on-next" class="headerlink" title="11.1.4、What part of the pipeline to work on next"></a>11.1.4、What part of the pipeline to work on next</h3><p>进行分块处理的目的是，我们可以很容易的分析出那一步骤是系统性能瓶颈，需要在那一步骤上投入更多的精力。</p>
<p><img src="http://ofacak8l3.bkt.clouddn.com/11_1.png" alt="11_1"></p>
<p><img src="http://ofacak8l3.bkt.clouddn.com/11_2.png" alt="11_2"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/12/23/AI入门之——Andrew-Ng-“Machine-Learning”课程学习笔记第十周/" itemprop="url">
                  AI入门之——Andrew Ng “Machine Learning”课程学习笔记第十周
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-12-23T15:53:56+08:00" content="2016-12-23">
              2016-12-23
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="10、Large-Scale-Machine-Learning"><a href="#10、Large-Scale-Machine-Learning" class="headerlink" title="10、Large Scale Machine Learning"></a>10、Large Scale Machine Learning</h1><h2 id="10-1、Gradient-Descent-with-Large-Datasets"><a href="#10-1、Gradient-Descent-with-Large-Datasets" class="headerlink" title="10.1、Gradient Descent with Large Datasets"></a>10.1、Gradient Descent with Large Datasets</h2><h3 id="10-1-1、Learning-with-large-dataset"><a href="#10-1-1、Learning-with-large-dataset" class="headerlink" title="10.1.1、Learning with large dataset"></a>10.1.1、Learning with large dataset</h3><p>It’s not who has the best algorithm that wins.<br>It’s who has the most data.</p>
<h3 id="10-1-2、Stochastic-gradient-descent"><a href="#10-1-2、Stochastic-gradient-descent" class="headerlink" title="10.1.2、Stochastic gradient descent"></a>10.1.2、Stochastic gradient descent</h3><p>不像Batch gradient descent每次迭代时都需要将数据集代入计算。</p>
<p>当数据集大的时候我们需要随机shuffle数据集，<br>然后选取第一个数据进行计算，然后进行梯度下降，再接着使用接下来的数据依次进行此过程。</p>
<h3 id="10-1-3、Mini-batch-gradient-descent"><a href="#10-1-3、Mini-batch-gradient-descent" class="headerlink" title="10.1.3、Mini-batch gradient descent"></a>10.1.3、Mini-batch gradient descent</h3><p>batch 和  stochastic的结合。每次选一组数据进行计算，然后再接着使用下一组重复此过程。</p>
<h3 id="10-1-4、Stochastic-gradient-descent-convergence"><a href="#10-1-4、Stochastic-gradient-descent-convergence" class="headerlink" title="10.1.4、Stochastic gradient descent convergence"></a>10.1.4、Stochastic gradient descent convergence</h3><p><img src="http://ofacak8l3.bkt.clouddn.com/10_1.png" alt="10_1"></p>
<p>Learning rate α is tapically held constant. Can slowly descrease α over time if we want θ to converge.</p>
<h2 id="10-2、Online-Learning"><a href="#10-2、Online-Learning" class="headerlink" title="10.2、Online Learning"></a>10.2、Online Learning</h2><p>上述方法可以应用在实时在线学习上，数据集大小不固定，以数据流的形式出现。</p>
<h2 id="10-3、Map-reduce-and-data-parallelism"><a href="#10-3、Map-reduce-and-data-parallelism" class="headerlink" title="10.3、Map-reduce and data parallelism"></a>10.3、Map-reduce and data parallelism</h2><p>在进行梯度下降计算时，中间有步骤需要求和，我们可以利用Map-reduce和并行计算来缩短处理时间。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/12/16/AI入门之——Andrew-Ng-“Machine-Learning”课程学习笔记第九周/" itemprop="url">
                  AI入门之——Andrew Ng “Machine Learning”课程学习笔记第九周
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-12-16T10:56:39+08:00" content="2016-12-16">
              2016-12-16
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="9、Anomaly-detection"><a href="#9、Anomaly-detection" class="headerlink" title="9、Anomaly detection"></a>9、Anomaly detection</h1><h2 id="9-1、Density-Estimation"><a href="#9-1、Density-Estimation" class="headerlink" title="9.1、Density Estimation"></a>9.1、Density Estimation</h2><h3 id="9-1-1、Problem-motivation"><a href="#9-1-1、Problem-motivation" class="headerlink" title="9.1.1、Problem motivation"></a>9.1.1、Problem motivation</h3><p>密度估计，判断一个test实例是否为不正常的。</p>
<p>Anomaly detection example：</p>
<ol>
<li><p>Fraud detection</p>
<pre><code>xi = features of user i&apos;s ativities.
Model p(x) from data.
Identify unusual users by checking which have p(x)&lt;ε
</code></pre></li>
<li><p>Manufacturing</p>
</li>
<li><p>Monitoring computers in a data center.</p>
<pre><code>xi = features of machine i.
memory use,number of disk access/sec,cpu load...
</code></pre></li>
</ol>
<h3 id="9-1-2、Gaussian-distribution"><a href="#9-1-2、Gaussian-distribution" class="headerlink" title="9.1.2、Gaussian distribution"></a>9.1.2、Gaussian distribution</h3><p><img src="http://ofacak8l3.bkt.clouddn.com/9_1.png" alt="9_1"></p>
<h3 id="9-1-3、Anomaly-detection-algorithm"><a href="#9-1-3、Anomaly-detection-algorithm" class="headerlink" title="9.1.3、Anomaly detection algorithm"></a>9.1.3、Anomaly detection algorithm</h3><ol>
<li>Choose features xi that might be indicative of anomalous examples.</li>
<li><p>Fit parameters μ1, … μn,σ12,…σn2</p>
<pre><code>μj = 1/m ξxji
σj2 = 1/m ξ(xji-μj)2
</code></pre></li>
<li>Given new example x, compute p(x),Anomaly if p(x)&lt;ε.</li>
</ol>
<p><img src="http://ofacak8l3.bkt.clouddn.com/9_2.png" alt="9_2"></p>
<h3 id="9-1-4、Developing-and-evaluating-an-anomaly-detection-system"><a href="#9-1-4、Developing-and-evaluating-an-anomaly-detection-system" class="headerlink" title="9.1.4、Developing and evaluating an anomaly detection system"></a>9.1.4、Developing and evaluating an anomaly detection system</h3><ol>
<li>The importance of real-number evaluation</li>
</ol>
<p>例如 10000 good engines， 20 flawed engines，我们可以进行如下划分：</p>
<pre><code>Training set：6000 good engines
CV:2000 good engines,10 anomalous
Test:2000 good engines,10 anomalous
</code></pre><ol>
<li>Algorithm evaluation  </li>
</ol>
<p>可以利用F1-score来评估算法，我们也可以用CV来选择参数ε。</p>
<h3 id="9-1-5、Anomaly-detection-VS-supervised-learning"><a href="#9-1-5、Anomaly-detection-VS-supervised-learning" class="headerlink" title="9.1.5、Anomaly detection VS supervised learning"></a>9.1.5、Anomaly detection VS supervised learning</h3><p>Anomaly detection:</p>
<ol>
<li>Very small number of positive example.</li>
<li>Large number of negative example.</li>
<li>Many different types od anomalies. 很难通过positive实例来学习异常的特征</li>
<li>未来和异常和目前的异常实例不相关</li>
</ol>
<p>Supervised Learning：</p>
<ol>
<li>Large number of positive and negative examples.</li>
<li>可以根据大量的positive值推断出其特征值，未来的positive和现在的训练集非常相似</li>
</ol>
<h3 id="9-1-6、多元高斯分布"><a href="#9-1-6、多元高斯分布" class="headerlink" title="9.1.6、多元高斯分布"></a>9.1.6、多元高斯分布</h3><p>通过μ矩阵和ξ矩阵来对多远高斯分布进行调整。</p>
<p><img src="http://ofacak8l3.bkt.clouddn.com/9_3.png" alt="9_3"></p>
<h2 id="9-2-推荐系统"><a href="#9-2-推荐系统" class="headerlink" title="9.2 推荐系统"></a>9.2 推荐系统</h2><h3 id="9-3-1-基于内容的推荐"><a href="#9-3-1-基于内容的推荐" class="headerlink" title="9.3.1 基于内容的推荐"></a>9.3.1 基于内容的推荐</h3><p>问题描述：</p>
<ol>
<li>r(i,j)=1 if user j has rated movie i</li>
<li>y(i,j)=rating by user j on movie i</li>
<li>θ(j)=paramater vector for user j</li>
<li>x(i)=feature vector for movie i</li>
<li>For user j,movie i, predicted rating θ(j)T(x(i))</li>
<li>m(j)=no. of movies rated by user j</li>
</ol>
<p><img src="http://ofacak8l3.bkt.clouddn.com/9_4.png" alt="9_4"></p>
<p><img src="http://ofacak8l3.bkt.clouddn.com/9_5.png" alt="9_5"></p>
<h3 id="9-3-2-正交过滤"><a href="#9-3-2-正交过滤" class="headerlink" title="9.3.2 正交过滤"></a>9.3.2 正交过滤</h3><p><img src="http://ofacak8l3.bkt.clouddn.com/9_6.png" alt="9_6"></p>
<p><img src="http://ofacak8l3.bkt.clouddn.com/9_7.png" alt="9_7"></p>
<h3 id="9-3-2-实现技巧"><a href="#9-3-2-实现技巧" class="headerlink" title="9.3.2 实现技巧"></a>9.3.2 实现技巧</h3><p>归一化，计算平均值，然后同时减去该值</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/12/08/AI入门之——Andrew-Ng-“Machine-Learning”课程学习笔记第八周/" itemprop="url">
                  AI入门之——Andrew Ng “Machine Learning”课程学习笔记第八周
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-12-08T19:59:23+08:00" content="2016-12-08">
              2016-12-08
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="8、Unsupervised-Learning"><a href="#8、Unsupervised-Learning" class="headerlink" title="8、Unsupervised Learning"></a>8、Unsupervised Learning</h1><h2 id="8-1-Clustering"><a href="#8-1-Clustering" class="headerlink" title="8.1 Clustering"></a>8.1 Clustering</h2><h3 id="8-1-1-Unsupervised-Learning-Introduction"><a href="#8-1-1-Unsupervised-Learning-Introduction" class="headerlink" title="8.1.1 Unsupervised Learning: Introduction"></a>8.1.1 Unsupervised Learning: Introduction</h3><p>Applications of clustering:</p>
<ol>
<li>Market segementation</li>
<li>Social network analysis</li>
<li>Organize computing clusters</li>
<li>Astronomical data analysis</li>
</ol>
<p>无监督学习，数据是没有label的。</p>
<h3 id="8-1-2-K-Means-Algorithm"><a href="#8-1-2-K-Means-Algorithm" class="headerlink" title="8.1.2 K-Means Algorithm"></a>8.1.2 K-Means Algorithm</h3><p>Input:</p>
<pre><code>K (number of clusters)
Training set {x1,x2,...xm}
</code></pre><p>算法：</p>
<p>随机初始化K个聚类簇（cluster centroids）u1,u2…uK</p>
<p>然后repeat操作：</p>
<ol>
<li><p>cluster assignment step：</p>
<pre><code>for     i = 1 to m
  c(i):=index(from 1 to K) of cluster centroids closest to xi
</code></pre></li>
<li><p>Move centroid:</p>
<pre><code>for k = 1 to K
  uk := average(mean)of points assigned to cluster k
</code></pre></li>
</ol>
<h3 id="8-1-3-Optimization-objective"><a href="#8-1-3-Optimization-objective" class="headerlink" title="8.1.3 Optimization objective"></a>8.1.3 Optimization objective</h3><p>最小化distortion：<br><img src="http://ofacak8l3.bkt.clouddn.com/8_1.png" alt="8_1"></p>
<p>因此K-means算法也可以表示为：</p>
<ol>
<li>Randomly initialize K cluster centroids u1,u2,…uk</li>
<li><p>Repeat:</p>
<pre><code>for i = 1 to m
    c(i):= index(from 1 to K) of cluster centroid closest to xi
</code></pre></li>
</ol>
<pre><code>for k = 1 to K
    uk:= average(mean) of points assigned to cluster k [minize J]
</code></pre><h3 id="8-1-4-Random-initialization"><a href="#8-1-4-Random-initialization" class="headerlink" title="8.1.4 Random initialization"></a>8.1.4 Random initialization</h3><p>Random initialize:</p>
<p>首先满足 K &lt; m；</p>
<p>然后随机选择K个训练实例；</p>
<p>将u1,u2,…uk等于这K个实例；</p>
<pre><code>for i = 1 to 100{
    Randomly initialize K-means.
    Run K-means. Get c1,c2,...cm,u1,...uk.
    Compute cost function(distortion)
</code></pre><p>选择最小cost的聚类</p>
<h3 id="8-1-5-Choosing-the-number-of-clusters"><a href="#8-1-5-Choosing-the-number-of-clusters" class="headerlink" title="8.1.5 Choosing the number of clusters"></a>8.1.5 Choosing the number of clusters</h3><p>目前最好的方法还是手动选择；</p>
<p>Elbow cost：手肘方法，不是所有情况都能画出这样的图形，有时候会下降趋势较平滑。</p>
<p>sometimes, you’re running K-means to get clusters to use for some later/downstream purpose.</p>
<p>Evaluate K-means based on a metric for how well it performs for that later purpose.    </p>
<h2 id="8-2-Dimensionality-Reduction"><a href="#8-2-Dimensionality-Reduction" class="headerlink" title="8.2 Dimensionality Reduction"></a>8.2 Dimensionality Reduction</h2><p>介绍了第二种无监督学习算法：维数约减。</p>
<p>主要分为两大类应用：</p>
<ol>
<li>Data Compression</li>
<li>Data Visualization</li>
</ol>
<h3 id="8-2-1-Data-Compression"><a href="#8-2-1-Data-Compression" class="headerlink" title="8.2.1 Data Compression"></a>8.2.1 Data Compression</h3><p>将数据从2D 降维到 1D</p>
<p>将数据从3D 降维到 2D （将三维中的点投影到一个平面上）</p>
<h3 id="8-2-2-Data-Visualization"><a href="#8-2-2-Data-Visualization" class="headerlink" title="8.2.2 Data Visualization"></a>8.2.2 Data Visualization</h3><p>数据可视化，便于用户更好的观察数据，理解数据之间的含义。</p>
<p>将数据比较相关的进行降维，原来N维的数据降低到K维</p>
<p>k &lt;= N； 并且通常K=2或3， 便于进行可视化视图分析 </p>
<h2 id="8-3-Principal-Component-Analysis"><a href="#8-3-Principal-Component-Analysis" class="headerlink" title="8.3 Principal Component Analysis"></a>8.3 Principal Component Analysis</h2><h3 id="8-3-1-Principal-Component-Analysis-Problem-Formulation"><a href="#8-3-1-Principal-Component-Analysis-Problem-Formulation" class="headerlink" title="8.3.1 Principal Component Analysis Problem Formulation"></a>8.3.1 Principal Component Analysis Problem Formulation</h3><p>Reduce from 2-dimension to 1-dimension:</p>
<p>Find a direction (a vector v1) onto which to project the data so as to minimize the projection error.</p>
<p>Reduce from n-dimension to k-dimension:</p>
<p>Find k vectors v1,v2…vk on to which to project the data, so as to minimize the projection error.</p>
<p>PCA 不是线性回归：线性回归是竖着映射，PCA是垂直映射。</p>
<p><img src="http://ofacak8l3.bkt.clouddn.com/8_2.png" alt="8_2"></p>
<h3 id="8-3-2-Principal-Component-Analysis-algorithm"><a href="#8-3-2-Principal-Component-Analysis-algorithm" class="headerlink" title="8.3.2 Principal Component Analysis algorithm"></a>8.3.2 Principal Component Analysis algorithm</h3><p><strong>Data Preprocessing:</strong></p>
<p>Training set: x1,x2,…xm</p>
<p>Preprocessing(feature scaling/mean normalization):</p>
<pre><code>uj = 1/m(x1+x2+...+xm)
xj&apos; = xj - uj
</code></pre><p>If different features on different scales, scale features to have comparable range of values.</p>
<p><strong>Principal Component Analysis (PCA) algorithm</strong></p>
<p>Reduce data from n-dimensions to k-dimensions</p>
<p>compute “covariance matrix”: sigma = 1/m(x1<em>x1T+…+xn</em>xnT)</p>
<p>compute “eigenvectors” of matrix sigma: [U,S,V] = svd(sigma)</p>
<p>Ureduce = U(:,1:k)</p>
<p>z = Ureduce’ * x</p>
<h3 id="8-4-Applying-PCA"><a href="#8-4-Applying-PCA" class="headerlink" title="8.4 Applying PCA"></a>8.4 Applying PCA</h3><h4 id="8-4-1-Reconstruction-from-Compressed-Representation"><a href="#8-4-1-Reconstruction-from-Compressed-Representation" class="headerlink" title="8.4.1 Reconstruction from Compressed Representation"></a>8.4.1 Reconstruction from Compressed Representation</h4><p>Xapprox = Ureduce*z</p>
<h4 id="8-4-2-Choosing-the-number-of-principal-components"><a href="#8-4-2-Choosing-the-number-of-principal-components" class="headerlink" title="8.4.2 Choosing the number of principal components"></a>8.4.2 Choosing the number of principal components</h4><p><strong>choosing k    </strong></p>
<p>(1)Average squared projection error: 1/m(||x1-xapprox1||2 +…)</p>
<p>(2)Total variation in the data : 1/m(||x1||2 + … +||xm||2)</p>
<p>Typically, choose k to be smallest value so that (1)/(2)&lt;=0.01</p>
<p>“99% of variance is retained”    </p>
<p><strong>Advice for applying PCA</strong></p>
<p>Supervised learning speedup</p>
<p>Compression:</p>
<ol>
<li>Reduce memory/disk needed to store data</li>
<li>speed up learning algorithm</li>
</ol>
<p>Visualization</p>
<p><strong>Bad use of PCA: To prevent overfitting</strong></p>
<p>fewer features, less likely to overfit.</p>
<p>This might work ok, but isn’t good way to address overfitting. Use regularization instead.</p>
<p>Before implementing PCA, first try running whatever you want to do with the original/raw data xi. Only if that doesn’t do what you want, then implement PCA and consider using zi.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/12/04/AI入门之——Andrew-Ng-“Machine-Learning”课程学习笔记第七周/" itemprop="url">
                  AI入门之——Andrew Ng “Machine Learning”课程学习笔记第七周
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-12-04T16:41:16+08:00" content="2016-12-04">
              2016-12-04
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="7、Support-Vector-Machines"><a href="#7、Support-Vector-Machines" class="headerlink" title="7、Support Vector Machines"></a>7、Support Vector Machines</h2><h3 id="7-1-Optimization-objective"><a href="#7-1-Optimization-objective" class="headerlink" title="7.1 Optimization objective"></a>7.1 Optimization objective</h3><p><img src="http://ofacak8l3.bkt.clouddn.com/7_1.png" alt="7_1"><br><img src="http://ofacak8l3.bkt.clouddn.com/7_2.png" alt="7_2"></p>
<h3 id="7-2-Large-Margin-Intuition"><a href="#7-2-Large-Margin-Intuition" class="headerlink" title="7.2 Large Margin Intuition"></a>7.2 Large Margin Intuition</h3><p><img src="http://ofacak8l3.bkt.clouddn.com/7_3.png" alt="7_3"></p>
<p>C如果越大，两个分类的间距越小。</p>
<h3 id="7-3-The-Mathematics-behind-large-margin-classification"><a href="#7-3-The-Mathematics-behind-large-margin-classification" class="headerlink" title="7.3 The Mathematics behind large margin classification"></a>7.3 The Mathematics behind large margin classification</h3><p>先讲解了||u||符号的含义,可以利用向量的长度来计算矩阵的乘积.</p>
<p><img src="http://ofacak8l3.bkt.clouddn.com/7_4.png" alt="7_4"><br>SVM Decision Boundary 计算时可以利用这个特性。</p>
<p><img src="http://ofacak8l3.bkt.clouddn.com/7_5.png" alt="7_5"></p>
<h3 id="7-4-Kernels"><a href="#7-4-Kernels" class="headerlink" title="7.4 Kernels"></a>7.4 Kernels</h3><h4 id="7-4-1-Kernels-I"><a href="#7-4-1-Kernels-I" class="headerlink" title="7.4.1 Kernels I"></a>7.4.1 Kernels I</h4><p>Gaussian Kernel.</p>
<p><img src="http://ofacak8l3.bkt.clouddn.com/7_6.png" alt="7_6"><br><img src="http://ofacak8l3.bkt.clouddn.com/7_7.png" alt="7_7"></p>
<h4 id="7-5-Kernels-II"><a href="#7-5-Kernels-II" class="headerlink" title="7.5 Kernels II"></a>7.5 Kernels II</h4><p>SVM parameters:<br>Large C: Lower bias, high variance</p>
<p>Small C: High bias, low variance</p>
<p>Large segma*segma: more smoothly. High bias, low variance.</p>
<p>Small segma*segma: less smoothly. Lower bias, higher variance.</p>
<h3 id="7-6-Using-an-SVM"><a href="#7-6-Using-an-SVM" class="headerlink" title="7.6 Using an SVM"></a>7.6 Using an SVM</h3><p>Use SVM software package(liblinear,libsvm…)to solve for parameters theta.</p>
<p><strong>Need to specify:</strong></p>
<pre><code>Choice of parameter C.
Choice of Kernel(similarity function):
    No Kernel(&apos;Linear Kernel&apos;)
    Gaussian Kernel.(need to choose segma)
</code></pre><p><strong>Note:</strong></p>
<pre><code>Do not perform feature scaling before using the Gaussian kernel.
</code></pre><p><strong>Other Choice of kernel:</strong></p>
<pre><code>Not all similarity functions similarity(x,l) make valid kernels. 
(Need to satisfy &apos;mercer&apos;s Theorem&apos; to make sure SVM package&apos;s optimications run correctly, and do not diverge)    
</code></pre><p><strong>Multi-class classification:</strong></p>
<p>Train K SVMs, 需要对K个类进行分类，而非k-1。</p>
<p><strong>Logistic regression vs SVM:</strong></p>
<p>n= number of features, m =number of training examples</p>
<pre><code>if n is large（相对于m）:
    using Logistic regression, or SVM without kernel.
if n is small, m is intermediate:
    use SVM with Gaussian Kernel.
if n is small, m is large:
    create/add more features,
    then use logistic regression or SVM without kernel.

Neural network likely to work well for most od these settings,
but many slower to train.
</code></pre>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/11/27/AI入门之——Andrew-Ng-“Machine-Learning”课程学习笔记第六周/" itemprop="url">
                  AI入门之——Andrew Ng “Machine Learning”课程学习笔记第六周
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-11-27T15:46:44+08:00" content="2016-11-27">
              2016-11-27
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="6、Advice-for-Applying-Machine-Learning"><a href="#6、Advice-for-Applying-Machine-Learning" class="headerlink" title="6、Advice for Applying Machine Learning"></a>6、Advice for Applying Machine Learning</h2><h3 id="6-1、Evaluating-a-learning-Algorithm"><a href="#6-1、Evaluating-a-learning-Algorithm" class="headerlink" title="6.1、Evaluating a learning Algorithm"></a>6.1、Evaluating a learning Algorithm</h3><h4 id="6-1-1、Deciding-What-to-Try-Next"><a href="#6-1-1、Deciding-What-to-Try-Next" class="headerlink" title="6.1.1、Deciding What to Try Next"></a>6.1.1、Deciding What to Try Next</h4><p>Which of the following statements about diagnostics are true? (BCD)</p>
<p>A. It’s hard to tell what will work to improve a learning algorithm, so the best approach is to go with gut feeling and just see what works.</p>
<p>B. Diagnostics can give guidance as to what might be more fruitful things to try to improve a learning algorithm.</p>
<p>C. Diagnostics can be time-consuming to implement and try, but they can still be a very good use of your time.</p>
<p>D. A diagnostic can sometimes rule out certain courses of action(changes to your learning algorithm) as being unlikely to improve its performance signigicantly.</p>
<h4 id="6-1-2、Evaluating-a-Hypothesis"><a href="#6-1-2、Evaluating-a-Hypothesis" class="headerlink" title="6.1.2、Evaluating a Hypothesis"></a>6.1.2、Evaluating a Hypothesis</h4><p>如何评估假设函数，后面可以以此为基础讨论如何避免过拟合和欠拟合的问题。</p>
<p>Suppose an implementation of linear regression(without reguarization) is badly overfitting the training set. In this case, we would expect:</p>
<p>The training error to be low, and the test error to be high.</p>
<p>数据划分为训练集和测试集，一般比例为7:3,random select。如果数据不是随机的，最好自己随机排序或打乱顺序后再选取70%.</p>
<p>Misclassification error(0/1 misclassification error)</p>
<h4 id="6-1-3、Model-Selection-and-Training-Validation-Test-Sets"><a href="#6-1-3、Model-Selection-and-Training-Validation-Test-Sets" class="headerlink" title="6.1.3、Model Selection and Training/Validation/Test Sets"></a>6.1.3、Model Selection and Training/Validation/Test Sets</h4><p>如何确定对于某组数据，最合适的多项式次数是几次？如何选择学习算法中的正规化参数lamda？</p>
<p>模型选择问题。（泛化误差）</p>
<p>我们将数据集分为三部分，training set(60%), cross validation set(20%), test set(20%).</p>
<p>Training error</p>
<p>cross validation error</p>
<p>test error</p>
<p>我们使用交叉验证集来选择模型，看这些假设在交叉验证集表现如何。选择最小交叉验证集误差的模型。</p>
<p>Consider the model selection procedure where we choose the degree of polynomial using a cross validation set. For the final model, we might generally expect Jcv to be lower than Jtest because:</p>
<p>An extra parameter(d,the degree of the polynomial) has been fit to the cross validation set.</p>
<h3 id="6-2、Bias-vs-Variance-偏差和方差"><a href="#6-2、Bias-vs-Variance-偏差和方差" class="headerlink" title="6.2、Bias vs. Variance(偏差和方差)"></a>6.2、Bias vs. Variance(偏差和方差)</h3><h4 id="6-2-1、Diagnosing-Bias-vs-Variance"><a href="#6-2-1、Diagnosing-Bias-vs-Variance" class="headerlink" title="6.2.1、Diagnosing Bias vs. Variance"></a>6.2.1、Diagnosing Bias vs. Variance</h4><p>High Bias Overfitting</p>
<p>High Variance Underfitting</p>
<p><img src="http://ofacak8l3.bkt.clouddn.com/6_1.png" alt="6_1"></p>
<h4 id="6-2-2、Regularization-and-Bias-Variance"><a href="#6-2-2、Regularization-and-Bias-Variance" class="headerlink" title="6.2.2、Regularization and Bias/Variance"></a>6.2.2、Regularization and Bias/Variance</h4><p><img src="http://ofacak8l3.bkt.clouddn.com/6_2.png" alt="6_2"></p>
<h4 id="6-2-3、Learning-Curves"><a href="#6-2-3、Learning-Curves" class="headerlink" title="6.2.3、Learning Curves"></a>6.2.3、Learning Curves</h4><p>判断一个假设是否存在偏差方差问题</p>
<pre><code>High Bias
If a learning algorithm is suffering from high bias, getting more training data will not help much.
</code></pre><p><img src="http://ofacak8l3.bkt.clouddn.com/6_3.png" alt="6_3"><br>因此知道自己的假设是否存在高偏差/方差问题，非常有用。</p>
<pre><code>High variance
If a learning algorithm is suffering from high variance, getting more training data is likely to help.
</code></pre><p><img src="http://ofacak8l3.bkt.clouddn.com/6_4.png" alt="6_4"></p>
<h4 id="6-2-4、Deciding-What-to-Do-Next-Revisited"><a href="#6-2-4、Deciding-What-to-Do-Next-Revisited" class="headerlink" title="6.2.4、Deciding What to Do Next Revisited"></a>6.2.4、Deciding What to Do Next Revisited</h4><p><img src="http://ofacak8l3.bkt.clouddn.com/6_5.png" alt="6_5"></p>
<h3 id="6-3、Machine-Learning-system-design"><a href="#6-3、Machine-Learning-system-design" class="headerlink" title="6.3、Machine Learning system design"></a>6.3、Machine Learning system design</h3><h4 id="6-3-1、Priorityzing-what-to-work-on"><a href="#6-3-1、Priorityzing-what-to-work-on" class="headerlink" title="6.3.1、Priorityzing what to work on"></a>6.3.1、Priorityzing what to work on</h4><h4 id="6-3-2、Error-Analysis"><a href="#6-3-2、Error-Analysis" class="headerlink" title="6.3.2、Error Analysis"></a>6.3.2、Error Analysis</h4><p>建议的方法：</p>
<p>1、尽快的实现一个最基本的算法，然后在交叉验证数据集上进行验证；</p>
<p>2、画出learning curves，看是否更多的数据、更多的features能提升正确性；</p>
<p>3、Error Analysis：主要分析那些算法预测出错的例子，看能否发现一些系统趋势。</p>
<pre><code>Error analysis may not be helpful for deciding is this is likely to improve performance, only solution is to try it and say if it works.
</code></pre><h4 id="6-3-3-Error-Metrics-for-Skewed-Classes"><a href="#6-3-3-Error-Metrics-for-Skewed-Classes" class="headerlink" title="6.3.3 Error Metrics for Skewed Classes"></a>6.3.3 Error Metrics for Skewed Classes</h4><p>不能仅仅依靠错误率来判断算法的性能，还需要利用Precision 和 Recall<br><img src="http://ofacak8l3.bkt.clouddn.com/6_6.png" alt="6_6"></p>
<h4 id="6-3-4-Trading-off-precision-and-recall"><a href="#6-3-4-Trading-off-precision-and-recall" class="headerlink" title="6.3.4 Trading off precision and recall"></a>6.3.4 Trading off precision and recall</h4><p>我们可以通过计算F1来自动选择性能较高的算法。</p>
<pre><code>F1 = 2*(P*R)/(P+R);
</code></pre><h4 id="6-3-5-Data-for-Machine-Learning"><a href="#6-3-5-Data-for-Machine-Learning" class="headerlink" title="6.3.5 Data for Machine Learning"></a>6.3.5 Data for Machine Learning</h4><p>Banko anf Brill 在2001年提出了一个观点：</p>
<pre><code>It&apos;s not who has the best algorithm that wins, 
It&apos;s who has the most data.
</code></pre><p>这个观点有时候不一定正确：</p>
<p>当feature很少不足以预测时（例，预测房价时仅知道尺寸），此时再多的数据可能也无法提升算法的性能； </p>
<p>当算法参数很多时（例，逻辑回归和线性回归有很多的feature，或者神经网络有很多的隐藏单元），更大的测试集可以尽可能的减少过拟合。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/11/24/AI入门之——Andrew-Ng-“Machine-Learning”课程学习笔记第五周/" itemprop="url">
                  AI入门之——Andrew Ng “Machine Learning”课程学习笔记第五周
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-11-24T15:10:34+08:00" content="2016-11-24">
              2016-11-24
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="5、Neural-Networks：Learning"><a href="#5、Neural-Networks：Learning" class="headerlink" title="5、Neural Networks：Learning"></a>5、Neural Networks：Learning</h2><h3 id="5-1、Cost-Function-and-Backpropagation"><a href="#5-1、Cost-Function-and-Backpropagation" class="headerlink" title="5.1、Cost Function and Backpropagation"></a>5.1、Cost Function and Backpropagation</h3><p><img src="http://ofacak8l3.bkt.clouddn.com/5_1.png" alt="5_1"></p>
<h3 id="5-2、Backprogation-algorithm"><a href="#5-2、Backprogation-algorithm" class="headerlink" title="5.2、Backprogation algorithm"></a>5.2、Backprogation algorithm</h3><p><img src="http://ofacak8l3.bkt.clouddn.com/5_2.png" alt="5_2"></p>
<h3 id="5-3、Gradient-checking"><a href="#5-3、Gradient-checking" class="headerlink" title="5.3、Gradient checking"></a>5.3、Gradient checking</h3><p><img src="http://ofacak8l3.bkt.clouddn.com/5_3.png" alt="5_3"></p>
<pre><code>Important:
Be sure to disable your gradient checking code before training your claaifier. otherwise code will be very slow.
</code></pre><h3 id="5-4-Random-initialization"><a href="#5-4-Random-initialization" class="headerlink" title="5.4 Random initialization"></a>5.4 Random initialization</h3><pre><code>initial each initialtheta to a random value in[-EPSILON,EPSILON]
</code></pre><h3 id="5-5-Put-it-together"><a href="#5-5-Put-it-together" class="headerlink" title="5.5 Put it together"></a>5.5 Put it together</h3><p><img src="http://ofacak8l3.bkt.clouddn.com/5_4.png" alt="5_4"></p>
<p><img src="http://ofacak8l3.bkt.clouddn.com/5_5.png" alt="5_5"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/11/24/毕设论文相关知识索引笔记/" itemprop="url">
                  毕设论文相关知识索引笔记
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-11-24T14:14:40+08:00" content="2016-11-24">
              2016-11-24
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="压缩相关"><a href="#压缩相关" class="headerlink" title="压缩相关"></a>压缩相关</h2><p><a href="http://blog.csdn.net/zhangskd/article/details/17009111" target="_blank" rel="external">速度之王-lz4压缩算法</a></p>
<p><a href="http://blog.csdn.net/zhangskd/article/details/17009111" target="_blank" rel="external">使用tar+lz4+ssh更快的数据传输</a></p>
<p><a href="http://mogu.io/docker-162" target="_blank" rel="external">Docker源码分析之Docker daemon启动和销毁</a></p>
<p><a href="http://www.readern.com/sublime-text-latex-chinese-under-mac.html" target="_blank" rel="external">部署MAC上的Sublime Text + LaTex 中文环境</a></p>
<h2 id="Cgroup介绍、应用实例及原理描述"><a href="#Cgroup介绍、应用实例及原理描述" class="headerlink" title="Cgroup介绍、应用实例及原理描述"></a>Cgroup介绍、应用实例及原理描述</h2><p><a href="http://www.ibm.com/developerworks/cn/linux/1506_cgroup/index.html" target="_blank" rel="external">Cgroup介绍、应用实例及原理描述</a></p>
<p><a href="http://tech.meituan.com/cgroups.html" target="_blank" rel="external">Linux资源管理之cgroups简介</a></p>
<p><a href="https://www.linuxplumbersconf.org/2015/ocw//system/presentations/2619/original/2015-08-20-CRIU_Support_in_Docker_for_Native_Checkpoint_and_Restore.pdf" target="_blank" rel="external">CRIU support in Docker C/R</a></p>
<h3 id="Cgroup设计原理分析"><a href="#Cgroup设计原理分析" class="headerlink" title="Cgroup设计原理分析"></a>Cgroup设计原理分析</h3><p>Linux中，管理进程的数据结构是task_struct</p>
<pre><code>#ifdef CONFIG_CGROUPS
/*Control Group info protected by css_set_lock*/
struct css_set *cgroups;
/*cg_list protected by css_set_lock and tsk-&gt;alloc_lock*/
struct list_head cg_list;
#endif
</code></pre><p>其中*cgroups指向css_set结构，css_set存储了与进程相关的cgroups信息。cg_list是一个嵌入式的list_head结构，将链到同一个css_set的进程组织成一个链表。</p>
<pre><code>struct css_set{
  atomic_t refcount;
  struct hlist_node hlist;
  struct list_head tasks;
  struct list_head cg_links;
  struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT];
  struct rcu_head ruc_head;
};
</code></pre><p>其中，refcount是该css_set的引用数，因为一个css_set可以被多个进程公用，只要这些进程的cgroups信息相同。</p>
<p>hlist是嵌入的hlist_node，用于把所有css_set组成一个hash表，这样内核可以快速定位css_set。</p>
<p>tasks指向所有连到此css_set的进程指向的链表。</p>
<p>cg_links指向一个由struct_cg_group_link连城的链表。</p>
<p>subsys是一个指针数组，存储一组指向cgroup_subsys_state的指针，一个cgroup_subsys_state就是进程与一个特定子系统相关的信息。通过这个数组，进程可以获得相应的cgroup控制信息了。</p>
<pre><code>struct cgroup_subsys_state{
  struct cgroup *cgroup;
  atomic_t refcnt;
  unsigned long flags;
  struct css_id *id;
};
</code></pre><p>*cgroup指向一个cgroup结构，也就是进程属于的cgroup。</p>
<pre><code>task_struct--&gt;css_set--&gt;cgroup_subsys_state--&gt;cgroup
</code></pre><p>这样进程就和cgroup连接起来了。</p>
<pre><code>struct cgroup{
  unsigned long flags;
  atomic_t count;
  struct list_head sibling;
  struct list_head children;
  struct cgroup *parent;
  struct dentry *dentry;
  struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT]
  struct cgroupfs_root *root;
  struct cgroup *top_cgroup;
  struct list_head css_sets;
  struct list_head release_list;
  struct list_head pidlists;
  struct mutex pidlist_mutex;
  struct rcu_head rcu_head;
  struct list_head event_list;
  spinlock_t event_list_lock;
};
</code></pre><p>sibling,children,parent三个嵌入的list_head负责将同一层级的cgroup连接成一颗cgroup树。</p>
<p>subsys指针数组，存储一组指向cgroup_subsys_state的指针。这组指针指向了此cgroup跟各个子系统相关的信息。类似css_set中。</p>
<p>root指向一个cgroupfs_root结构，就是cgroup所在层级对应的结构体。</p>
<p>top_cgroup指向了所在层级的根cgroup，即创建层级时自动创建的那个cgroup。</p>
<p>css_set指向一个由struct_cg_cgroup_link连成的链表。</p>
<pre><code>struct cg_cgroup_link{
  struct list_head cgrp_link_list;
  struct cgroup *cgrp;
  struct list_head cg_link_list;
  struct css_set *cg;
};
</code></pre><p>cgrp_link_list连入到 cgroup-&gt;css_set链表，cgrp指向此cg_group_link相关的cgroup。</p>
<p>cg_link_list连入到css_set-&gt;cg_links指向的链表，cg指向此cg_group_link相关的css_set。</p>
<p>cgroup和css_set是一个多对多的关系，必须添加一个中间结构来将两者联系起来，这既是cg_cgroup_link的作用。cgrp和cg为此结构体的联合主键，cgrp_link_list和cg_link_list分别连入cgroup和css_set，使后两者都可以尽心遍历查询。</p>
<p>####为什么cgroup和css_set是多对多的关系？<br>一个进程对应一个css_set，一个css_set存储了一组进程跟各个子系统相关的信息，但是这些信息由可能不是从一个cgroup那里获得的，因为一个进程可以同时属于多个cgroup，只要这些cgroup不在同一个层级。</p>
<pre><code>eg：
我们创建一个层级A，A上面附加了CPU和memory两个子系统，进程a属于A的根cgroup；创建一个层级B，B上面附加了ns和blkio两个子系统，进程a也属于B的根cgroup；那么进程a对应的CPU和memory是从A的根cgroup获得的，ns和blkio则是从B的根cgroup获得。因此一个css_set存储的cgroup_subsys_state可以对应多个cgroup。另一方面cgroup也存储了一组cgroup_subsys_state，这一组则是cgroup从所在的层级附加的子系统获得的。一个cgroup可以有多个进程，这些进程的css_set不一定都相同，因为有些进程可能还加入了其他cgroup，但是同一个cgroup中的进程与该cgroup关联的cgroup_subsys_state都受到该cgroup的管理，所以一个cgroup也可以对应多个css_set。
</code></pre><p>从前面的分析，我们可以看出从 task 到 cgroup 是很容易定位的，但是从 cgroup 获取此 cgroup 的所有的 task 就必须通过这个结构了。每个进程都回指向一个 css_set，而与这个 css_set 关联的所有进程都会链入到 css_set-&gt;tasks 链表，而 cgroup 又通过一个中间结构 cg_cgroup_link 来寻找所有与之关联的所有 css_set，从而可以得到与 cgroup 关联的所有进程。<br><img src="http://ofacak8l3.bkt.clouddn.com/cgroups_1.png" alt="cgroups_1"></p>
<p>上面这个图从整体结构上描述了进程与 cgroups 之间的关系。最下面的P代表一个进程。每一个进程的描述符中有一个指针指向了一个辅助数据结构css_set（cgroups subsystem set）。 指向某一个css_set的进程会被加入到当前css_set的进程链表中。一个进程只能隶属于一个css_set，一个css_set可以包含多个进程，隶属于同一css_set的进程受到同一个css_set所关联的资源限制。</p>
<p>上图中的”M×N Linkage”说明的是css_set通过辅助数据结构可以与 cgroups 节点进行多对多的关联。但是 cgroups 的实现不允许css_set同时关联同一个cgroups层级结构下多个节点。 这是因为 cgroups 对同一种资源不允许有多个限制配置。</p>
<p>一个css_set关联多个 cgroups 层级结构的节点时，表明需要对当前css_set下的进程进行多种资源的控制。而一个 cgroups 节点关联多个css_set时，表明多个css_set下的进程列表受到同一份资源的相同限制。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Frances Hu" />
          <p class="site-author-name" itemprop="name">Frances Hu</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">28</span>
              <span class="site-state-item-name">Artikel</span>
            </a>
          </div>

          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">7</span>
                <span class="site-state-item-name">Tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Frances Hu</span>
</div>

<div class="powered-by">
  Erstellt mit  <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  

  

  

  

</body>
</html>
