<!doctype html>



  


<html class="theme-next muse use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta property="og:type" content="website">
<meta property="og:title" content="Frances Hu's Blog">
<meta property="og:url" content="http://xiaozhazi.github.io/index.html">
<meta property="og:site_name" content="Frances Hu's Blog">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Frances Hu's Blog">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: 'Author'
    }
  };
</script>




  <link rel="canonical" href="http://xiaozhazi.github.io/"/>

  <title> Frances Hu's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Frances Hu's Blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">Born to be wild!</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archiv
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2020/08/02/设计模式之美第一周/" itemprop="url">
                  设计模式之美第一周
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2020-08-02T16:55:00+08:00" content="2020-08-02">
              2020-08-02
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>之前也下决心看过《HeadFirst设计模式》和《HeadFirst面向对象分析与设计》，但是都没有坚持读完。看了下极客上的这个课程比较适合自己，希望能坚持下来✊</p>
<h2 id="码农要尽早学习并掌握设计模式相关知识"><a href="#码农要尽早学习并掌握设计模式相关知识" class="headerlink" title="码农要尽早学习并掌握设计模式相关知识"></a>码农要尽早学习并掌握设计模式相关知识</h2><p>设计模式能更直接地提高我们的开发能力，如同数据结构和算法教人如何写出高效代码，设计模式教我们如何写出可扩展、可读、可维护的高质量代码。</p>
<h3 id="为什么学习设计模式？"><a href="#为什么学习设计模式？" class="headerlink" title="为什么学习设计模式？"></a>为什么学习设计模式？</h3><ul>
<li>应对面试中的设计模式相关问题<ul>
<li>不管是前端、后端还是全栈工程师，在面试中设计模式问题总是被问得频率比较高。因此平时要多注意积累。</li>
</ul>
</li>
<li>被人吐槽代码烂<ul>
<li>Talk is cheap。 代码能力是码农最基础的能力，是展示程序员基础素养的最直接的衡量标准。这个专栏不仅讲解设计模式，还会通过实战教我们避免类似命名不规范、类设计不合理、分层不清晰、没有模块化概念、代码结构混乱、高度耦合等代码问题</li>
</ul>
</li>
<li>提高复杂代码的设计和开发能力</li>
<li>让读源码、学框架事半功倍<ul>
<li>优秀的开源项目、框架、中间件、代码量、类个数都会比较多，为了保证代码的扩展性、灵活性、可维护性，代码中会使用到很多设计模式或者设计思想。学习设计模式相关知识，可以让我们更轻松地读开源项目。</li>
</ul>
</li>
<li>为职场发展做铺垫</li>
</ul>
<p>投资要趁早，这样才能尽早享受复利。设计模式作为一门与编码、开发有着直接关系的基础知识，早点学习就可以在项目中早点实践锻炼。</p>
<h2 id="从哪些维度评判代码质量的好坏？如何具备写出高质量代码的能力？"><a href="#从哪些维度评判代码质量的好坏？如何具备写出高质量代码的能力？" class="headerlink" title="从哪些维度评判代码质量的好坏？如何具备写出高质量代码的能力？"></a>从哪些维度评判代码质量的好坏？如何具备写出高质量代码的能力？</h2><h3 id="如何评价代码质量的高低？"><a href="#如何评价代码质量的高低？" class="headerlink" title="如何评价代码质量的高低？"></a>如何评价代码质量的高低？</h3><ul>
<li><strong>可维护性 Maintainability</strong>，对于一个项目来说，维护代码的时间远远大于编写代码的时间。工程师大部分的时间可能都是花在了修bug，改老功能逻辑，添加新功能之类的工作上。如果代码分层清晰、模块化好、高内聚低耦合、遵从基于接口而非事先编程的设计原则，那么就可能意味着代码易维护。除此之外，还跟项目代码量的多少、业务复杂程度、利用到的技术复杂程序、文档是否全面、团队成员的开发水平等诸多因素有关。</li>
<li><strong>可读性 Readability</strong>，Any fool can write code that a computer can understand, Good programmer write code that humans can understand. 看代码是否符合编码规范、命名是否达意、注释是否详尽、函数是否长短合适、模块划分是否清晰、是否符合高内聚低耦合等。 Code revie是很好的检测代码可读性的手段。</li>
<li><strong>可扩展性 Extensibility</strong>，对修改关闭，对扩展开放设计准则</li>
<li><strong>灵活性 Flexibility</strong>， 代码易扩展、易复用、或者易用。</li>
<li><strong>简洁性 Simplicity</strong>， KISS原则， ”Keep It Simple， Stupid“，思从深而行从简，真正的高手能云淡风轻地用最简单的方法解决最复杂的问题。</li>
<li><strong>复用性 Reusability</strong>， DRY设计原则，Don’t Repeat Yourself</li>
<li><strong>可测试性 Testability</strong>， 易写单元测试。</li>
</ul>
<h3 id="如何写出高质量代码？"><a href="#如何写出高质量代码？" class="headerlink" title="如何写出高质量代码？"></a>如何写出高质量代码？</h3><p>需要掌握一些更加细化、更加能落地的编程方法论，包括面向对象设计思想、设计原则、设计模式、编码规范、重构技巧等。</p>
<h2 id="面向对象、设计原则、设计模式、编码规范重构，五者有何关系？"><a href="#面向对象、设计原则、设计模式、编码规范重构，五者有何关系？" class="headerlink" title="面向对象、设计原则、设计模式、编码规范重构，五者有何关系？"></a>面向对象、设计原则、设计模式、编码规范重构，五者有何关系？</h2><h3 id="面向对象"><a href="#面向对象" class="headerlink" title="面向对象"></a>面向对象</h3><ul>
<li>四大特性： 封装、抽象、继承、多态</li>
<li>面向对象编程和面向过程编程的区别和联系</li>
<li>面向对象分析、面向对象设计、面向对象编程</li>
<li>接口和抽象类的区别以及各自的应用场景</li>
<li>基于接口而非实现编程的设计思想</li>
<li>多用组合少用继承的设计思想</li>
<li>面向过程的贫血模型和面向对象的充血模型</li>
</ul>
<h3 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h3><ul>
<li>SOLID原则-SRP 单一职责原则</li>
<li>SOLID原则-OCP 开闭原则</li>
<li>SOLID原则-LSP 里式替换原则</li>
<li>SOLID原则-ISP 接口隔离原则</li>
<li>SOLID原则-DIP 依赖倒置原则</li>
<li>DRY原则、KISS原则、YAGNI原则、LOD法则</li>
</ul>
<h3 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h3><p>经典的设计模式有23种，随着编程语言的演进，一些设计模式Singleton随时过时，甚至成了反模式，一些则被内置在编程语言中（如Iterator），另外还有一些新模式诞生（如Monostate）。</p>
<p>23中经典的设计模式，可以分为三大类：创建型、结构型、行为型。</p>
<ul>
<li>创建型 <ul>
<li>常用的： 单例模式、工厂模式、建造者模式</li>
<li>不常用： 原型模式</li>
</ul>
</li>
<li>结构型<ul>
<li>常用的： 代理模式、桥接模式、装饰者模式、适配器模式</li>
<li>不常用： 门面模式、组合模式、享元模式</li>
</ul>
</li>
<li>行为型<ul>
<li>常用的： 观察者模式、模版模式、策略模式、指责链模式、迭代器模式、状态模式</li>
<li>不常用： 访问者模式、备忘录模式、命令模式、解释器模式、中介模式</li>
</ul>
</li>
</ul>
<h3 id="编程规范"><a href="#编程规范" class="headerlink" title="编程规范"></a>编程规范</h3><p>编程规范主要解决的是代码的可读性问题。编程规范相对于设计原则、设计模式，更加具体、更加偏重代码细节。 《重构》《代码大全》《代码整洁之道》书籍推荐</p>
<h3 id="代码重构"><a href="#代码重构" class="headerlink" title="代码重构"></a>代码重构</h3><p>重构是软件开发中非常重要的一个环节。持续重构是保持代码质量不下降的有效手段，能有效避免代码腐化到无可救药的地步。</p>
<p>重构的工具就是前面罗列的那些面向对象设计思想、设计原则、设计模式、编码规范。实际上，设计思想、设计原则、设计模式一个最重要的应用场景就是在重构的时候。虽然设计模式可以提高代码的可扩展性，但是过度不恰当地使用，会增加代码的复杂度，影响代码的可读性。在开发初期，除非特别必须，一定不要过度设计，应用复杂的设计模式。而是当代码出现问题的时候，再针对问题，应用原则和模式进行重构。这样就能有效避免前期的过度设计。</p>
<ul>
<li>重构的目的Why、对象What、时机When、方法How</li>
<li>保证重构不出错的技术手段：单元测试和代码的可测试性</li>
<li>两种不同规模的重构：大重构（大规模高层次）和小重构（小规模低层次）</li>
</ul>
<h3 id="五者之间的联系"><a href="#五者之间的联系" class="headerlink" title="五者之间的联系"></a>五者之间的联系</h3><ul>
<li>面向对象编程因其具有丰富的特性，可以实现很多复杂的设计思路，是很多设计原则设计模式等编码实现的基础。</li>
<li>设计原则指导我们代码设计的一些经验总结。</li>
<li>设计模式是针对软件开发中经常遇到的一些设计问题，总结出来的一套解决方案或者设计思路。相比设计原则更具体更加可执行。</li>
<li>编程规范主要解决代码的可读性问题，相比设计原则、设计模式更具体，更偏重代码细节、更加能落地。持续小重构依赖的理论基础就是编程规范。</li>
<li>重构作为保持代码质量不下降的有效手段，利用的就是面向对象、设计原则、设计模式、编程规范这些理论。</li>
</ul>
<h2 id="本周回顾"><a href="#本周回顾" class="headerlink" title="本周回顾"></a>本周回顾</h2><p>专栏中所涉及的知识点都在下图中。<br><img src="/2020/08/02/设计模式之美第一周/DesignModelAll.jpg" alt>  </p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2020/07/25/TalkGo读书会第一期总结/" itemprop="url">
                  TalkGo读书会第一期总结
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2020-07-25T16:55:00+08:00" content="2020-07-25">
              2020-07-25
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="个人总结"><a href="#个人总结" class="headerlink" title="个人总结"></a>个人总结</h2><p>选择加入读书会首先是本身对性能优化这个Topic比较感兴趣，另外公司底层架构升级维护也需要关注性能问题。课程计划表是两个月，一天一篇的话也不会特别占时间，但是真正执行下来才深刻体会到惰性的强大(如果不是读书会的话应该很容易就弃掉)。平时工作的话回家看书的时间也不会太多，有两三次都是周末抓紧时间搞定，尤其是后面网络那部分平时不太会去关注的指标，可能以前遇到这种章节都会直接略过。</p>
<p>这个课程主要还是偏向原理，基础的性能指标，主要提供了一些遇到性能问题如何下手分析解决的思路。真正在环境中遇到问题分析出原因定位代码还是需要一些经验。特别是一些开源软件遇到性能问题时定位具体代码还是需要耗费一些精力。我们组这个月正好遇到了ES小版本升级后，xpack monitor导致的内存使用问题，定位代码借助了jstack和阿里的Arthas才最终找到原因。</p>
<p>总之，这个课程还是需要经常拿来回顾下，遇到性能问题多积攒经验才是王道。</p>
<p>接下来的看书计划的话，正好前两天收到了一本《架构修炼之道》，准备先翻看下。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2020/07/19/Linux性能优化实战第八周--套路篇/" itemprop="url">
                  《Linux 性能优化实战》第八周--套路篇
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2020-07-19T16:55:00+08:00" content="2020-07-19">
              2020-07-19
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="个人感悟"><a href="#个人感悟" class="headerlink" title="个人感悟"></a>个人感悟</h2><p>在实际的性能分析中，发生性能瓶颈后登陆服务器想要排查的时候发现瓶颈已经消失且很难复现。因此要事先搭建监控系统，把系统和应用程序的运行状况监控下来，并定义一系列的策略，在发生问题第一时间告警处理。</p>
<p>系统监控通过USE法则利用prometheus+grafana来监控系统资源。应用程序监控分为指标监控和日志监控两大块，在复杂业务场景中通常搭建全链路跟踪系统来定位应用瓶颈。</p>
<p>性能问题可以从系统资源瓶颈和应用程序瓶颈两个角度来梳理分析。系统时应用的运行环境，系统的瓶颈会导致应用的性能下降，而应用的不合理设计也会引发系统资源的瓶颈。做性能分析要结合应用程序和操作系统的原理，就出引发问题的真凶。</p>
<p>本周回顾了前几周学习到的常见性能优化方法。值得注意的是一定切记要避免过早优化，性能优化往往会提高复杂度，一方面降低了可维护性，另一方面也为适应复杂多变的新需求带来障碍。所以要逐步完善，首先保证能满足当前的性能要求。发现性能不满足要求或者出现性能瓶颈后，再根据性能分析的结果选择最重要的性能问题进行优化。</p>
<p>不能把性能工具当成性能分析和优化的全部，一方面性能分析和优化的核心是对系统和应用程序运行原理的掌握，性能工具只是辅助我们更快完成此过程的帮手；另一方面完善监控系统可以提供绝大部分性能分析所需的基准数据，从这些数据中很可能大致定位出性能瓶颈，也就不用再去手动执行各类工具了。</p>
<h3 id="捞评论"><a href="#捞评论" class="headerlink" title="捞评论"></a>捞评论</h3><ol>
<li>除了USE原则，还有RED原则。更偏重于应用，在很多微服务中会用到。<ul>
<li>Rate： 每秒请求数量</li>
<li>Errors： 失败的请求次数</li>
<li>Duration： 处理一条请求所需的时间</li>
</ul>
</li>
<li>想要学习eBPF来说，可以从BPF Compiler Collection（BCC）这个项目开始。BCC提供了很多短小的示例，可以快速了解eBPF的工作原理并熟悉eBPF程序的开发思路。了解这些基本的用法后，再去深入了解eBPF。</li>
</ol>
<h2 id="Lesson-53-套路篇：系统监控的综合思路"><a href="#Lesson-53-套路篇：系统监控的综合思路" class="headerlink" title="Lesson 53 套路篇：系统监控的综合思路"></a>Lesson 53 套路篇：系统监控的综合思路</h2><p>一个好的监控系统，不仅可以实时暴露系统的各种问题，更可以根据这些监控到的状态，自动分析和定位大致的瓶颈来源，从而更精确地把问题汇报给相关团队。</p>
<ul>
<li>从系统来说，监控系统要涵盖系统的整体资源使用情况。如CPU、内存、磁盘、文件系统和网络等</li>
<li>从应用程序来说，监控系统要涵盖应用程序内部的运行状态。即包括进程的CPU、磁盘I/O等整体运行状况，也包括接口调用耗时、执行中的错误、内部对象的内存使用等程序内部的运行状况</li>
</ul>
<h3 id="USE法"><a href="#USE法" class="headerlink" title="USE法"></a>USE法</h3><p>USE， Utilization Saturation and Errors</p>
<ul>
<li>使用率，资源用于服务的时间或容量百分比</li>
<li>饱和度，资源的繁忙程度，通常和队列长度相关</li>
<li>错误数，表示发生错误的事件个数</li>
</ul>
<p>常见指标分类如下图所示：</p>
<p><img src="/2020/07/19/Linux性能优化实战第八周--套路篇/use.png" alt></p>
<h3 id="监控系统"><a href="#监控系统" class="headerlink" title="监控系统"></a>监控系统</h3><p>一个完整的监控系统通常由数据采集、数据存储、数据查询和处理、告警以及可视化展示等多个模块组成。</p>
<p>常见的开源监控工具有Zabbix、Nagios、Prometheus等，下面介绍Prometheus的基本架构：</p>
<p><img src="/2020/07/19/Linux性能优化实战第八周--套路篇/prometheus.png" alt></p>
<h4 id="数据采集"><a href="#数据采集" class="headerlink" title="数据采集"></a>数据采集</h4><p>Prometheus targets就是数据采集的对象，Retrieval负责采集这些数据。Prometheus支持两种采集模式：</p>
<ul>
<li>Pull模式，服务端的采集模块触发采集。只要采集目标提供HTTP接口即可（常用的采集模式）</li>
<li>Push模式，各个采集目标主动向Push Gateway推送目标，再由服务器端从Gateway中拉取（移动应用中常用）</li>
</ul>
<p>Prometheus提供服务发现机制，自动根据配置的规则动态发现需要监控的对象。在K8S容器平台中非常有效。</p>
<h4 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h4><p>TSDB（Time Series Database），负责将采集到的数据持久化到SSD等磁盘设备中。 TSDB是专门为时序数据设计的数据库，以时间为索引、数据量大且以追加的方式写入。</p>
<h4 id="数据查询和处理"><a href="#数据查询和处理" class="headerlink" title="数据查询和处理"></a>数据查询和处理</h4><p>TSDB在存储数据的同时，还提供了数据查询和基本的数据处理功能。即PromQL语言，提供了简介的查询、过滤功能。</p>
<h4 id="告警模块"><a href="#告警模块" class="headerlink" title="告警模块"></a>告警模块</h4><p>AlertManager提供了告警功能，基于PromQL语言的触发条件、告警规则的配置管理以及告警的发送。还支持通过分组、抑制或者静默等多种方式来聚合同类告警。</p>
<h4 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h4><p>Prometheus WebUI提供了简单的可视化界面。通常配合Grafana来构建强大的图形界面。</p>
<h2 id="Lesson-54-套路篇：应用监控的一般思路"><a href="#Lesson-54-套路篇：应用监控的一般思路" class="headerlink" title="Lesson 54 套路篇：应用监控的一般思路"></a>Lesson 54 套路篇：应用监控的一般思路</h2><h3 id="指标监控"><a href="#指标监控" class="headerlink" title="指标监控"></a>指标监控</h3><p><strong>应用程序的核心指标，不再是资源的使用情况，而是请求数、错误率和响应时间。</strong><br>除了上述三个指标外，下面几种指标也是应用程序监控必不可少的，可以帮助我们快速定位性能瓶颈。</p>
<ul>
<li><strong>应用进程的资源使用情况</strong>，比如进程占用的CPU、内存、磁盘I/O、网络等。</li>
<li><strong>应用程序之间的调用情况</strong>，如调用频率、错误数、延时等<ul>
<li>可以迅速分析出一个请求处理的调用链中哪个组件导致性能问题</li>
</ul>
</li>
<li><strong>应用程序内部核心逻辑的运行情况</strong>，比如关键环节的耗时以及执行过程中的错误等<ul>
<li>直接进入应用程序内部，定位到底是哪个处理环节的函数导致性能问题</li>
</ul>
</li>
</ul>
<p>由于业务系统通常会涉及到一连串的多个服务，形成一个复杂的分布式调用链。为了迅速定位这类跨应用的性能瓶颈，可以使用Zipkin、Jaeger、Pinpoint等各类开源工具来构建全链路跟踪系统。</p>
<h3 id="日志监控"><a href="#日志监控" class="headerlink" title="日志监控"></a>日志监控</h3><ul>
<li>指标是特定时间段的数值型测量数据，通常以时间序列的方式处理，适合于实时监控</li>
<li>日志都是某个时间点的字符串消息，通常需要对搜索引擎进行索引后，才能进行查询和汇总分析</li>
</ul>
<p>日志监控经典的方法是ELK技术栈，Elasticsearch、Logstash、Kibana三个组件的组合。</p>
<ul>
<li>Logstash负责从各个日志源采集日志，进行预处理，最后再把初步处理过的日志发送给Elasticsearch进行索引</li>
<li>Elasticsearch负责对日志进行检索，并提供一个完整的全文搜索引擎</li>
<li>Kibana负责对日志进行可视化分析，包括日志搜索、处理以及绚丽的仪表板展示</li>
</ul>
<p>ELK中logstash资源消耗较大，在资源紧张时往往使用Fluentd来替代，即EFK技术栈。采集端还可以使用filebeat，架构拓展为filebeat-kafka（zookeeper）-logstash或sparkstreaming-es，除了日志查询外可以做业务关联等。</p>
<h2 id="Lesson-55-套路篇：分析性能问题的一般步骤"><a href="#Lesson-55-套路篇：分析性能问题的一般步骤" class="headerlink" title="Lesson 55 套路篇：分析性能问题的一般步骤"></a>Lesson 55 套路篇：分析性能问题的一般步骤</h2><p>在收到监控系统的告警，发现系统戏院或者应用程序出现性能瓶颈，如何进一步分析根源？</p>
<h3 id="系统资源瓶颈"><a href="#系统资源瓶颈" class="headerlink" title="系统资源瓶颈"></a>系统资源瓶颈</h3><p>系统资源的瓶颈通过USE法，即使用率、饱和度和错误数三类指标来衡量。系统的资源可以分为硬件资源和软件资源两大类：</p>
<ul>
<li>CPU、内存、磁盘和文件系统以及网络等，都是常见的硬件资源</li>
<li>文件描述符、连接跟踪数、套接字缓冲区大小等都是典型的软件资源。</li>
</ul>
<p>在收到监控系统告警后就可以对照这些资源列表，再根据指标的不同来定位。</p>
<h4 id="CPU性能分析"><a href="#CPU性能分析" class="headerlink" title="CPU性能分析"></a>CPU性能分析</h4><p>利用top、vmstat、pidstat、strace以及perf等几个常见的工具，获得CPU性能指标后，再结合进程与CPU的工作原理，就可以迅速定位CPU性能瓶颈的来源。</p>
<p>top、vmstat、pidstat等工具所汇报的CPU性能指标都来源于/proc文件系统，这些指标都应该通过监控系统监控起来。 </p>
<p>比如当收到CPU使用率告警时，从监控系统中直接查询导致CPU使用率过高的进程，然后登陆到服务器分析该进程行为。可以使用strace查看进程的系统调用汇总，也可以使用perf找出热点函数，甚至可以使用动态追踪的方法来观察进程的当前执行过程，直到确定瓶颈个根源。</p>
<h4 id="内存性能分析"><a href="#内存性能分析" class="headerlink" title="内存性能分析"></a>内存性能分析</h4><p>通过free和vmstat输出的性能指标确认内存瓶颈，然后根据内存问题的类型，进一步分析内存的使用、分配、泄漏以及缓存等，最后找出问题的根源。</p>
<p><img src="/2020/07/19/Linux性能优化实战第八周--套路篇/mem_analysis.png" alt></p>
<p>内存的性能指标也来源于/proc文件系统，它们也都应该通过监控系统监控起来。如当收到内存不足的告警时，可以从监控系统中找出占用内存最多的几个进程。然后根据这些进程的内存占用历史，观察是否存在内存泄漏问题。确定可疑进程后，再登陆服务器分析该进程的内存空间或内存分配，查明原因。</p>
<h4 id="磁盘和文件系统I-O性能分析"><a href="#磁盘和文件系统I-O性能分析" class="headerlink" title="磁盘和文件系统I/O性能分析"></a>磁盘和文件系统I/O性能分析</h4><p>当使用iostat发现磁盘I/O存在性能瓶颈后，可以再通过pidstat、vmstat等确认I/O的来源。再根据来源的不同进一步分析文件系统和磁盘的使用率、缓存以及进程的I/O等，从而找出I/O问题所在。</p>
<p><img src="/2020/07/19/Linux性能优化实战第八周--套路篇/io.png" alt></p>
<p>磁盘和文件系统的性能指标也来源于/proc和/sys文件系统，也应该通过监控系统监控起来。</p>
<p>如果发现某块磁盘的I/O使用率为100%时，首先可以从监控系统中，找出I/O最多的进程。然后登陆服务器借助strace、lsof、perf等工具，分析该进程的I/O行为。最后再结合应用程序的原理找出大量I/O的原因。</p>
<h4 id="网络性能分析"><a href="#网络性能分析" class="headerlink" title="网络性能分析"></a>网络性能分析</h4><p>网络性能其实包含两类资源，网络接口和内核资源。网络分析要从Linux网络协议栈的原理来切入。</p>
<ul>
<li>链路层，从网络接口的吞吐量、丢包、错误以及软中断和网络功能卸载等角度分析；</li>
<li>网络层，从路由、分片、叠加网络等角度分析</li>
<li>传输层，从TCP、UDP的协议原理出发，从连接数、吞吐量、延迟重传等角度分析</li>
<li>应用层，从应用层协议、请求数、套接字缓存等角度进行分析</li>
</ul>
<p>网络的性能指标也都来源于内核，包括/proc文件系统、网络接口以及conntrack等内核模块，这些指标同样需要被监控系统监控。</p>
<p>例如，当收到网络不同的告警时，就可以从监控系统中查找各个协议层的丢包指标，确认丢包所在的协议层。然后从监控系统的数据中，确认网络带宽、缓冲区、连接跟踪数等软硬件，是否存在性能瓶颈。最后再登录到服务器中，借助netstat、tcpdump、bcc等工具分析网络的收发数据，并且结合内核中的网络选项以及TCP等网络协议的原理找出问题所在。</p>
<h3 id="应用程序瓶颈"><a href="#应用程序瓶颈" class="headerlink" title="应用程序瓶颈"></a>应用程序瓶颈</h3><p>应用程序瓶颈本质来源有三种：<strong>资源瓶颈、依赖服务瓶颈、应用自身瓶颈</strong>。</p>
<p>资源瓶颈可以用前面的方法来分析。</p>
<p>依赖服务的瓶颈，也就是诸如数据库、分布式缓存、中间件等应用程序，直接或间接调用的服务出现了性能问题从而导致应用程序的响应变慢或者错误率升高。使用全链路跟踪系统可以帮助快速定位这类问题的根源。</p>
<p>应用程序自身的性能问题，包括了多线程处理不当、死锁、业务的复杂度过高等，这类问题可以通过应用程序指标监控以及日志监控中，观察关键环节的耗时和内部执行过程中的错误，帮助缩小问题范围。</p>
<p>不过应用程序内部的状态，外部通常不能直接获取详细的性能数据，需要应用程序在设计和开发时提供这些指标。</p>
<p>如果上述手段还是无法找出瓶颈，可以通过系统资源模块提供的各类进程分析工具来定位分析。 比如：</p>
<ul>
<li>strace观察系统调用</li>
<li>perf和火焰图分析热点函数</li>
<li>动态追踪技术分析进程的执行状态</li>
</ul>
<h2 id="Lesson-56-套路篇：优化性能问题的一般方法"><a href="#Lesson-56-套路篇：优化性能问题的一般方法" class="headerlink" title="Lesson 56 套路篇：优化性能问题的一般方法"></a>Lesson 56 套路篇：优化性能问题的一般方法</h2><h3 id="系统优化"><a href="#系统优化" class="headerlink" title="系统优化"></a>系统优化</h3><h4 id="CPU优化"><a href="#CPU优化" class="headerlink" title="CPU优化"></a>CPU优化</h4><p><strong>CPU性能优化的核心，在于排除所有不必要的工作、充分利用CPU缓存并减少进程程度对性能的影响。</strong></p>
<ul>
<li>把进程绑定到一个或者多个CPU上，充分利用CPU缓存的本地性，并减少进程间的相互影响。</li>
<li>为中断处理程序开启多CPU负载均衡，以便在发生大量中断时可以充分利用多CPU的优势分摊负载</li>
<li>使用cgroups等方法为进程设置资源限制，避免个别进程消耗过多的CPU。同时为核心应用程序设置更高的优先级，减少低优先级任务的影响</li>
</ul>
<h4 id="内存优化"><a href="#内存优化" class="headerlink" title="内存优化"></a>内存优化</h4><ul>
<li>除非有必要，Swap应该禁止掉。避免Swap的额外I/O，带来内存访问变慢的问题</li>
<li>使用Cgroups方法为进程设置内存限制。对于核心应用还应该降低oom_score，避免被OOM杀死</li>
<li>使用大页、内存池等方法，减少内存的动态分配，从而减少缺页异常</li>
</ul>
<h4 id="磁盘和文件系统I-O优化"><a href="#磁盘和文件系统I-O优化" class="headerlink" title="磁盘和文件系统I/O优化"></a>磁盘和文件系统I/O优化</h4><ul>
<li>通过SSD替代HDD、或者用RAID方法来提升I/O性能。</li>
<li>针对磁盘和应用程序I/O模式的特征，选择最合适的I/O调度算法。比如，SSD和虚拟机中的磁盘，通常用的是noop调度算法；数据库应用更推荐使用deadline算法</li>
<li>优化文件系统和磁盘的缓存、缓冲区，比如优化藏也的刷新频率、脏页限额，以及内核回收目录项缓存和索引节点缓存的倾向等</li>
</ul>
<h4 id="网络优化"><a href="#网络优化" class="headerlink" title="网络优化"></a>网络优化</h4><p>从内核资源和网络协议的角度：</p>
<ul>
<li>增大套接字缓冲区、连接跟踪表、最大半连接数、最大文件描述符数、本地端口范围等内核资源配额</li>
<li>减少TIMEOUT超时时间、SYN+ACK重传数、Keepalive探测时间等异常参数处理</li>
<li>还可以开启端口复用、反向地址校验，并调整MTU大小等降低内核的负担</li>
</ul>
<p>从网络接口的角度：</p>
<ul>
<li>将原来CPU上执行的工作，卸载到网卡中执行，即开启网卡的GRO、GSO、RSS、VXLAN等卸载功能；</li>
<li>也可以开启网络接口的多队列功能，这样每个队列就可以用不用的中断号，调度到不同CPU上执行</li>
<li>增大网络接口的缓冲区大小以及队列长度等，提升网络传输的吞吐量</li>
</ul>
<p>在极限性能情况下，内核的网络协议栈可能是最主要的性能瓶颈，所以一般考虑绕过内核协议栈。</p>
<ul>
<li>DPDK技术跳过内核协议栈，直接由用户态进程用轮询的方式，来处理网络请求。同时再结合大页、CPU绑定、内存对齐、流水线并发等多种机制，优化网络包的处理效率</li>
<li>内核自带的XDP技术，在网络包进入内核协议栈前，就对其进行处理。</li>
</ul>
<h4 id="应用程序优化"><a href="#应用程序优化" class="headerlink" title="应用程序优化"></a>应用程序优化</h4><p><strong>性能优化的最佳位置，还是应用程序内部</strong></p>
<ul>
<li>从CPU的角度来说，简化代码、优化算法、异步处理以及编译器优化等</li>
<li>从数据访问的角度，使用缓存、写时复制、增加I/O尺寸等都是常用的减少磁盘I/O的方法</li>
<li>从内存管理的角度，使用大页、内存池等方法，可以预先分配内存，减少内存的动态分配，从而更好地内存访问性能</li>
<li>从网络的角度，使用I/O多路复用，长连接代替短连接、DNS缓存等，可以优化网络I/O并减少网络请求数，从而减少网络延时带来的性能问题</li>
<li>从进程的工作模型来说，异步处理、多线程或多进程可以充分利用每一个CPU的处理能力，从而提高应用程序的吞吐能力</li>
</ul>
<p>还可以使用消息队列，CDN、负载均衡等各种方法来优化应用程序的架构，将原来单机要承担的任务调度到多台服务器中并行处理。</p>
<h2 id="Lesson-57-套路篇：Linux性能工具速查"><a href="#Lesson-57-套路篇：Linux性能工具速查" class="headerlink" title="Lesson 57 套路篇：Linux性能工具速查"></a>Lesson 57 套路篇：Linux性能工具速查</h2><h3 id="CPU性能工具"><a href="#CPU性能工具" class="headerlink" title="CPU性能工具"></a>CPU性能工具</h3><p><img src="/2020/07/19/Linux性能优化实战第八周--套路篇/cpu_metric.png" alt></p>
<p><img src="/2020/07/19/Linux性能优化实战第八周--套路篇/cpu_tools.png" alt></p>
<h3 id="内存性能工具"><a href="#内存性能工具" class="headerlink" title="内存性能工具"></a>内存性能工具</h3><p><img src="/2020/07/19/Linux性能优化实战第八周--套路篇/mem_metric.png" alt></p>
<p><img src="/2020/07/19/Linux性能优化实战第八周--套路篇/mem_tools.png" alt></p>
<h3 id="磁盘I-O性能工具"><a href="#磁盘I-O性能工具" class="headerlink" title="磁盘I/O性能工具"></a>磁盘I/O性能工具</h3><p><img src="/2020/07/19/Linux性能优化实战第八周--套路篇/io_metric.png" alt></p>
<p><img src="/2020/07/19/Linux性能优化实战第八周--套路篇/io_tools.png" alt></p>
<h3 id="网络性能工具"><a href="#网络性能工具" class="headerlink" title="网络性能工具"></a>网络性能工具</h3><p><img src="/2020/07/19/Linux性能优化实战第八周--套路篇/net_metric.png" alt></p>
<p><img src="/2020/07/19/Linux性能优化实战第八周--套路篇/net_tools.png" alt></p>
<h3 id="基准测试工具"><a href="#基准测试工具" class="headerlink" title="基准测试工具"></a>基准测试工具</h3><ul>
<li>在文件系统和磁盘I/O模块中，使用fio工具</li>
<li>在网络模块，使用iperf、pktgen等</li>
<li>在基于Nginx的案例中，使用ab、wrk等</li>
</ul>
<p>现在重新回看Brendan Gregg的这张Linux基准测试工具图谱，收获良多。</p>
<p><img src="/2020/07/19/Linux性能优化实战第八周--套路篇/performance_tool.png" alt></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2020/07/10/Linux性能优化实战第七周--综合实战篇/" itemprop="url">
                  《Linux 性能优化实战》第七周--综合实战篇
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2020-07-10T21:55:00+08:00" content="2020-07-10">
              2020-07-10
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="个人感悟"><a href="#个人感悟" class="headerlink" title="个人感悟"></a>个人感悟</h2><p>本周主要通过一些案例，对之前所学的知识进行复习和深化。首先容器化的应用程序性能分析，依旧可以使用之前的方法来分析和定位，不过要结合命名空间、cgroups、iptables等来综合分析。比如：</p>
<ul>
<li>cgroups影响容器应用的运行</li>
<li>iptables中的NAT会影响容器的网络性能</li>
<li>叠加文件系统，会影响应用的I/O性能</li>
</ul>
<p>对于网络丢包问题分析，要从Linux网络收发的流程入手，结合TCP/IP协议栈的原理来逐层分析。当碰到内核线程的资源使用异常时，很多常用的进程级性能工具并不能直接用到内核线程上。此时可以使用内核自带的perf来观察它们的行为，并找出热点函数，进一步定位性能瓶颈。不过perf汇总报告并不直观，可以通过火焰图来协助排查。</p>
<p>perf对系统内核线程进行分析时，内核线程依然还在正常运行，这种方法也被称为动态追踪技术。动态追踪技术，通过探针机制，来采集内核或者应用程序的运行信息，从而可以不用修改内核和应用程序的代码，就获得丰富的信息，帮助分析、定位想要排查的问题。在Linux系统中，常用的动态追踪方法包括ftrace、perf、eBPF/BCC以及SystemTap等。</p>
<ul>
<li>使用perf配合火焰图寻找热点函数，是一个比较通用的性能定位方法，在很多场景中都可以使用</li>
<li>如果仍然满足不了需求的话，在新版的内核中eBPF和BCC是最灵活的动态追踪方法</li>
<li>而在旧版本内核，特别是在RHEL系统中，由于eBPF支持受限，SystemTap和ftrace往往是更好的选择</li>
</ul>
<hr>
<p>接下来是本周读书笔记</p>
<hr>
<h2 id="Lesson-46-案例篇：为什么应用容器化后，启动慢了很多？"><a href="#Lesson-46-案例篇：为什么应用容器化后，启动慢了很多？" class="headerlink" title="Lesson 46 案例篇：为什么应用容器化后，启动慢了很多？"></a>Lesson 46 案例篇：为什么应用容器化后，启动慢了很多？</h2><p>本课主要学习如何分析应用程序容器化后的性能问题。</p>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><pre><code>sudo docker run --name tomcat --cpus 0.1 -m 512M -p 8080:8080 -itd feisky/tomcat:8
curl localhost:8080
</code></pre><p>容器内核心应用逻辑比较简单，申请一个256M的内存然后输出“HelloWorld”。等待容器启动后运行curl命令给出了结果“HelloWorld”，但是随后出现Empty reply from server一直connection refused。</p>
<p>查看tomcat log并没有发现问题并且容器状态为Exited，此时利用docker inspect查看容器信息，发现State信息中OOMKilled为true，说明容器是被OOM杀死。但是我们已经指定了-m为512M正常不会遇到OOM问题。</p>
<p>此时利用dmesg命令查看系统日志，定位OOM相关日志，可以看到输出显示：</p>
<ul>
<li>mem_cgroup_out_of_memory，超出了cgroup内存限制</li>
<li>java进程在容器内运行，容器内存的使用和限制都是512M，当前使用量已经超过该限制</li>
<li>被杀死的进程，虚拟内存为4.3G，匿名内存页为505M，页内存为19M。</li>
</ul>
<p>分析可知，Tomcat容器的内存主要用在了匿名内存，其实就是主动申请分配的堆内存。Tomcat是基于JAVA开发，自然想到JVM堆内存配置问题。</p>
<pre><code>重新启动容器，执行下列命令查看JVM堆配置
sudo docker exec tomcat java -XX:+PrintFlagsFinal -version | grep HeapSize
sudo docker exec tomcat free -m #容器内部看到的仍然是主机内存
</code></pre><p>看到初始堆内存大小InitialHeapSize为126MB，最大堆内存大小为1.95GB，比容器限制要大。因为容器看不到该配置，虽然在启动容器时设置了内存限制，但是并不影响JVM使用。</p>
<p><strong>解决方法：</strong>在运行容器时加上 -e JAVA_OPT=“-Xmx512m -Xms512m”限制JVM的初始内存和最大内存即可</p>
<p>重新启动容器后，查看tomcat log发现能正常启动，但是启动时间需要22s。</p>
<p>再次重启容器并使用top来观察输出，发现机器中CPU使用率并不高且内存也非常充足，再看进程上Java进程的CPU使用率为10%，内存使用率0.9%。 其他进程使用率几乎可以忽略。</p>
<p>继续重启容器，top拿到JAVA进程PID之后，再用pidstat分析该进程，发现虽然CPU使用率很低，只有10%，但是wait%却非常高达到了87%，说明线程大部分时间都在等待调度，没有真正运行。 </p>
<p>再看我们运行容器时限制了–cpus 0.1,限制了CPU使用。将该值增加大1再重启此时只需要2s即可完成。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>在容器平台中最常见的一个问题就是刚开始图省事不进行资源限制，当容器数量增长之后就会经常出现各种异常问题，最终查下来可能就是某个应用资源使用过高，导致整台机器短时间无法响应。因此使用Docker运行Java应用时一定要确保设置容器资源限制的同时，配置好JVM选项。 也可以升级JAVA版本到JAVA10，即可自动解决类似问题。</p>
<h2 id="Lesson-47-48-案例篇：服务器总是时不时丢包怎么办？"><a href="#Lesson-47-48-案例篇：服务器总是时不时丢包怎么办？" class="headerlink" title="Lesson 47/48 案例篇：服务器总是时不时丢包怎么办？"></a>Lesson 47/48 案例篇：服务器总是时不时丢包怎么办？</h2><p><strong>丢包率是网络性能中最核心的指标之一</strong></p>
<h3 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h3><p>本次实验案例是一个Nginx应用，hping3和curl是Nginx的客户端。</p>
<pre><code>sudo docker run --name nginx --hostname nginx --privileged -p 80:80 -itd feisky/nginx:drop
hping3 -c 10 -S -p 80 XXX.XXX.XXX.XXX
</code></pre><p>因为Nginx使用的是TCP协议，而ping是基于ICMP协议的，因此我们用hping3来测试。此时输出显示10个请求包值收到5个回复，每个请求的RTT波动较大，小的只有3ms大的则有3s左右。可以猜测3s左右的RTT是丢包重传导致。</p>
<p>从图中可以看出可能发生丢包的位置，实际上贯穿了整个网络协议栈：</p>
<ul>
<li>在两台VM连接之间，可能会发生传输失败的错误。如网络阻塞、线路错误等</li>
<li>网卡收包后，环形缓冲区因溢出而丢包</li>
<li>链路层，会因为网络帧校验失败、QoS等丢包</li>
<li>IP层，会因为路由失败、组包大小超过MTU等而丢包</li>
<li>传输层，因为端口未监听、资源占用超过内核限制丢包</li>
<li>套接字层，因为套接字缓冲区溢出而丢包</li>
<li>应用层，应用程序异常而丢包</li>
<li>此外如果配置了iptables规则，可能因为过滤规则而丢包</li>
</ul>
<p>因为VM2只是一个hping3命令，为了简化排查同时假设VM1的网络和内核配置也没问题。因此可能发生问题的地方就是容器内部了。进入容器内部逐层排查丢包原因。</p>
<h4 id="链路层分析"><a href="#链路层分析" class="headerlink" title="链路层分析"></a>链路层分析</h4><p>首先查看<strong>链路层</strong>，通过ethtool/netstat查看网卡的丢包记录,从输出中没有发现任何错误，说明容器的虚拟网卡没有丢包。（<strong>注意：如果tc等工具配置了QoS，tc规则导致额丢包不会包含在网卡的统计信息中</strong>）接下来检查eth0是否配置了tc规则，并查看有无丢包。</p>
<pre><code>sudo docker exec -ti nginx /bin/bash
netstat -f

tc -s qdisc show dev eth0
qdisc netem 800d: root refcnt 2 limit 1000 loss 30%
 Sent 432 bytes 8 pkt (dropped 4, overlimits 0 requeues 0)
</code></pre><p>此时tc规则中看到，eth0上面配置了一个网络模拟排队规则qdisc netem，并且配置了丢包率为30%。后面统计信息显示发送了8个包，但是丢了4个。</p>
<p>发现这点问题之后，直接删掉netem模块即可。</p>
<pre><code>tc qdisc del dev eth0 root netem loss 30%
</code></pre><p>此时再次执行hping3命令，发现还是50%的丢包，RTT的波动也很大，从3ms到1s。</p>
<h4 id="网络层和传输层"><a href="#网络层和传输层" class="headerlink" title="网络层和传输层"></a>网络层和传输层</h4><p>在容器内部继续执行netstat -s命令，可以看到各协议的收发汇总，以及错误信息。 输出表明只有TCP协议发生了丢包和重传。TCP协议有多次超时和失败重试，并且主要错误是半连接充值。即主要失败都是三次握手失败。</p>
<ul>
<li>11 failed connection attempts</li>
<li>4 sgements retransmitted</li>
<li>11 resets received for embryonic SYN_RECV sockets</li>
<li>4 TCPSynRetrans</li>
<li>7 TCPTimeouts</li>
</ul>
<h4 id="iptables"><a href="#iptables" class="headerlink" title="iptables"></a>iptables</h4><p>因为iptables和内核的连接跟踪机制也可能会导致丢包，因此也需要进行排查。要确定是不是说连接跟踪导致的问题，只需要对比当前的连接跟踪数和最大连接跟踪数即可。由于连接跟踪在内核中是全局的，因此需要在主机中查看。</p>
<pre><code>sysctl net.netfilter.nf_conntrack_max
</code></pre><p>此时当前连接跟踪数远小于最大连接跟踪数，因此丢包不可能是连接跟踪导致。</p>
<p>接下来回到容器内部查看iptables的过滤规则，发现有两条DROP规则的统计数值不是0，分别是在INPUT和OUTPUT链中。这两条规则是一样的，指的是使用statistic模块进行随机30%的丢包。删除这两条规则即可。</p>
<pre><code>iptables -t filter -nvL
    Chain INPUT
    pkts  bytes  target  prot  opt  in  out  source      destination
    6     240    DROP    all   --   *    *   0.0.0.0/0   0.0.0.0/0   statistic mode random probability 0.299999999981

    Chain FORWARD
   pkts  bytes  target  prot  opt  in  out  source      destination

    Chain OUTPUT
    pkts  bytes  target  prot  opt  in  out  source      destination
    6     264    DROP    all   --    *   *   0.0.0.0/0   0.0.0.0/0   statistic mode random probability 0.299999999981

iptables -t filter -D INPUT -m statistic --mode random --probability 0.30 -j DROP
iptables -t filter -D OUTPUT -m statistic --mode random --probability 0.30 -j DROP  
</code></pre><p>再用hping3验证此时80端口接发包正常。下面用curl命令检查Nginx对HTTP请求的响应：</p>
<pre><code>curl --max-time 3 http://XXX.XXX.XXX.XXX
    curl:(28) Operation timed out after 3000 milliseconds with 0 bytes received
</code></pre><p>这时候可以tcpdump转包来分析：</p>
<pre><code>tcpdump -i eth0 -nn port 80
</code></pre><p>从结果中可以看出，前三个包是正常的TCP三次握手，但是第四个包确实在3s之后，并且还是客户端VM2发送来的FIN包，说明客户端的连接关闭了。因为curl命令设置了3s超时选项，所以这种情况是因为curl命令超时后退出。</p>
<p>重新执行netstat -i命令查看网卡有没有丢包问题，输出显示RX-DRP是344，即网卡接收时丢包了。但是之前hping3不丢包，现在换成curl GET却丢包，我们需要对比下这两个工具。</p>
<ul>
<li>hping3只发送SYN包</li>
<li>curl在发送SYN包之后，还会发送HTTP GET 请求</li>
</ul>
<p>HTTP GET本质上也是一个TCP包，但是和SYN包相比，它还携带了HTTP GET的数据。这时候就容易想到时MTU配置错误导致。查看eth0的MTU设置只有199，将其改为以太网默认值1500即可。</p>
<pre><code>ifconfig eth0 mtu 1500
</code></pre><h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3><p>遇到网络丢包问题，要从Linux网络收发的流程入手，结合TCP/IP协议栈的原理来逐层分析。</p>
<h2 id="Lesson-49-案例篇：内核线程CPU利用率太高怎么办？"><a href="#Lesson-49-案例篇：内核线程CPU利用率太高怎么办？" class="headerlink" title="Lesson 49 案例篇：内核线程CPU利用率太高怎么办？"></a>Lesson 49 案例篇：内核线程CPU利用率太高怎么办？</h2><p>CPU使用率较高的内核线程，如果用之前的分析方法，一般需要借助于其他性能工具进行辅助分析。本节提供了一种直接观察内核线程的行为，更快定位瓶颈的方法。</p>
<h3 id="内核线程"><a href="#内核线程" class="headerlink" title="内核线程"></a>内核线程</h3><p>Linux中用户态进程的”祖先“都是PID为1的init进程，即systemd进程。但是systemd只管理用户态进程，那么内核态线程是有谁来管理呢？</p>
<ul>
<li>0号进程为idle进程，系统创建的第一个进程，它在初始化1号和2号进程后，演变为空闲任务。</li>
<li>1号进程为init进程，即systemd进程，在用户态运行，用来管理其他用户态进程</li>
<li>2号进程为kthreadd进程，在内核态运行用来管理内核线程。</li>
</ul>
<p>所以要查找内核线程，只需要从2号进程开始，查找它的子孙进程即可</p>
<pre><code>ps -f --ppid 2 -p 2 
#可以看出内核线程的名称都在中括号内，因此更简单的方法是直接查找名称中包含中括号的进程

ps -ef | grep &apos;\[.*\]&apos;
</code></pre><ul>
<li><strong>ksoftirqd </strong>软中断</li>
<li><strong>kswapd0</strong>， 用于内存回收</li>
<li><strong>kworker</strong>，用于执行内核工作队列，分为绑定CPU和未绑定CPU两大类</li>
<li><strong>migration</strong>，用于负载均衡中，把进程迁移到CPU上，每个CPU都有一个migration内核线程</li>
<li><strong>jbd2/sda1-8</strong>， Journaling Block Device，用来为文件系统提供日志功能，以保证数据的完整性</li>
<li><strong>pdflush</strong>，用于将内存中的脏页写入磁盘</li>
</ul>
<h3 id="实验-2"><a href="#实验-2" class="headerlink" title="实验"></a>实验</h3><p>运行一个nginx容器，通过curl命令验证nginx服务正常开启。用hping3命令模拟Nginx客户端请求，此时回到第一个终端，发现系统响应变慢。</p>
<p>用top观察发现2个CPU上软中断使用率都超过了30%，正好是软中断内核线程ksoftirqd/0和ksoftirqd/1。对于内核线程我们用stace、pstack、lsof无法查看详细的调用栈情况，此时可以用内核提供的工具来分析。</p>
<pre><code>perf record -a -g -p $pid --sleep 30
perf report
</code></pre><p>后续利用火焰图来协助排查分析定位热点函数，找出潜在的性能问题。</p>
<h2 id="Lesson-50-51-案例篇：动态追踪怎么用？"><a href="#Lesson-50-51-案例篇：动态追踪怎么用？" class="headerlink" title="Lesson 50/51 案例篇：动态追踪怎么用？"></a>Lesson 50/51 案例篇：动态追踪怎么用？</h2><p><strong>动态追踪技术，通过探针机制，来采集内核或者应用程序的运行信息，从而可以不用修改内核和应用程序的代码，就获得丰富的信息，帮你分析、定位想要排查的问题。</strong></p>
<p>Dtrace的工作原理：它的运行常驻在内核中，用户可以用dtrace命令，把D语言编写的追踪脚本，提交到内核中的运行时来执行。Dtrace可以跟踪用户态和内核态的所有事件，并通过一些列的优化措施，保证最小的性能开销。</p>
<p>Dtrace本身依然无法在Linux中运行，很多工程师都尝试过把Dtrace移植到Linux中，其中最著名的就是RedHat主推的SystemTap。</p>
<p>SystemTap也定义了一种类似的脚本语言，方便用户根据需要自由扩展。不过SystemTap没有常驻内核运行时，需要先把脚本编译为内核模块，然后再插入到内核中执行。因此systemTap启动比较慢，并且依赖于完整的调试符号表。</p>
<p>总的来说，为了追踪内核或用户空间的事件，Dtrace和SystemTap都会把用户传入的追踪处理函数，关联到被称为探针的检测点上。这些探针实际上也就是各种动态追踪技术所依赖的事件源。</p>
<p>根据事件类型不同，动态追踪所使用的事件源，可以分为<strong>静态探针、动态探针以及硬件事件</strong>三类。</p>
<ul>
<li><strong>硬件事件</strong>通常由性能监控计数器PMC产生，包含了各种硬件的性能情况，比如CPU的缓存、指令周期、分支预测等；</li>
<li><strong>静态探针</strong>，是指实现在代码中定义好，并编译到应用程序或者内核中的探针。这些探针只有在开启探测功能时才会被执行到。<ul>
<li>跟踪点 tracepoints，实际上就是在源码中插入的一些带有控制条件的探测点，这些探测点允许时候再添加处理函数。如内核中的printk</li>
<li>USDT探针，全称时用户级静态定义跟踪，需要在源码中插入DTRACE_PROBE()代码，并编译到应用程序中。MYSQL/PostgreSQL也内置了USDT探针</li>
</ul>
</li>
<li><p><strong>动态探针</strong>，指没有事先在代码中定义，但却可以在运行时动态添加的探针。常见的动态探针都两种：</p>
<ul>
<li>kprobes用来跟踪内核态的函数，包括用于函数调用的kprobe和用于函数返回的kretprobe</li>
<li><p>uprobes用来跟踪用户态的函数，包括用于函数调用的uprobe和用于函数返回的uretprobe</p>
<p>  kprobes需要内核编译时开启CONFIG_KPROBE_EVENTS，uprobes需要内核编译中开启CONFIG_UPROBE_EVENTS</p>
</li>
</ul>
</li>
</ul>
<h3 id="动态追踪机制"><a href="#动态追踪机制" class="headerlink" title="动态追踪机制"></a>动态追踪机制</h3><p>在探针基础上，Linux也提供了一系列的动态追踪机制，比如ftrace、perf、eBPF等</p>
<ul>
<li>ftrace最早用于函数跟踪，后来又扩展支持了各种事件跟踪功能。</li>
<li>perf是一种最简单的静态跟踪机制，也可以通过perf来定义动态事件，只关注真正感兴趣的事件</li>
<li>eBPF是在BPF（Berkeley Packet Filter）的基础上扩展来的，不仅支持事件跟踪机制，还可以通过自定义的BPF代码</li>
</ul>
<p>除此之外，还有很多内核外的工具，也提供了丰富的动态追踪功能，最常见的就是SystemTap和BCC，以及常用于容器性能分析的sysdig</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2020/07/04/Linux性能优化实战第六周--网络性能篇实战/" itemprop="url">
                  《Linux 性能优化实战》第六周--网络性能实战篇
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2020-07-04T17:26:55+08:00" content="2020-07-04">
              2020-07-04
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="个人感悟"><a href="#个人感悟" class="headerlink" title="个人感悟"></a>个人感悟</h2><p>本周主要从案例分析来学习Linux网络问题如何分析与解决，这也是这个专栏四个基础模块的最后一小部分。对于网络性能评估，一般情况需要从上到下对每个协议层进行性能测试，然后根据性能测试结果结合Linux网络协议栈原理，找出导致性能瓶颈的根源。</p>
<p>在优化网络的性能时，可以结合Linux系统的网络协议栈和网络收发流程，从应用程序、套接字、传输层、网络层再到链路层等，对每个层进行逐层优化。</p>
<ul>
<li>应用程序中，主要优化I/O模型、工作模型以及应用层的网络协议</li>
<li>套接字层，主要优化套接字的缓冲区大小</li>
<li>传输层，主要优化TCP和UDP协议</li>
<li>网络层，主要优化路由、转发、分片以及ICMP协议</li>
<li>链路层，主要优化网络包的收发、网络功能卸载以及网卡选项</li>
</ul>
<p>对于DDoS攻击，由于其分布式、大流量、难追踪等特点，目前还无法完全御防，只能设法缓解DDoS带来的影响。在实际应用中通常让Linux服务器配合专业的流量清洗以及网络防火墙设备一起来缓解该问题。</p>
<h3 id="新工具GET"><a href="#新工具GET" class="headerlink" title="新工具GET"></a>新工具GET</h3><pre><code>网络流量分析：
确认网络包的收发是否正常
tcpdump Wireshark
确认单次请求和并发请求时的网络延迟是否正常
hping3，wrk
确认路由是否正确，并查看路由中每一跳网关的延迟
traceroute
观察应用程序对网络套接字的调用情况是否正常
strace
Linux动态追踪框架
SystemTap
</code></pre><hr>
<p>接下来是本周读书笔记</p>
<hr>
<h2 id="Lesson-37-案例篇：DNS解析时快时慢应该怎么办？"><a href="#Lesson-37-案例篇：DNS解析时快时慢应该怎么办？" class="headerlink" title="Lesson 37 案例篇：DNS解析时快时慢应该怎么办？"></a>Lesson 37 案例篇：DNS解析时快时慢应该怎么办？</h2><h3 id="域名与DNS解析"><a href="#域名与DNS解析" class="headerlink" title="域名与DNS解析"></a>域名与DNS解析</h3><pre><code>cat /etc/resolv.conf
nameserver 8.8.8.8
</code></pre><p>除了nslookup之外，另一个常用的DNS解析工具dig，还提供了trace功能，可以展示递归查询的整个过程。</p>
<pre><code>dig +trace +ndnssec xiaozhazi.github.io #nodnssec表示禁止DNS安全扩展
</code></pre><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="DNS解析失败"><a href="#DNS解析失败" class="headerlink" title="DNS解析失败"></a>DNS解析失败</h4><pre><code>sudo docker run -it --rm -v $(mktemp):/etc/resolv.conf feisky/dnsutils bash 
nslookup xiaozhazi.github.io  
#connection timeout, no servers could be reached
ping -c3 8.8.8.8 # works normally

nslookup -debug xiaozhazi.github.io 
</code></pre><p>发现并没有连接DNS服务器而是连接环回地址，此时猜测可能容器内部没有配置DNS服务器。 在resolv.conf文件中添加即可。</p>
<h4 id="DNS解析不稳定"><a href="#DNS解析不稳定" class="headerlink" title="DNS解析不稳定"></a>DNS解析不稳定</h4><pre><code>sudo docker run -it --rm --cap-add=NET_ADMIN --dns 8.8.8.8 feisky/dnsutils bash 
time nslookup time.geekbang.org  # real time=10s
ping -c3 8.8.8.8  #latency=140ms
ping -c3 114.114.114.114 #latency=31ms， change dnsserver
#rerun nslookup now timecost=64ms
#此时重复执行仍会出现1s延时的情况，说明容器内没有使用DNS缓存

/etc/init.d/dnsmasq start 
然后修改resolv.conf文件，将DNS服务器改为dnsmasq的监听地址
此时再重复执行nslookup除第一次运行外，都只需10ms左右
</code></pre><p>DNS解析结果不稳定，可能存在以下几种情况：</p>
<ul>
<li>DNS服务器本身有问题，响应慢且不稳定</li>
<li>客户端到DNS服务器的网络延迟较大</li>
<li>DNS请求或响应包，在某些情况下被链路中的网络设备弄丢了</li>
</ul>
<p>几种常见的DNS优化方法：</p>
<ul>
<li>对DNS解析的结果进行缓存</li>
<li>对DNS解析的结果进行预取</li>
<li>使用HTTPDNS取代常规的DNS解析，使用HTTP协议栈绕过链路中的DNS服务器，可以避免域名被劫持的问题</li>
<li>基于DNS的全局负载均衡GSLB，根据用户的位置返回距离最近的IP地址</li>
</ul>
<h2 id="Lesson-38-案例篇：怎么使用tcpdump和Wireshark分析网络流量"><a href="#Lesson-38-案例篇：怎么使用tcpdump和Wireshark分析网络流量" class="headerlink" title="Lesson 38 案例篇：怎么使用tcpdump和Wireshark分析网络流量"></a>Lesson 38 案例篇：怎么使用tcpdump和Wireshark分析网络流量</h2><p>我们通常使用ping来测试服务延迟，不过有时候ping本身也会出现意想不到的问题，此时就需要我们抓取ping命令执行时收发的网络包，然后分析这些网络包，进而找出问题根源。</p>
<ul>
<li>tcmdump仅支持命令行格式使用，常用在服务器中抓取和分析网络包</li>
<li>Wireshark还提供了图形界面和汇总分析工具，在分析复杂的网络场景是比较实用</li>
</ul>
<h3 id="实验分析"><a href="#实验分析" class="headerlink" title="实验分析"></a>实验分析</h3><pre><code>#禁止接收从DNS服务器中发送过来并包含googleusercontent的包
iptables -I INPUT -p udp --sport 53 -m string --string googleusercontent --algo bm -j DROP
ping -c3 geektime.org

#此时三次请求都得到了响应，每次延迟30ms左右，没有丢包。但是总时间却超过了11s
#是不是DNS解析慢的原因呢？发现ping的输出中三次都是用的IP地址，说明ping只需要在最开始运行时解析一次得到IP
#用nslookup验证了下不存在域名解析慢的问题

tcpdump -nn udp port 53 or host XXX(geektime.org ip)
#另一个终端执行ping指令 
</code></pre><p>逐条分析tcpdump输出，发现有两条反向地址解析PTR请求，只看到了请求包没有应答包。而且每条记录都执行了5s才出现下一个网络包。</p>
<p>因此这里的ping缓慢是因为两次PTR请求超时导致的， 在ping执行时禁掉PTR即可</p>
<pre><code>ping -n -c3 geektime.org
</code></pre><h3 id="tcpdump"><a href="#tcpdump" class="headerlink" title="tcpdump"></a>tcpdump</h3><p>tcpdump 基于libpcap，利用内核中的AF_PACKET套接字，抓取网络接口中传输的网络包，并提供了请打的过滤规则，从大量的网络包中挑出最想关注的信息。</p>
<pre><code>-i   #tcpdump -i eth0  指定网络接口
-nn  #tcpdump -nn   不解析IP地址和端口号的名称 
-c   #tcpdump -c5   限制要抓取网络包的个数
-A   #tcpdump -A    以ASSCII格式显示网络包内容
-w   #tcpdump -w file.pcap  保存到文件中，通常以pcap作为后缀
-e   #tcpdump -e    输出链路层的头部信息
</code></pre><h2 id="Lesson-39-案例篇：怎么缓解DDoS攻击带来的性能下降问题？"><a href="#Lesson-39-案例篇：怎么缓解DDoS攻击带来的性能下降问题？" class="headerlink" title="Lesson 39 案例篇：怎么缓解DDoS攻击带来的性能下降问题？"></a>Lesson 39 案例篇：怎么缓解DDoS攻击带来的性能下降问题？</h2><h3 id="DDoS简介"><a href="#DDoS简介" class="headerlink" title="DDoS简介"></a>DDoS简介</h3><p>DDoS， Distributed Denial of Service。 前身是DoS，即拒绝服务攻击，指利用大量的合理请求，来占用过多的目标资源，从而使得目标服务无法响应正常请求。</p>
<p>DDoS则是采用的分布式架构，利用多台主机同时攻击目标主机。这样，即使目标服务部署了网络防御设备，面对大量网络请求时还是无力应对。目前已知的最大流量攻击正是Github遭受的DDoS攻击，峰值流量达到了1.35Tbps，PPS更是超过了1.2亿。</p>
<p>从攻击原理来看，DDoS分为：</p>
<ul>
<li>耗尽带宽。无论是服务器还是路由器、交换机等网络设备，带宽都有固定的上限。带宽耗尽后就会发生网络拥堵，无法传输其他正常的网络报文。</li>
<li>耗尽操作系统资源。例如CPU、内存等物理资源，以及连接表等软件资源。</li>
<li>消耗应用程序的运行资源。应用程序的运行，通常要和其他的资源或系统交互，如果程序一直忙于处理无效请求，也会导致正常请求的处理变慢甚至无法响应</li>
</ul>
<h3 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h3><p>通过hping3命令模拟DoS攻击：</p>
<pre><code>hping3 -S -p 80 -i u10 XXX.XXX.XXX.XXX
#-S表示设置TCP协议的SYN
</code></pre><p>用Sar来观察，可以看到网络接收的PPS（每秒收发的报文数）已经达到了2w多，但是BPS（每秒收发的字节数）只有1174KB，即每个包只有54B。全是小包 </p>
<pre><code>sar -n DEV 1
</code></pre><p>继续通过tcpdump抓取eth0网卡的包</p>
<pre><code>tcpdump -i eth0 -n tcp port 80
</code></pre><p>Flag[S]表示是SYN包，大量的SYN包表明，这是一个SYN Flood攻击。通过Wireshark可以更直观的输出SYN Flood的过程。</p>
<p>其原理是：</p>
<ul>
<li>客户端构造大量的SYN包，请求建立TCP连接</li>
<li>服务器收到包后，向源IP发送SYN+ACK报文，并等待三次握手的最后一次ACK报文，直到超时</li>
</ul>
<p>这种等待状态的TCP连接，通常称为半开连接。由于连接表的大小有限，大量的半开连接就会导致连接表迅速占满，从而无法建立新的TCP连接。</p>
<pre><code>netstat -n -p | grep SYN_REC #定位半开连接的IP
iptables -I INPUT -s XXX.XXX.XXX.XXX -p tcp -j REJECT
</code></pre><p>如果遇到多台服务器同时发送SYN Flood攻击，这种方法可能就无效了。因为很可能无法SSH到机器上，因此提前要对系统做一些TCP，限制半开连接的数量/减少连接失败内核重启次数。</p>
<pre><code># /etc/sysctl.conf
sysctl -w net.ipv4.tcp_max_syn_backlog=1024
sysctl -w net.ipv4.tcp_synack_retries=1
</code></pre><p>还可以启用TCP SYN Cookies来防御SYN Flood攻击。</p>
<pre><code>sysctl -w net.ipv4.tcp_syncookies=1
</code></pre><h3 id="DDoS到底该如何防御"><a href="#DDoS到底该如何防御" class="headerlink" title="DDoS到底该如何防御"></a>DDoS到底该如何防御</h3><ul>
<li>可以用XDP或者DPDK构建DDoS方案，在内核网络协议栈前，或者跳过内核协议栈来识别并丢弃DDoS报文</li>
<li>对于流量型的DDoS，当服务器的带宽被耗尽时，服务器内部处理就无能为力了。此时只能在服务器外部的网络设备中增加专业的入侵检测和防御设备，配置流量清洗设备阻断恶意流量等。</li>
<li>对于慢速请求，响应流量很大时使得应用程序会耗费大量的资源处理，此时需要应用程序考虑识别，并尽早拒绝掉这些恶意流量。比如合理利用缓存，增加WAF(Web Application Firewall),使用CDN等。</li>
</ul>
<h2 id="Lesson-40-案例篇：网络请求延迟变大了，该怎么办？"><a href="#Lesson-40-案例篇：网络请求延迟变大了，该怎么办？" class="headerlink" title="Lesson 40 案例篇：网络请求延迟变大了，该怎么办？"></a>Lesson 40 案例篇：网络请求延迟变大了，该怎么办？</h2><h3 id="网络延迟"><a href="#网络延迟" class="headerlink" title="网络延迟"></a>网络延迟</h3><p><strong>网络延迟</strong> 网络数据传输所用的时间，这个时间可能单向也可以指双向的。 双向的往返通道延迟，RTT Round-Trip Time</p>
<p><strong>应用程序延迟</strong> 从应用程序接收请求到发回响应全程所用的时间。</p>
<p>通常用ping来测试网络延迟，但是ping基于ICMP通过计算ICMP回显响应报文和回显请求报文的时间差，来获得延时。这个过程不需要特殊认证，通常会被很多网络攻击利用。为了避免被攻击，很多网络服务会把ICMP禁掉。此时可以借助traceroute和hping3工具。</p>
<pre><code>hping3 -c 3 -S -p 80 baidu.com
# -c表示发送3次，-S设置TCPSYN，-p端口号
traceroute --tcp -p 80 -n baidu.com
# -n表示不对结果中的IP地址执行反向域名解析
</code></pre><h3 id="实验分析-1"><a href="#实验分析-1" class="headerlink" title="实验分析"></a>实验分析</h3><p>设计了对比实验，在80端口运行官方Nginx容器，在8080端口运行案例Nginx容器</p>
<pre><code>sudo docker run --network=host --name=good -itd nginx
sudo docker run --network=host --name=nginx -itd feisky/nginx:latency
</code></pre><p>通过hping3命令分别测试其延迟时，发现差不多都是7ms。</p>
<p>再用wrk测试并发请求下的延迟，分别测试机器并发100时两个端口的性能</p>
<pre><code>wrk --latency -c 100 -t 2 --timeout 2 http://IP:Port
</code></pre><p>此时官方Nginx的延迟在9ms左右，而案例应用则是44ms左右。 此时我们首先想到的是通过tcpdump抓取8080端口的网络包，并保存文件到nginx.pcap</p>
<pre><code>tcpdump -nn tcp port 8080 -w nginx.pcap
wrk --latency -c 100 -t 2 --timeout 2 htto://IP:Port 
</code></pre><p>再把抓取到的nginx.pcap文件复制到装有Wireshark的机器中进行分析，此时只过滤除TCP Stream的。 通过输出界面可以看出三次握手和第一次请求和响应都挺快，但是第二次请求就比较慢，40ms之后才发送ACK响应。</p>
<p>而TCP延迟确认（Delayed ACK）的最小超时时间就是40ms。 <strong>延迟确认</strong>是针对TCP ACK机制的一种优化，不用每次请求都发送一个ACK，而是等一会看看有没有其他包需要发送，捎带着ACK一起发送过去。如果等不到就在超时后单独发送ACK。</p>
<p>man TCP，发现TCP可以设置TCP_QUICKACK开启快速确认模式，否则默认采用延迟确认机制。</p>
<p>为了验证猜想，用strace观察wrk为套接字设置了哪些TCP选项,证明确实没有TCP_QUICKACK</p>
<pre><code>strace -f wrk --latency -c 100 -t 2 --timeout 2 http://IP:Port
&apos;&apos;&apos;
setsockopt(52,SOL_TCP,TCP_NODELAY,[1],4)=0
&apos;&apos;&apos;
</code></pre><p>但是这只是客户端的行为，按理说Nginx服务器不应该受此影响，再回过去分析网络包，重新观察Wireshark输出。发现第二个分组是等到客户端第一个分组的ACK后才发送的，有点类似延迟确认，不过此时不是ACK包，而是发送数据。</p>
<p>此时考虑<strong>Nagle算法</strong>，纳格算法，是TCP协议中用于减少小包发送数量的一种优化算法，目的是为了提高实际带宽利用率。算法规定一个TCP连接上，最多只能有一个未确认的未完成分组，在收到这个分组的ACK之前，不发送其他分组。这些小分组会被组合起来，并在收到ACK后，用同一个分组发送出去。</p>
<p>Nagle算法和Linux默认的延迟确认机制一起使用后，网络延迟会非常明显。 TCP可以设置TCP_NODELAY来禁用掉Nagle算法。</p>
<pre><code>sudo docker exec nginx cat /etc/nginx/nginx.conf | grep tcp_nodelay
    tcp_nodelay off;
</code></pre><p>将其设置为on即可。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>遇到网络延迟增大问题时，可以通过以下工具来定位网络中的潜在问题：</p>
<ul>
<li>hping3，wrk确认单次请求和并发请求时的网络延迟是否正常</li>
<li>traceroute 确认路由是否正确，并查看路由中每一跳网关的延迟</li>
<li>tcpdump和Wireshark 确认网络包的收发是否正常</li>
<li>strace观察应用程序对网络套接字的调用情况是否正常</li>
</ul>
<h2 id="Lesson-41-42-如何优化NAT性能？"><a href="#Lesson-41-42-如何优化NAT性能？" class="headerlink" title="Lesson 41/42 如何优化NAT性能？"></a>Lesson 41/42 如何优化NAT性能？</h2><h3 id="NAT原理"><a href="#NAT原理" class="headerlink" title="NAT原理"></a>NAT原理</h3><p>NAT，Network Address Tranlation，可以重写IP数据包的源IP或者目的IP，被普遍用来解决公网IP地址短缺的问题。原理是，网络中的多台主机通过共享一个公网IP地址，来访问外网资源。</p>
<ul>
<li>静态NAT，内网IP和公网IP一对一永久映射关系</li>
<li>动态NAT，内网IP从公网IP池中动态选择一个进行映射</li>
<li>网络地址端口转换NAPT，Network Address and Port Translation，即把内网IP映射到公网IP的不同端口上，让多个内网IP可以共享同一个公网地址</li>
</ul>
<p>NAPT是目前最流行的NAT类型，根据转换方式又分为三类：</p>
<ul>
<li>源地址转换SNAT，目的地址不变只替换源IP或者源端口</li>
<li>目的地址转换DNAT，源IP保持不变只替换目的IP或目的端口</li>
<li>双向地址转换，当接收网络包时执行DNAT，将目的地址转换为内网IP，发送网络包时执行SNAT，把源IP替换为外部IP</li>
</ul>
<p>比如，本地服务器IP为192.168.0.2，NAT网关IP为100.100.100，目的服务器baidu.com地址为123.125.115.110</p>
<ul>
<li>服务器访问baidu.com时，NAT地址会把源地址从本地服务器IP替换为网关IP，然后才发送给baidu.com</li>
<li>baidu.com发回响应包时，NAT网关又把目的地址替换为本地服务器IP，然后发送给目的服务器</li>
</ul>
<h3 id="iptables与NAT"><a href="#iptables与NAT" class="headerlink" title="iptables与NAT"></a>iptables与NAT</h3><p>Linux内核提供的Netfiler框架，允许对网络数据包进行修改和过滤。 以及iptables、ip6tables、ebtables等工具。</p>
<p>NAT表中内置了三个链：</p>
<ul>
<li>PREROUTING，路由判断前所执行的规则，比如，对接收到的数据包进行DNAT</li>
<li>POSTROUTING，路由判断后所执行的规则，比如，对发送或转发的数据包进行SNAT或MASQUERADE</li>
<li>OUTPUT，类似于PREROUTING，但只处理从本机发送出去的包</li>
</ul>
<p>SNAT配置需要在NAT表中的POSTROUTING链中配置： </p>
<ul>
<li><ol>
<li>为一个子网统一配置SNAT，并由Linux选择默认的出口IP，即MASQUERAGE      <em>iptables -t nat -A POSTROUTING -s 192.168.0.0/16 -j MASQUERADE</em></li>
</ol>
</li>
<li><ol>
<li>为具体的IP地址配置SNAT，并制定转换后的源地址<br> <em>iptables -t nat -A POSTROUTING -s 192.168.0.2 -j SNAT –to-source 100.100.100.100</em>    </li>
</ol>
</li>
</ul>
<p>DNAT配置需要在NAT表中的PREROUTING或OUTPUT链中配置，其中前者更常用<br><em>iptables -t nat -A PREROUTING -d 100.100.100.100 -j DNAT –to-destination 192.168.0.2</em></p>
<p>在使用iptables配置NAT规则后，Linux需要转发来自其他IP的网络包，要确保开启Linux的IP转发功能</p>
<pre><code>sysctl -w net.ipv4.ip_forward=1
</code></pre><h3 id="实验-2"><a href="#实验-2" class="headerlink" title="实验"></a>实验</h3><p>主要使用了SystemTap工具，Linux的一种动态追踪框架，把用户提供的脚本转换为内核模块来执行，用来监测和跟踪内核的行为。</p>
<p>先运行一个不用NAT的Nginx服务，用ab测试其性能作为基准性能。然后运行使用DNAT的Nginx容器</p>
<pre><code>sudo docker run --name nginx --priviledged -p 8080:8080 -itd feisky/nginx:nat
iptables -nL -t nat  #ensure DNAT rules are created
</code></pre><p>再用ab测试时发现连接超时错误，将超时时间延长后减少总测试次数发现延迟比基准值相差太多。</p>
<p>因为我们已经知道根源时NAT，因此不需要tcpdump再抓包分析来源。此时用SystemTap工具来测试，先写一个dropwatch.stp脚本</p>
<pre><code>#! /usr/bin/env stop
global locations

probe begin {printf &quot;Monitoring for dropped packets\n&quot;}
probe end {printf &quot;Stopping dropped packet monitor \n&quot;}

probe kernel.trace(&quot;kfree_skb&quot;) { locations[$location] &lt;&lt;&lt; 1 }

probe timer.sec(5)
{
  printf(&quot;\n&quot;)
  foreach ( l in locations-) {
    printf(&quot;%d packets dropped at %s\n&quot;,@count(locations[l]),sysname(l))
  }
  delete locations
}
---------
stap --all-modules dropwatch.stp
</code></pre><p>当probebegin输出后执行ab测试，观察stap命令输出，发现大量丢包发生在nf_hook_slow位置。再用perf report来查看nf_hook_slow的调用位置，主要来自于三个地方。分别是ipv4——conntrack_in，br_nf_pre_routing以及iptable_nat_ipv4_in。即nf_hook_slow主要在执行三个动作：</p>
<ul>
<li>接收网络包时，在连接跟踪表中查找连接，并为新连接分配跟踪对象</li>
<li>Linux网桥中转发包，因为实验中容器网络通过网桥实现</li>
<li>接收网络包时，执行DNAT将8080端口的包转发给容器</li>
</ul>
<p>此时要优化只有从内核着手，DNAT的基础时conntrack，因此主要针对其参数进行优化</p>
<pre><code>sysctl -a | grep conntrack

net.netfilter.nf_conntrack_count
net.netfilter.nf_conntrack_max 
net.netfilter.nf_conntrack_buckets
net.netfilter.nf_conntrack_tcp_timout_syn_recv
net.netfilter.nf_conntrack_tcp_timeout_syn_sent
net.netfilter.nf_conntrack_tcp_timeout_time_wait
</code></pre><h2 id="Lesson-44-44-套路篇：网络性能优化的几个思路"><a href="#Lesson-44-44-套路篇：网络性能优化的几个思路" class="headerlink" title="Lesson 44/44 套路篇：网络性能优化的几个思路"></a>Lesson 44/44 套路篇：网络性能优化的几个思路</h2><p>网络性能优化首先要获得网络基准测试报告，然后通过相关性能工具，定位出网络性能瓶颈，再进行优化。可以从应用程序、套接字、传输层、网络层以及链路层分别来看</p>
<h3 id="应用程序"><a href="#应用程序" class="headerlink" title="应用程序"></a>应用程序</h3><p>应用程序通过套接字接口进行网络操作，主要对网络I/O和进程自身的工作模型进行优化。<br>除了之前C10K的多路复用技术之外，应用层也有一些网络协议优化可以考虑：</p>
<ul>
<li>长连接代替短连接，显著降低TCP建立连接的成本</li>
<li>使用内存方式来缓存不常变化的数据，降低网络I/O次数，同时加快应用程序的响应速度</li>
<li>使用Protocol Buffer等序列化的方式，压缩网络I/O的数据了，可以提高应用程序的吞吐</li>
<li>使用DNS缓存、预取、HTTPDNS等方式，减少DNS解析的延迟，也可以提升网络IO的整体速度</li>
</ul>
<h3 id="套接字"><a href="#套接字" class="headerlink" title="套接字"></a>套接字</h3><p>每个套接字都有一个读写缓冲区，为了提高网络吞吐量，通常需要调整这些缓冲区的大小</p>
<ul>
<li>读缓冲区，缓存了远端发来的数据。</li>
<li><p>写缓冲区，缓存了要发出去的数据。</p>
<pre><code>net.core.optmem_max
net.core.rmem_max net.core.wmem_max
net.ipv4.tcp_rmem net.ipv4.tcp_wmem
</code></pre></li>
</ul>
<h3 id="传输层"><a href="#传输层" class="headerlink" title="传输层"></a>传输层</h3><h4 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h4><ul>
<li>请求数大的场景下，大量处于TIME_WAIT状态的连接，会占用大量内存和端口资源。这种场景下可以优化与TIME_WAIRT相关的内核选项。<ul>
<li>增加处于TIME_WAIT状态的连接数量net.ipv4.tcp_max_tw_buckets，并增大连接跟踪表的大小net,netfilter.nf_conntrack_max;</li>
<li>减少net.ipv4.tcp_fin_timeout,net.netfilter.nf_conntrack_tcp_timeout_time_wait,让系统尽快释放它们占用的资源</li>
<li>开启端口复用net.ipv4.tcp_tw_reuse，这样被TIME_WAIT状态占用的端口还能用于新建的连接中</li>
<li>增大本地端口的范围net.ipv4.ip_local_port_range，支持更多的连接，提高整体的并发能力</li>
<li>增加最大文件描述符的数量 </li>
</ul>
</li>
<li>缓解SYN FLOOD等攻击，可以优化与SYN状态相关的内核选项<ul>
<li>增大TCP半连接的最大数量，或者开启TCP SYN Cookies来绕开半开连接数量限制</li>
<li>减少SYN_RECV的重传SYN+ACK次数</li>
</ul>
</li>
<li>在长连接场景中，通常使用Keepalive来检测TCP连接的状态，以便对端连接断开后可以自动回收。系统默认的Keepalive探测间隔和重试次数一般都无法满足应用程序的性能要求。考虑优化与Keepalive相关的内核选项。<ul>
<li>缩短最后一次数据包到Keepalive的探测包间隔时间</li>
<li>缩短发送Keepalive探测包的间隔时间</li>
<li>减少探测失败后一直到通知应用程序前的重试次数</li>
</ul>
</li>
</ul>
<h4 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h4><ul>
<li>增大套接字缓冲区大小以及UDP缓冲区范围</li>
<li>增大本地端口号的范围</li>
<li>根据MTU大小，调整UDP数据包的大小，减少或避免分片的发生</li>
</ul>
<p>###网络层<br>网络层主要对路由、IP分片以及ICMP等进行优化。</p>
<ul>
<li>从路由和转发的角度出发<ul>
<li>在需要转发的服务器中，开启IP转发。 net.ipv4.ip_forward=1</li>
<li>调整数据包的生存周期TTL net.ipv4.ip_default_ttl</li>
<li>开启数据包的反向地址校验，防止IP欺骗，减少伪造IP带来的DDoS问题， net.ipv4.conf.eth0.rp_filter=1</li>
</ul>
</li>
<li>从分片的角度出发，调整MTU的大小</li>
<li>从ICMP的角度出发，为了避免ICMP主机探测，ICMP Flood等问题，限制ICMP的行为<ul>
<li>禁用ICMP</li>
<li>禁止广播ICMP</li>
</ul>
</li>
</ul>
<p>###链路层</p>
<p>网卡收包后调用的中断处理程序，需要消耗大量的CPU，可以将这些中断处理程序调度到不同的CPU上执行，提高网络吞吐量。</p>
<ul>
<li>为网卡硬中断配置CPU亲和性，或者开启irqbalance服务</li>
<li>开启RPS(Receive Packet Steering)和RFS(Receive Flow Steering)，将应用程序和软中断的处理调度到相同的CPU上。增加CPU缓存命中率，减少网络延迟</li>
<li>将原来在内核中通过软件处理的功能，卸载到网卡中通过硬件执行<ul>
<li>TSO (TCP Segmentation Offload), UFO (UDP Fragmentation Offload) </li>
<li>GSO (Generic Segmentation Offload)</li>
<li>LRO (Large Receive Offload)</li>
<li>GRO (Generic Receive Offload)</li>
<li>RSS (Receive Side Scaling)</li>
<li>VXLAN卸载</li>
</ul>
</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2020/06/27/Linux性能优化实战第五周--网络性能篇/" itemprop="url">
                  《Linux 性能优化实战》第五周--网络性能篇
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2020-06-27T15:26:55+08:00" content="2020-06-27">
              2020-06-27
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="个人感悟"><a href="#个人感悟" class="headerlink" title="个人感悟"></a>个人感悟</h2><p>本周的学习首先了解了Linux网络的工作原理，<strong>OSI七层网络模型</strong>，<strong>TCP/IP模型</strong>以及<strong>网络包的收发流程</strong>。应用程序通过Socket接口发送数据包时先要在网络协议栈从上到下逐层处理最终到网卡上发送，接收也要经过网络协议栈从下到上逐层解析，最后送到应用程序。以及网络传输相关性能指标和响应的查看工具。</p>
<p>并且学习了经典的C10K问题，以及延伸的C1000K和C10M问题。这个印象中研究生毕业面试B家的时候被问到过。C10K问题的根源一方面在于系统有限的资源，另一方面，同步阻塞I/O模型以及轮询的套接字接口限制了网络事件的处理效率。目前高性能网络方法都基于epoll。从10K到100K，增加物理资源就能解决，但是到1000K时就需要多方面的优化工作，从硬件中断处理和网络功能卸载、到网络协议栈的文件描述符数量、连接状态跟踪、缓存队列等内核的优化，再到应用程序的工作模型优化，都需要考虑。</p>
<p>再进一步实现10M，就需要用XDP的方式，在内核协议栈之前处理网络包；或者用DPDK直接跳过网络协议栈在用户空间通过轮询的方式直接处理网络包。其中DPDK时目前最主流的高性能网络解决方案，但是需要能支持DPDK的网卡配合使用。</p>
<h3 id="新工具GET"><a href="#新工具GET" class="headerlink" title="新工具GET"></a>新工具GET</h3><pre><code>查看网络配置
ifconfig/ip
套接字信息/协议栈统计信息
netstat/ss
网络吞吐量和PPS
sar
带宽
ethtool
连通性和延时
ping
应用层性能
wrk/jmeter
传输层性能
iperf
转发性能
pktgen
</code></pre><h3 id="捞评论GET"><a href="#捞评论GET" class="headerlink" title="捞评论GET"></a>捞评论GET</h3><p>1、客户端的网络环境复杂，出现网络抖动如何分析解决？</p>
<p>在第一个网络出入口记录每次收发消息的内容和具体时间戳(精确到ms)，遇到玩家反馈时根据id及发生的大致时间在日志中查找响应记录，看是服务器响应慢还是客户端到服务器的线路慢。可以考虑更多的接入点、专线、CDN等优化公网的链路延迟问题。</p>
<hr>
<p>接下来是本周读书笔记</p>
<hr>
<h2 id="Lesson-33-34-关于网络，你必须知道这些"><a href="#Lesson-33-34-关于网络，你必须知道这些" class="headerlink" title="Lesson 33/34 关于网络，你必须知道这些"></a>Lesson 33/34 关于网络，你必须知道这些</h2><h3 id="网络模型"><a href="#网络模型" class="headerlink" title="网络模型"></a>网络模型</h3><p>开放式系统互联通信参考模型（Open System Interconnection Reference Model），简称<strong>OSI网络模型</strong></p>
<p>为了解决网络互联中异构设备的兼容性，并解耦复杂的网络包处理流程，OSI模型把网络互联的框架分为应用层、表示层、会话层、传输层、网络层、数据链路层以及物理层等七层。</p>
<ul>
<li>应用层，负责为应用程序提供统一的接口</li>
<li>表示层，负责把数据转换成兼容接收系统的格式</li>
<li>会话层，负责维护计算机之间的通信连接</li>
<li>传输层，负责为数据加上传输表头，形成数据包</li>
<li>网络层，负责数据的路由和转发</li>
<li>数据链路层，负责MAC寻址，错误侦测和改错</li>
<li>物理层，负责在物理网络中传输数据帧</li>
</ul>
<p>在Linux中我们实际上使用的是一个更实用的四层模型，即TCP/IP网络模型。</p>
<p>TCP/IP模型把网络互联的框架分为应用层、传输层、网络层、网络接口层等四层。</p>
<ul>
<li>应用层，负责向用户提供一组应用程序，如HTTP，FTP，DNS等</li>
<li>传输层，负责端到端的通信，如TCP，UDP</li>
<li>网络层，负责网络包的封装、寻址和路由，如IP，ICMP</li>
<li>网络接口层，负责网络包在物理网络中的传输，比如MAC寻址、错误侦测以及通过网卡传输网络帧等</li>
</ul>
<h3 id="Linux网络栈"><a href="#Linux网络栈" class="headerlink" title="Linux网络栈"></a>Linux网络栈</h3><ul>
<li>传输层在应用数据前面增加了TCP头</li>
<li>网络层在TCP数据包前增加了IP头</li>
<li>网络接口层在IP数据包前后分别增加了帧头和帧尾</li>
</ul>
<p>网络接口配置的最大传输单元MTU规定了最大的IP包大小，以太网中MTU默认时1500</p>
<h3 id="Linux网络收发流程"><a href="#Linux网络收发流程" class="headerlink" title="Linux网络收发流程"></a>Linux网络收发流程</h3><h4 id="网络包的接收流程"><a href="#网络包的接收流程" class="headerlink" title="网络包的接收流程"></a>网络包的接收流程</h4><ul>
<li>当一个网络帧到达网卡后，网卡通过DMA方式，把网络包放到收包队列中；然后通过硬中断告诉中断处理程序已经接收到了网络包。</li>
<li>网卡中断处理程序为网络帧分配内核数据结构sk_buff，并将其拷贝到sk_buff缓冲区中；再通过软中断通知内核接收到了新的网络帧。</li>
<li>内核协议栈从缓冲区中取出网络帧，并通过网络协议，从上到下处理这个网络帧<ul>
<li>链路层检查报文合法性，找出上层协议的类型（IPv4 or IPv6），再去掉帧头和帧尾，交给网络层；</li>
<li>网络层取出IP头，判断网络包的下一步走向，比如是交给上层处理还是转发。当网络层确认这个包发送本机后，取出上层协议的类型（TCP or UDP），去掉IP头再交给传输层处理。</li>
<li>传输层取出TCP/UDP头之后根据&lt;源IP，源端口，目的IP，目的端口&gt;四元组作为标识，找出对应的Socket，并把数据拷贝到Socket接收缓存中</li>
</ul>
</li>
<li>应用程序使用Socket接口读取到新收到的数据</li>
</ul>
<h4 id="网络包的发送流程"><a href="#网络包的发送流程" class="headerlink" title="网络包的发送流程"></a>网络包的发送流程</h4><ul>
<li>应用程序通过调用Socket API发送网络包</li>
<li>由于这是系统调用，会陷入内核态的套接字层中。套接字层把数据包放到Socket发送缓冲区中</li>
<li>网络协议栈从Socket发送缓冲区中取出数据包，再按照TCP/IP栈，从上到下逐层处理</li>
<li>分片后的网络包再发送到网络接口层，进行物理地址寻址，找到下一跳的MAC地址，然后添加帧头和帧尾，放到发包队列中。这一切完成后会有软中断通知驱动程序</li>
<li>驱动程序通过DMA从发包队列中读出网络帧，并通过物理网卡发送出去</li>
</ul>
<h3 id="性能指标"><a href="#性能指标" class="headerlink" title="性能指标"></a>性能指标</h3><ul>
<li>带宽， 表示链路的最大传输速率，单位b/s</li>
<li>吞吐量，表示单位时间内成功传输的数据量，单位b/s或者B/s 吞吐量/带宽=网络使用率</li>
<li>延时，表示从网络请求发出后，一直到收到远端响应，所需要的时间延迟。<ul>
<li>建立连接需要的时间， TCP握手延时</li>
<li>一个数据包往返所需的时间，RTT</li>
</ul>
</li>
<li>PPS，Packet Per Second，表示以网络包为单位的传输速率。通常用来评估网络的转发能力</li>
</ul>
<p>此外，<strong>网络的可用性、并发连接数、丢包率、重传率</strong>也是常用的性能指标。</p>
<h3 id="网络配置"><a href="#网络配置" class="headerlink" title="网络配置"></a>网络配置</h3><pre><code>ifconfig eth0
ip -s addr show dev eth0
</code></pre><ul>
<li>网络接口的状态标志， ifconfig输出中的RUNNING，ip输出中的LOWER_UP，都表示物理网络是联通的</li>
<li>MTU大小</li>
<li>网络接口的IP地址、子网、以及MAC地址</li>
<li>网络收发的字节数、包数、错误数以及丢包情况，特别是TX和RX部分的errors、dropped、overruns、carrier以及collisions等指标不为0时，通常表示出现了网络I/O问题<ul>
<li><strong>errors</strong>表示发生错误的数据包数，比如校验错误、帧同步错误等</li>
<li><strong>dropped</strong>表示丢弃的数据包数，即数据包已经收到了Ring Buffer，但是因为内存不足等原因丢包</li>
<li><strong>overruns</strong>表示超限数据包数，即网络I/O速度过快，导致RingBuffer中的数据包来不及处理导致的丢包</li>
<li><strong>carrier</strong>表示发生carrier错误的数据包数，比如双工模式不匹配、物理电缆出问题</li>
<li><strong>collisions</strong>表示碰撞数据包数</li>
</ul>
</li>
</ul>
<h3 id="套接字信息"><a href="#套接字信息" class="headerlink" title="套接字信息"></a>套接字信息</h3><pre><code>netstat -nlp | head -n 3
ss -ltnp | head -n 3
</code></pre><p>netstat和ss用来查看套接字、网络栈、网络接口以及路由表的信息。其中Recv-Q和Send-Q信息需要特别关注，如果不是0的话说明有网络包的堆积发生。</p>
<p>当Socket处于Established时，Recv-Q表示套接字缓冲中还没有被应用取走的字节数，Send-Q表示还没有被远端主机确认的字节数。<br>当Socket处于Listening时，Recv-Q表示全连接队列的长度，Send-Q表示全连接队列的最大长度。</p>
<h3 id="协议栈统计信息"><a href="#协议栈统计信息" class="headerlink" title="协议栈统计信息"></a>协议栈统计信息</h3><pre><code>netstat -s 
ss -s
</code></pre><h3 id="吞吐量和PPS"><a href="#吞吐量和PPS" class="headerlink" title="吞吐量和PPS"></a>吞吐量和PPS</h3><pre><code>sar -n DEV 1 
</code></pre><p>带宽可以用ethtool来查询</p>
<pre><code>ethtool eth0 | grep Speed
</code></pre><h3 id="连通性和延时"><a href="#连通性和延时" class="headerlink" title="连通性和延时"></a>连通性和延时</h3><pre><code>ping -c3 XXX.XXX.XXX.XXX
</code></pre><h2 id="Lesson-35-基础篇：C10K和C1000K回顾"><a href="#Lesson-35-基础篇：C10K和C1000K回顾" class="headerlink" title="Lesson 35 基础篇：C10K和C1000K回顾"></a>Lesson 35 基础篇：C10K和C1000K回顾</h2><p>C10K问题最早由Dan Kegel在1999年提出，那是服务器还是32位系统，运行Linux2.2版本，只配置的很少的内存(2G)和千兆网卡。怎样在这样的系统中支持并发1万的请求？</p>
<p>从资源上说，2G内存和千兆网卡服务器，同时处理1w请求，只要每个请求处理占用不超200KB内存和100Kbit的网络带宽就可以。所以物理资源充足，接下来时软件的问题。</p>
<p>如果每个请求分配一个进程/线程，1w个请求会涉及1w个进程/线程的调度、上下文切换乃至它们占用的内存都会成为瓶颈。</p>
<ul>
<li>怎样在一个线程内处理多个请求？非阻塞I/O或者异步I/O？</li>
<li>怎么更节省资源地处理用户请求？用最少的线程来服务这些请求？</li>
</ul>
<h3 id="I-O模型优化"><a href="#I-O模型优化" class="headerlink" title="I/O模型优化"></a>I/O模型优化</h3><p>I/O事件的通知方式：</p>
<ul>
<li><strong>水平触发</strong>：只要文件描述符可以非阻塞的执行I/O，就会触发通知 </li>
<li><strong>边缘出发</strong>：只有在文件描述符发生改变时(I/O请求到达时)，才发送一次通知。</li>
</ul>
<p>I/O多路复用的方法：</p>
<ul>
<li><strong>使用非阻塞I/O和水平触发通知，比如使用select和poll</strong><ul>
<li>select和 poll从文件描述符列表中，找出哪些可以执行IO，然后进行真正的网络I/O读写。由于I/O是非阻塞的，一个线程中就可以同时监控一批套接字的文件描述符，达到了单线程处理多请求的目的。 </li>
<li>优点：对程序友好，API简单。</li>
<li>缺点：需要对文件描述符列表轮询，请求多时较为耗时，且select和poll还有一些限制。以及应用程序每次调用select和poll时还需要把文件描述符的集合从用户空间传入内核空间，由内核修改后再传回用户空间。增加了处理成本。</li>
</ul>
</li>
<li><strong>使用非阻塞I/O和边缘触发通知，如epoll</strong><ul>
<li>epoll使用红黑树在内核中管理文件描述符的集合，使用事件驱动的机制，只关注有I/O事件发生的文件描述符，不需要轮询整个集合</li>
<li>epoll在Linux2.6之后提供，由于边缘触发只在文件描述符可读或可写事件发生时才通知，应用程序需要尽可能多地执行I/O并要处理更多的异常事件</li>
</ul>
</li>
<li><strong>使用异步I/O</strong><ul>
<li>异步I/O也是在Linux2.6后提供，和直观逻辑不太一样，使用时要小心设计，难度较高</li>
</ul>
</li>
</ul>
<h3 id="工作模型优化"><a href="#工作模型优化" class="headerlink" title="工作模型优化"></a>工作模型优化</h3><ul>
<li>主进程+多个worker子进程<ul>
<li>主进程执行bind()+listen()后创建多个子进程</li>
<li>每个子进程中都通过accept()和epoll_wait（）来处理相同的套接字</li>
<li>Nginx就是采取这种模式，主进程用来初始化套接字并管理子进程的生命周期，worker进程用来负责实际的请求处理</li>
<li>accept和epoll_wait调用存在一个惊群问题，当网络I/O事件发生时多个进程被同时唤醒，但实际上只有一个进程来响应事件，其他被唤醒的进程都会重新休眠。<ul>
<li>accept惊群问题在Linux2.6中解决了</li>
<li>epoll_wait到Linux4.5才通过EPOLLEXCLUSIVE解决</li>
<li>nginx通过在worker进程中增加一个全局锁来解决，worker进程首先要竞争到锁，然后才加入到epoll中，确保只有一个worker子进程被唤醒</li>
</ul>
</li>
</ul>
</li>
<li>监听相同端口的多进程模型<ul>
<li>所有进程都监听相同的接口，并且开启SO_REUSEPORT选项，由内核将请求负载均衡到这些监听进程中</li>
<li>不会存在惊群问题，Nginx1.9.1中支持该模式，SO_REUSEPORT选项在Linux3.9以上版本才有</li>
</ul>
</li>
</ul>
<h3 id="C1000K"><a href="#C1000K" class="headerlink" title="C1000K"></a>C1000K</h3><p>基于I/O多路复用和请求处理的优化，C10K问题很容易解决，那么C1000K呢？</p>
<p>100万个请求需要大量的系统资源</p>
<ul>
<li>假设一个请求16KB，需要15GB内存</li>
<li>带宽上来看，假设只有20%的活跃连接，即使每个连接只需要1KB/s的吞吐量，总共也需要1.6Gb/s的吞吐量。因此还需要配置万兆网卡，或者基于多网卡bonding承载更大的吞吐量。</li>
</ul>
<p>C1000K的解决方法，本质上还是构建在epoll的非阻塞I/O模型上，只不过除了I/O模型外还需要从应用程序到Linux内核，再到CPU、内存和网络各个层次的深度优化，特别是需要借助硬件来卸载哪些通过软件处理的大量功能。</p>
<h3 id="C10M"><a href="#C10M" class="headerlink" title="C10M"></a>C10M</h3><p>同时处理1000w条请求呢？在C1000K时各种软件硬件的优化可能已经做到极致了，此时无论怎么优化应用程序和内核中各种网络参数，想实现1000万请求的并发都是及其困难的。</p>
<p>究其根本，还是Linux内核协议栈做了太多太多繁重的工作，从网卡中断带来的硬中断处理程序开始到软中断中的各层网络协议处理，最后再到应用程序，这个路径太长导致网络包的处理优化到一定程度后就无法再进一步。</p>
<p>要解决这个问题，就要跳过内核协议栈的冗长路径，把网络包直接发送到要处理的应用程序那里。</p>
<ul>
<li>DPDK，用户态网络的标准，跳过内核协议栈直接由用户进程通过轮询方式处理网络接收。 还通过大页、CPU绑定、内存对齐、流水线并发等多种机制，优化网络包的处理效率。</li>
<li>XDP，Linux内核提供的一种高性能网络数据路径。它允许网络包在进入内核协议栈之前就进行处理，也可以带来更高的性能。XDP底层也是基于Linux内核的eBPF机制实现的。</li>
</ul>
<h2 id="Lesson-36-套路篇：怎么评估系统的网络性能？"><a href="#Lesson-36-套路篇：怎么评估系统的网络性能？" class="headerlink" title="Lesson 36 套路篇：怎么评估系统的网络性能？"></a>Lesson 36 套路篇：怎么评估系统的网络性能？</h2><h3 id="各协议层的性能测试"><a href="#各协议层的性能测试" class="headerlink" title="各协议层的性能测试"></a>各协议层的性能测试</h3><h4 id="转发性能"><a href="#转发性能" class="headerlink" title="转发性能"></a>转发性能</h4><p>网络接口和网络层，主要负责网络包的封装、寻址、路由以及发送和接收。在这两个网络协议中，每秒可处理的网络包数PPS就是最重要的性能指标。特别是64B小包的处理能力，值得我们特别关注。如何来测试网络包的处理能力呢？</p>
<p>Linux内核自带的高性能网络测试工具pktgen,但是并不能直接找到pktgen命令，需要加载pktgen内核模块后，再通过/proc文件系统来交互</p>
<pre><code>modprobe pktgen
ps -ef | grep pktgen | grep -v grep
ls /proc/net/pktgen/
</code></pre><h3 id="TCP-UDP性能"><a href="#TCP-UDP性能" class="headerlink" title="TCP/UDP性能"></a>TCP/UDP性能</h3><pre><code>iperf
netperf
</code></pre><h3 id="HTTP性能"><a href="#HTTP性能" class="headerlink" title="HTTP性能"></a>HTTP性能</h3><p>在应用层，有的应用程序会直接基于TCP或UDP构建服务，也有大量的应用基于应用层的协议来构建服务。HTTP就是一个最常用的应用层协议，要测试HTTP性能可以通过ab、webbench等。</p>
<pre><code>ab
webbench
</code></pre><h3 id="应用负载性能"><a href="#应用负载性能" class="headerlink" title="应用负载性能"></a>应用负载性能</h3><pre><code>wrk
TCPCopy
Jmeter
</code></pre><hr>
<h2 id="Lesson-36-套路篇：怎么评估系统的网络性能"><a href="#Lesson-36-套路篇：怎么评估系统的网络性能" class="headerlink" title="Lesson 36 套路篇：怎么评估系统的网络性能"></a>Lesson 36 套路篇：怎么评估系统的网络性能</h2><p>上节课学习了C10M的解决方案，不过在大多数场景下，我们并不需要单机并发1000万请求。通过调整系统架构，把请求分发到多台服务器中并行处理，才是更简单、扩展性更好的方案。</p>
<p>这就需要我们评估系统的网络性能，以便考察系统的处理能力，并为容量规划提供基准数据。</p>
<h3 id="性能指标回顾"><a href="#性能指标回顾" class="headerlink" title="性能指标回顾"></a>性能指标回顾</h3><p><strong>带宽、吞吐量、延时、PPS</strong>，这四个性能指标中带宽跟物理网卡配置直接关联；Linux服务器的网络吞吐量一般会比带宽小，交换机等专门的网络设备吞吐量一般接近带宽；PPS以网络包为单位的网络传输速率，通常用在需要大量转发的场景中；对于TCP或者Web服务来说通常会用并发连接数和每秒请求数QPS等指标。</p>
<h3 id="网络基准测试"><a href="#网络基准测试" class="headerlink" title="网络基准测试"></a>网络基准测试</h3><p>在测试之前需要弄清楚需要测试的应用程序基于协议栈的哪一层？</p>
<ul>
<li>基于HTTP和HTTPS的Web应用程序，属于应用层，需要测试HTTP/HTTPS的性能；</li>
<li>大多数游戏服务器，为了支持更大的在线人数。通常会基于TCP/UDP与客户端交互，需要测试TCP/UDP性能</li>
<li>还有一些场景将Linux作为一个软交换机或者路由器来使用，此时要更关注网络包的处理能力。即PPS，关注网络层的转发能力。</li>
</ul>
<h3 id="各协议层性能测试"><a href="#各协议层性能测试" class="headerlink" title="各协议层性能测试"></a>各协议层性能测试</h3><h4 id="转发性能-1"><a href="#转发性能-1" class="headerlink" title="转发性能"></a>转发性能</h4><p>网络接口层和网络层，主要负责网络包的封装、寻址、路由以及发送和接收。这里最重要的性能指标就是PPS每秒可处理的网络包数。</p>
<p>可以用hping3或者pktgen来测试网络包处理能力。其中pktgen作为一个Linux内核自带的高性能网络测试工具，需要加载pktgen内核模块后再通过/proc文件系统交互。</p>
<pre><code>modprobe pktgen
ls /proc/net/pktgen
</code></pre><p>在测试时，需要先给每个内核线程kpktgend_X以及测试网卡，配置pktgen选项。再通过pgctrl启动测试。</p>
<p>假设发包及其使用网卡eth0，目标机器的IP为192.168.0.30， MAC地址为11:11:11:11:11:11</p>
<pre><code>#define function for test options
function pgset() {
    local result
    echo $1 &gt; $PGDEV
    result=`cat $PGDEV | fgrep &quot;Result: OK:&quot;`

    if [ &quot;$result&quot; = &quot;&quot; ]; then 
        cat $PGDEV | fgrep Result:
    fi
} 

#bind eth0 for thread 0
PGDEV=/proc/net/pktgen/eht0
pgset &quot;count 1000000&quot; #total packages
pgset &quot;delay 5000&quot;
pgset &quot;clone_skb 0&quot;
pgset &quot;pkt_size 64&quot;
pgset &quot;dst 192.168.0.30&quot;
pgset &quot;dst_mac 11.11.11.11.11.11&quot;

#Start test
PGDEV=/proc/net/pktgen/pgctrl
pgset &quot;start&quot;

#Check result
cat /proc/net/pktgen/eth0
</code></pre><h4 id="TCP-UDP性能-1"><a href="#TCP-UDP性能-1" class="headerlink" title="TCP/UDP性能"></a>TCP/UDP性能</h4><pre><code>iperf
netperf
</code></pre><h4 id="HTTP性能-1"><a href="#HTTP性能-1" class="headerlink" title="HTTP性能"></a>HTTP性能</h4><pre><code>ab -c 1000 -n 10000 http://www.baidu.com
webbench
</code></pre><h4 id="应用负载性能-1"><a href="#应用负载性能-1" class="headerlink" title="应用负载性能"></a>应用负载性能</h4><pre><code>wrk TCPCopy Jmeter LoadRunner
工作中用过Jmeter进行测试
</code></pre>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2020/06/21/Linux性能优化实战第四周--IO性能篇/" itemprop="url">
                  《Linux 性能优化实战》第四周--IO性能篇
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2020-06-21T10:57:55+08:00" content="2020-06-21">
              2020-06-21
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="个人感悟"><a href="#个人感悟" class="headerlink" title="个人感悟"></a>个人感悟</h2><p>本周主要学习Linux I/O相关的基础知识以及遇到I/O异常问题如何分析解决。<strong>Linux一切皆文件</strong>。为了支持不同的文件系统，首先Linux在用户进程和文件系统之间实现了一层虚拟文件系统。用户进程和内核中的其他子系统只需要跟VFS提供的统一接口进行交互。其次，为了降低慢速磁盘对性能的影响，文件系统又通过页缓存、目录项缓存以及索引节点缓存来减少对应用程序性能的影响。</p>
<p>文件系统层、通用块层和块设备层组成了Linux存储系统I/O栈。其中通用块层是磁盘I/O的核心，向上为文件系统和应用程序提供访问块设备的标准接口，向下把各种异构磁盘抽象为统一的块设备，并对文件系统和应用程序发来的I/O请求进行重新排序、请求合并等。</p>
<p>通过实验学习了遇到IO瓶颈进一步导致CPU使用率高的问题如何分析和解决。一般通过iostat确认是否存在I/O性能瓶颈，再用strace和lsof定位应用程序以及它正在写入的日志文件路径。最后通过调整日志打印级别来解决。如果strace无法跟踪到write系统调用时，可以用filetop和opensnoop来定位具体的线程和读写文件目录；也可以加-p选项开启线程跟踪。</p>
<p>MYSQL的MyISAM引擎主要依赖系统缓存加速磁盘IO的访问。如果系统中还有其他应用同时运行，MyISAM引擎很难充分利用系统缓存。缓存可能会被其他应用程序占用，甚至被清理掉。因此最好不要将应用程序的性能优化完全建立在系统缓存上，最好能在应用程序内部分配内存，构建完全自主的缓存；或者利用第三方缓存应用，如Memcached，redis等。</p>
<p>对于磁盘IO瓶颈可以通过在内存充足时将数据放在更快的内存中来进行优化。也可以进一步利用Trie树等各种算法来进一步优化处理效率。</p>
<h3 id="新工具GET"><a href="#新工具GET" class="headerlink" title="新工具GET"></a>新工具GET</h3><p>查看目录项和各种文件系统索引节点的缓存情况： </p>
<pre><code>cat /proc/slabinfo | slabtop
</code></pre><p>磁盘IO观察</p>
<pre><code>iostat -d -x 1      # -d -x 表示显示所有磁盘I/O的指标
</code></pre><p>进程IO观察</p>
<pre><code>pidstat -d 1

iotop #可以按照I/O大小对进程排序找到I/O较大的进程
</code></pre><p>当strace无法跟踪到文件IO痕迹时</p>
<pre><code>filetop 查看文件名以及使用情况
opensnoop 查看具体的文件目录
</code></pre><p>TCP网络连接可以用过nsenter工具来查看详细信息</p>
<h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><pre><code>find / -name XXX 会不会导致系统的缓存升高？
会，导致inode_cache/dentry/proc_inode_cache/xfs_inode缓存升高
</code></pre><p>可以通过实验进行验证，先清除系统缓存，然后执行命令观察缓存使用情况。</p>
<pre><code>iostat/pidstat已经证明了IO瓶颈是由哪个进程导致，为什么strace跟踪没有发现痕迹？
</code></pre><p>写文件是由子线程来进行处理的，默认strace是不开启线程跟踪的。在strace命令加上-fp选项既可以跟踪进程也可以跟踪线程。</p>
<hr>
<p>接下来是本周读书笔记</p>
<hr>
<h2 id="Lesson-23-Linux文件系统是怎么工作的"><a href="#Lesson-23-Linux文件系统是怎么工作的" class="headerlink" title="Lesson 23 Linux文件系统是怎么工作的"></a>Lesson 23 Linux文件系统是怎么工作的</h2><ul>
<li>磁盘为文件系统提供了最基本的持久化存储</li>
<li>文件系统在磁盘的基础上，提供了一个用来管理文件的树状结构</li>
</ul>
<h3 id="索引节点和目录项"><a href="#索引节点和目录项" class="headerlink" title="索引节点和目录项"></a>索引节点和目录项</h3><p>Linux中一切皆文件。为了方便管理，Linux文件系统为每个文件都分配两个数据结构：</p>
<ul>
<li>索引节点： index node，记录文件的元数据(如inode编号，文件大小，访问权限，修改日期，数据位置等)。索引节点会持久化存储到磁盘中，同样占用磁盘空间。</li>
<li>目录项： directory entry，记录文件的名字，索引节点指针以及与其他目录项的关联关系。目录项是由内核维护的一个内存数据结构，也叫目录项缓存。</li>
</ul>
<p>索引节点是每个文件唯一标志，目录项维护文件系统的树状结构。目录项和索引节点关系是多对一。</p>
<p>磁盘在执行文件系统格式化时，会被分成三个存储区域：</p>
<ul>
<li>超级块，存储整个文件系统的状态</li>
<li>索引节点区，用来存储索引节点</li>
<li>数据块区，用来存储文件数据</li>
</ul>
<h3 id="虚拟文件系统"><a href="#虚拟文件系统" class="headerlink" title="虚拟文件系统"></a>虚拟文件系统</h3><p>目录项、虚拟节点、逻辑块以及超级块构成了Linux文件系统的四大基本要素，为了支持各种不同的文件系统，内核在用户进程和文件系统之间引入了一个虚拟文件系统VFS抽象层。</p>
<p>VFS定义了一组所有文件系统都支持的数据结构和标准接口。这样用户进程和内核中的其他子系统只需要跟VFS提供的统一接口进行交互即可。</p>
<h3 id="文件系统I-O"><a href="#文件系统I-O" class="headerlink" title="文件系统I/O"></a>文件系统I/O</h3><p>根据是否利用标准库缓存，可以分为：</p>
<ul>
<li>缓冲I/O，利用标准库缓存来加速文件的访问，标准库内部再通过系统调度访问文件</li>
<li>非缓冲I/O，直接通过系统调用来访问文件，不再经过标准库缓存</li>
</ul>
<p>根据是否利用系统的页缓存，分为：</p>
<ul>
<li>直接I/O，跳过操作系统的页缓存，直接跟文件系统交互来访问文件  （O_DIRECT）</li>
<li>非直接I/O，文件读写时，先要经过系统的页缓存然后再由内核或额外的系统调用，真正写入磁盘</li>
</ul>
<p>根据应用程序是否阻塞自身运行，分为：</p>
<ul>
<li>阻塞I/O，应用程序执行I/O操作后如果没有获得响应，就会阻塞当前线程</li>
<li>非阻塞I/O，应用程序执行I/O操作后，不会阻塞当前的线程，可以继续执行其他的任务。然后再通过轮询或者事件通知的形式获取调用结果                   （O_NONBLOCK）</li>
</ul>
<p>根据是否响应结果，分为：</p>
<ul>
<li>所谓同步I/O，应用程序执行I/O操作后，要一直等到整个I/O完成后才能获得I/O响应 （O_SYNC/O_DSYNC）</li>
<li>所谓异步I/O，应用程序执行I/O操作后，不用等待完成和完成后的响应，而是继续执行就可以。等这次I/O完成后，响应会用事件通知的方式告诉应用程序 （O_ASYNC）</li>
</ul>
<h3 id="性能观测"><a href="#性能观测" class="headerlink" title="性能观测"></a>性能观测</h3><pre><code>cat /proc/slabinfo | grep -E &apos;^#|dentry|inode&apos;

slabtop
</code></pre><hr>
<h2 id="Lesson-24-25-Linux磁盘I-O时怎么工作的？"><a href="#Lesson-24-25-Linux磁盘I-O时怎么工作的？" class="headerlink" title="Lesson 24/25 Linux磁盘I/O时怎么工作的？"></a>Lesson 24/25 Linux磁盘I/O时怎么工作的？</h2><p>###磁盘<br>磁盘是可以持久化的设备，根据存储介质不同，分为：</p>
<ul>
<li>机械磁盘(Hard Disk Driver)，主要由盘片和读写磁头组成，数据存储在盘片的环状磁道中。读写数据时移动磁头，定位到数据所在的磁道中，然后才能访问。最小读写单位是扇区，一般512byte</li>
<li>固态磁盘(Solid State Disk)，由固态电子元器件组成，不需要磁道寻址。无论连续I/O还是随机I/O都比前者要好。最小读写单位是页，一般4KB，8KB等</li>
</ul>
<p>两种磁盘随机I/O都要比连续I/O慢得多：</p>
<ul>
<li>机械磁盘随机I/O需要更多的磁头寻道和盘片旋转</li>
<li>固态磁盘同样存在“先擦除再写入的限制”，随机读写会导致大量的垃圾回收</li>
<li>连续I/O可以通过预读的方式来减少I/O请求的次数</li>
</ul>
<p>###通用块层</p>
<p>通用块层，是处在文件系统和磁盘驱动中间的一个块设备抽象层。主要有以下功能：</p>
<ul>
<li>与VFS类似，向上为文件系统和应用程序提供块设备的标准接口；向下，把各种异构的磁盘设备抽象为统一的块设备，并提供统一框架来管理这些设备的驱动程序。</li>
<li>给文件系统和应用程序发来的I/O请求排队，并通过重新排序、请求合并等来提升磁盘读写的能力。</li>
</ul>
<p><strong>I/O调度算法</strong>：</p>
<ul>
<li><strong>NONE</strong>，不使用任何I/O调度，常用在虚拟机中</li>
<li><strong>NOOP</strong>，先入先出队列，只进行最基本的请求合并，常用与SSD磁盘</li>
<li><strong>CFQ（Completely Fair Schedule）</strong>，完全公平调度器，为每个进程维护一个I/O调度队列，并按照时间片来均匀分布每个进程的I/O请求。 类似进程CPU调度，CFQ还支持进程I/O的优先级调度，适用于大量进程的系统</li>
<li><strong>Deadline</strong>，分别为读写请求创建不同的I/O队列，提高机械磁盘的吞吐量，并确保达到最终期限的请求被优先处理。多用于IO压力较重的场景，如数据库等</li>
</ul>
<h3 id="IO栈"><a href="#IO栈" class="headerlink" title="IO栈"></a>IO栈</h3><p>Linux存储系统的I/O栈由上到下分为 <strong>文件系统层、通用块层、设备层</strong>。存储系统的IO通常是整个系统最慢的一环，所以Linux系统通过多种缓存机制来优化I/O效率。</p>
<ul>
<li>优化文件访问性能： 页缓存、索引节点缓存、目录项缓存等减少对下层设备的直接调用</li>
<li>优化块设备访问性能：使用缓冲区来缓存块设备的数据</li>
</ul>
<h3 id="磁盘性能指标"><a href="#磁盘性能指标" class="headerlink" title="磁盘性能指标"></a>磁盘性能指标</h3><ul>
<li>使用率， 磁盘处理I/O的时间百分比</li>
<li>饱和度， 磁盘处理I/O的繁忙程度</li>
<li>IOPS， 每秒的I/O请求数</li>
<li>吞吐量， 每秒I/O请求大小</li>
<li>响应时间， I/O请求从发出到收到响应的间隔时间</li>
</ul>
<h3 id="磁盘I-O观测"><a href="#磁盘I-O观测" class="headerlink" title="磁盘I/O观测"></a>磁盘I/O观测</h3><pre><code>iostat -d -x 1      # -d -x 表示显示所有磁盘I/O的指标
</code></pre><h3 id="进程I-O观测"><a href="#进程I-O观测" class="headerlink" title="进程I/O观测"></a>进程I/O观测</h3><pre><code>pidstat -d 1

iotop #可以按照I/O大小对进程排序找到I/O较大的进程
</code></pre><hr>
<h2 id="Lesson-26-案例篇：如何找出狂打日志的内鬼"><a href="#Lesson-26-案例篇：如何找出狂打日志的内鬼" class="headerlink" title="Lesson 26 案例篇：如何找出狂打日志的内鬼"></a>Lesson 26 案例篇：如何找出狂打日志的内鬼</h2><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>首先运行目标应用</p>
<pre><code>sudo docker run -v /tmp:/tmp --name=app -itd feisky/logapp
ps -ef | grep /app.py #确保程序启动
</code></pre><p>我们先用top来观察CPU和内存的使用情况，然后再用iostat来观察磁盘使用情况</p>
<pre><code>top 
#观察发现CPU0使用率高且iowait超过了90%，说明cpu0上正在运行IO密集型程序
#进程方面pythonCPU使用率较高，记录其pid号
#内存使用方面，总内存8G剩余700+M，Buffer/Cache占用较高
</code></pre><p>基本可以判断出CPU使用率中的iowait是一个潜在瓶颈，而内存中的缓存占比较大。<br>再用iostat查看I/O使用情况</p>
<pre><code>iostat -x -d 1 
#发现sda的I/O使用率很高，很可能已经接近饱和
#查看前面指标，每秒写磁盘请求数是64，写大小是32MB，写请求响应时间7s，而请求队列长度则达到了1000+
#超慢的响应时间和请求队列过长，进一步验证了IO已经饱和
</code></pre><p>接下来分析I/O性能瓶颈的根源</p>
<pre><code>pidstat -d 1 
#此时python进程的写比较大，且每秒数据超过了45M，说明python进程导致了IO瓶颈

strace -p XXXX 
#在write()系统调用上，可以看出进程向文件描述符编号为3的文件中写入了300M数据
#再观察后面的stat调用，可以看到它正在获取/tmp/logtest.txt.1的状态，这种格式的文件在日志回滚中常见

losf -p XXXX
#查看进程打开了哪些文件，/tmp/logtest.txt
</code></pre><p>综上说明进程以每次300MB的速度在疯狂的写日志，其中日志文件目录为/tmp/logtest.txt。此时查看案例源码发现其默认记录INFO级别以上的所有日志。此时将默认级别调高到WARNING级别，日志问题即可解决。</p>
<hr>
<h2 id="Lesson-27-案例篇：为什么我的磁盘IO延迟很高？"><a href="#Lesson-27-案例篇：为什么我的磁盘IO延迟很高？" class="headerlink" title="Lesson 27 案例篇：为什么我的磁盘IO延迟很高？"></a>Lesson 27 案例篇：为什么我的磁盘IO延迟很高？</h2><h3 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h3><p>本实验需要两台虚拟机，一台案例分析的目标机器运行Flask应用，另一台作为客户端请求单词的热度。</p>
<pre><code>sudo docker run --name=app -p 10000:80 -itd feisky/word-app
</code></pre><p>然后在第二天机器 curl */popularity/word 发现一直没响应</p>
<p>回第一台机器来分析，首先执行df命令查看文件系统使用情况，发现也要等好久才输出。此时df显示系统还有足够多的磁盘空间。此时同样可以先用top来观察CPU和内存使用情况，再用iostat来观察磁盘的IO情况。</p>
<p>为了避免curl请求结束，在终端2循环执行curl，并用time观察每次执行时间。</p>
<pre><code>while true； do 
    time curl */popularity/word
    sleep 1
done
</code></pre><p>top输出发现两个CPU的iowait都非常高，进程部分python进程的CPU使用率稍高，可能和iowait相关。 记录其pid</p>
<pre><code>ps -aux | grep app.py #正好CPU使用率高的进程是我们的案例应用

iostat -x -d 1 #发现磁盘sda的I/O使用率已经达到98%，写响应时间18s，每秒32MB显然已经达到了IO瓶颈

pidstat -d 1 #再次看到了案例应用pid导致的io瓶颈

strace -p XXX
</code></pre><p>类似上节的套路，此时strace中可以看到大量的stat系统调用，却没有任何write调用。文件写明明应该有响应的write系统调用，现有工具却找不到痕迹。此时就该考虑换工具了，filetop基于eBPF机制，主要跟踪内核中文件的读写情况，并输出线程ID、读写大小、读写类型以及文件名称。</p>
<pre><code>filetop -C #发现每隔一段时间线程号为XXX的python应用会写入大量的txt文件，再大量读。
ps -efT | grep XXX #该线程确实属于我们的应用进程
</code></pre><p>filetop只给出文件名，并没有给出文件路径。此时opensnoop工具登场</p>
<pre><code>opensnoop #可以看到这些txt文件位于/tmp目录下，文件从0.txt到1000.txt
</code></pre><p>结合filetop和opensnoop我们可以猜测案例应用应该是写入1000个txt文件后，又将这些文件内容读取到内存中进行处理。在打断ls检查路径中文件时发现内容为空。此时再次运行opensnoop发现目录变化了，说明这些目录都是应用程序动态生成的，用后就删除了。</p>
<p>接下来查看程序源码发现该案例应用，在每个请求的处理过程中都会生成一批临时文件，然后读入内存处理，最后再删除整个目录。这是一种常见的利用磁盘空间处理大量数据的技巧，不过本次案例中的IO请求太重导致磁盘I/O利用率过高。</p>
<p>通过算法优化，在内存充足时将所有数据放到内存中处理，这样就能避免IO性能问题。</p>
<hr>
<h2 id="Lesson-28-案例篇：一个SQL查询要15s是怎么回事？"><a href="#Lesson-28-案例篇：一个SQL查询要15s是怎么回事？" class="headerlink" title="Lesson 28 案例篇：一个SQL查询要15s是怎么回事？"></a>Lesson 28 案例篇：一个SQL查询要15s是怎么回事？</h2><h3 id="实验-2"><a href="#实验-2" class="headerlink" title="实验"></a>实验</h3><p>案例由3个容器组成，一个mysql数据库应用，一个商品搜索应用，一个数据处理的应用。在执行搜索命令时遇到了返回数据为空且处理时间超过15s的问题。同样通过循环持续发送请求来进行问题问题，为了避免系统压力过大sleep 5s再开始新请求。</p>
<p>同样的套路，top iostat pidstat定位IO瓶颈问题以及mysqld进程。慢查询现象大多是CPU使用率高，但这里看到的却是IO问题，说明这并不是单纯的慢查询问题。</p>
<p>接下来通过strace发现线程XXX正在读取大量数据，且读取文件的描述符编号为38。再用lsof尝试查找对应的文件，此时发现lsof没有任何输出。</p>
<pre><code>echo $? #查找上一条指令退出时返回值，结果为1说明lsof命令执行失败。
</code></pre><p>因为-p需要指定进程号，而我们传入线程号所以执行失败。<br>切换回进程号重新执行lsof命令，从输出可以看出确实mysqld进程打开了大量的文件，根据文件描述符找到对应的文件路径为/var/lib/mysql/test/products.MYD文件。</p>
<p>MYSQL中MYD文件时MyISAM引擎用来存储表数据的文件，文件名就是数据表的名字，父目录即为数据库的名字。 即改文件告诉我们mysqld正在读取test数据库中的products表。</p>
<p>如何确定这些文件是不是mysqld正在使用的数据库文件呢？有没有可能是不再使用的旧数据？我们通过查看mysqld配置的数据路径即可。</p>
<pre><code>sudo docker exec -ti mysql mysql -e &apos;show global variable like &quot;%datadir%&quot;;&apos;
</code></pre><p>可以看到/var/lib/mysql确实是mysqld正在使用的数据存储目录。<br>即然找出了数据库和表，下一步就是弄清楚数据库中正在执行什么样的SQL。</p>
<p>在SQL命令界面执行</p>
<pre><code>show full processlist #可以看到select * from products where productName=‘geektime’这条执行时间比较长
</code></pre><p>一般SQL慢查询问题，很可能是没有利用好索引导致，如何判断这条是不是这样？</p>
<pre><code>explain  select * from products where productName-‘geektime’
</code></pre><p>其中pissible_keys和key都为NULL，type为ALL全表查询，这条查询语句根本没有使用索引，所以查询时会扫描整个表。</p>
<p>因此给productName建立索引即可， 优化后查询时间从15s缩短到了3ms。</p>
<p>该案例中测试时启动了一个DataService应用，其实停止该应用查询时间也能缩短到0.1s。这种情况下是否还存在IO瓶颈呢？通过vmstat来查看IO变化，发现磁盘读和iowait刚开始挺大，但是没过多久就变成了0，说明IO瓶颈消失。为什么呢？</p>
<p>通过查看DataService源码可以看到其读取文件前先将 /proc/sys/vm/drop_caches改为1。即释放文件缓存，而mysql读取的数据就是文件缓存，dataService不断释放缓存导致mysql直接访问磁盘。因此产生IO瓶颈。</p>
<hr>
<h2 id="Lesson-29-案例篇：Redis响应验证延迟，如何解决？"><a href="#Lesson-29-案例篇：Redis响应验证延迟，如何解决？" class="headerlink" title="Lesson 29 案例篇：Redis响应验证延迟，如何解决？"></a>Lesson 29 案例篇：Redis响应验证延迟，如何解决？</h2><h3 id="实验-3"><a href="#实验-3" class="headerlink" title="实验"></a>实验</h3><p>本实验由python应用和redis两部分组成。Python应用是一个基于Flask的应用，会利用Redis来管理应用程序的缓存。</p>
<p>实验中在访问应用程序的缓存接口时，发现10s的长响应时间，接下来定位瓶颈。</p>
<p>同样为了避免分析过程中请求结束，通过loop循环来执行curl命令。</p>
<p>继续先通过top和iostat先分析是否存在IO瓶颈。 结果发现CPU的iowait比较高，但是磁盘每秒写数据为2.5M，IO使用率为0，没有IO瓶颈。</p>
<p>但是案例中测试时从Redis缓存中读取数据，对应应该时磁盘的读操作，iostat结果却显示时写操作。所以我们就要知道是什么进程在具体写磁盘。</p>
<p>运行pidstat -d查看发现是redis-server进程在写磁盘。接下来用strace+lsof查看到底在写什么。从系统调用看epoll_wait、read、write、fdatasync这些系统调用都比较频繁，刚才观察的写操作应该是write和fdatasync导致。lsof找出这些系统调用的操作对象，发现只有7号普通文件会产生磁盘写，其操作路径为/data/appendonly.aof。</p>
<p>在Redis中这对应着持久化配置中的appendonly和appendfsync选项，可能是由于它们配置不合理导致磁盘写较多。为了验证这个猜测，通过redis命令行查这两个选项的配置。</p>
<pre><code>sudo docker exec -ti redis redis-cli config get &apos;append*&apos;
</code></pre><p>发现appendfsync配置为always，appendonly配置为yes。</p>
<p>Redis提供了两种数据持久化方式：</p>
<ul>
<li><strong>快照方式</strong>，按照指定的时间间隔生成数据的快照，并且保存在磁盘文件中。为避免阻塞主进程，Redis会fork一个子进程来进行快照的保存。 无论备份恢复都比追加文件性能好，缺点是在数据量大时fork子进程会用到比较大的内存，保存数据比较耗时。</li>
<li><strong>追加文件</strong>，在文件末尾追加记录的方式对redis写入数据进行持久化。提供appendfsync选项设置fsync策略：<ul>
<li>always， 每个操作都会执行一次fsync，最安全</li>
<li>everysec，每秒钟调用一次fsync，即使最坏情况也只会丢失1s数据</li>
<li>no， 交给操作系统来处理</li>
</ul>
</li>
</ul>
<p>回头看上述测试，因为配置为always导致每次写数据都会调用一次fsync，从而造成比较大的磁盘IO压力。</p>
<p>但是为什么查询会有磁盘写呢，我们再次审视strace和lsof的输出，发现编号为8的TCP socket正好对应TCP读写，是一个标准的“请求-相应”格式。从socket中GET uuid：X后响应good，再从socket中读取SADD good X后响应1。对Redis来说SADD是一个写操作，所以Redis会将其持久化到appendonly.aof文件中。因此产生大量的磁盘读写。</p>
<p>接下来我们确认8号TCPsocket对应的Redis客户端是否为我们的案例应用。 通过lsof -i 找出TCP socket对应的TCP连接信息，进入容器网络命名空间内部看到完成的TCP连接。</p>
<pre><code>PID=$(sudo docker inspect --format {{.State.Pid}} app)
nsenter --target $PID --net -- lsof -i
</code></pre><p>综合分析可知，首先redis配置always不太合理，本案例不需要这么高频的同步写，改为1s时间间隔足够；其次python应用在查询接口中会调用Redis的SADD命令，这很可能是不合理使用缓存导致。</p>
<p>修改配置后请求时间降低到0.9s，接着通过分析源码解决第二个问题。代码中Python应用将Redis当成临时空间，用来存储查询过程中找到的数据。优化将其放在内存中，再次查看响应时间已经降低到了0.2s。</p>
<hr>
<h2 id="Lesson-30-套路篇：如何迅速分析出系统IO瓶颈"><a href="#Lesson-30-套路篇：如何迅速分析出系统IO瓶颈" class="headerlink" title="Lesson 30 套路篇：如何迅速分析出系统IO瓶颈"></a>Lesson 30 套路篇：如何迅速分析出系统IO瓶颈</h2><h3 id="性能指标"><a href="#性能指标" class="headerlink" title="性能指标"></a>性能指标</h3><h4 id="文件系统IO性能指标"><a href="#文件系统IO性能指标" class="headerlink" title="文件系统IO性能指标"></a>文件系统IO性能指标</h4><ul>
<li>存储空间的使用情况，容量、使用量以及剩余空间等<ul>
<li>文件系统向外展示的空间使用，而非磁盘空间的真实用量</li>
<li>索引节点的使用情况，包括容量、使用量以及剩余量 （如果文件系统中存储过多的小文件，就能碰到索引节点容量已满的问题）</li>
</ul>
</li>
<li>缓存使用情况，页缓存、目录项缓存、索引节点缓存以及各个具体文件系统的缓存</li>
<li>文件系统IO， IOPS、响应延迟时间、以及吞吐量</li>
</ul>
<p>Linux文件系统并没有提供直接查看这些指标的方法，只能通过系统调用、动态跟踪或者基准测试的方法来间接观察评估。</p>
<h4 id="磁盘IO性能指标"><a href="#磁盘IO性能指标" class="headerlink" title="磁盘IO性能指标"></a>磁盘IO性能指标</h4><ul>
<li>使用率</li>
<li>IOPS</li>
<li>吞吐量</li>
<li>响应时间</li>
<li>Buffer也常出现在内存和磁盘问题的分析中</li>
</ul>
<h3 id="性能工具"><a href="#性能工具" class="headerlink" title="性能工具"></a>性能工具</h3><ul>
<li><strong>df</strong>，既可以查看文件系统数据的空间容量，也可以查看索引节点的容量</li>
<li><strong>/proc/meminfo，/proc/slabinfo及slaptop</strong>，观察页缓存、目录项缓存、索引节点缓存以及具体的文件系统的缓存</li>
<li><strong>iostat，pidstat</strong>观察磁盘和进程的IO情况<ul>
<li><strong>iostat</strong>查看磁盘的IO使用率、吞吐量、响应时间以及IOPS性能指标</li>
<li><strong>pidstat</strong>查看进程的IO吞吐量以及块设备的IO延迟     </li>
</ul>
</li>
<li><strong>strace+lsof</strong>定位问题进程正在读写的文件</li>
<li><strong>filetop+opensnoop</strong>，从内核中跟踪系统调用，最终找出瓶颈来源</li>
</ul>
<h3 id="性能指标和工具的联系"><a href="#性能指标和工具的联系" class="headerlink" title="性能指标和工具的联系"></a>性能指标和工具的联系</h3><h4 id="根据指标找工具"><a href="#根据指标找工具" class="headerlink" title="根据指标找工具"></a>根据指标找工具</h4><p><img src="/2020/06/21/Linux性能优化实战第四周--IO性能篇/metrictool.png" alt>  </p>
<h4 id="根据工具查指标"><a href="#根据工具查指标" class="headerlink" title="根据工具查指标"></a>根据工具查指标</h4><p><img src="/2020/06/21/Linux性能优化实战第四周--IO性能篇/toolmetric.png" alt>  </p>
<h3 id="如何迅速分析I-O的性能瓶颈"><a href="#如何迅速分析I-O的性能瓶颈" class="headerlink" title="如何迅速分析I/O的性能瓶颈"></a>如何迅速分析I/O的性能瓶颈</h3><ul>
<li>先用iostat发现磁盘IO性能瓶颈</li>
<li>再借助pidstat定位出导致瓶颈的进程</li>
<li>随后分析进程的IO行为</li>
<li>最后结合应用程序的原理，分析这些IO的来源</li>
</ul>
<p>为了缩小排查范围，通常先运行几个支持指标较多的工具，如iostat、vmstat、pidstat等，然后再根据观察到的现象，结合系统和应用程序的原理，寻找下一步的分析方向。</p>
<p>例如MYSQL和Redis案例中，通过iostat确认磁盘出现IO性能瓶颈，然后用pidstat找出I/O最大的进程，接着借助strace找出该进程正在读写的文件，最后结合应用程序的原理找出大量IO的原因。</p>
<p>当用iostat发现磁盘IO性能瓶颈后，再用pidstat和vmstat检查，可能会发现IO来自内核线程。如Swap使用大量升高。这种情况下，就得进行内存分析，先找出占用大量内存的进程，再设法减少内存的使用。</p>
<p><img src="/2020/06/21/Linux性能优化实战第四周--IO性能篇/analysis.png" alt>  </p>
<hr>
<h2 id="Lesson-31-套路篇：-磁盘I-O性能优化的几个思路"><a href="#Lesson-31-套路篇：-磁盘I-O性能优化的几个思路" class="headerlink" title="Lesson 31 套路篇： 磁盘I/O性能优化的几个思路"></a>Lesson 31 套路篇： 磁盘I/O性能优化的几个思路</h2><h3 id="IO基准测试"><a href="#IO基准测试" class="headerlink" title="IO基准测试"></a>IO基准测试</h3><p>为了更客观的评估优化效果，首先应该对磁盘和文件系统进行基准测试，得到文件系统或磁盘IO的极限性能。<br>fio（Flexible I/O Tester）是最常用的基准测试工具</p>
<pre><code># 随机读
fio -name=randread -direct=1 -iodepth=64 -rw=randread -ioengine=libaio -bs=4k -size=1G -numjobs=1 -runtime=1000 -group_reporting -filename=/dev/sdb
# 随机写
fio -name=randwrite -direct=1 -iodepth=64 -rw=randwrite -ioengine=libaio -bs=4k -size=1G -numjobs=1 -runtime=1000 -group_reporting -filename=/dev/sdb
#顺序读
fio -name=read -direct=1 -iodepth=64 -rw=read -ioengine=libaio -bs=4k -size=1G -numjobs=1 -runtime=1000 -group_reporting -filename=/dev/sdb
#顺序写
fio -name=write -direct=1 -iodepth=64 -rw=write -ioengine=libaio -bs=4k -size=1G -numjobs=1 -runtime=1000 -group_reporting -filename=/dev/sdb
</code></pre><ul>
<li>direct表示是否跳过系统缓存，1表示跳过</li>
<li>iodepth表示使用异步I/O（asynchronous I/O）时同时发出的IO请求上限</li>
<li>rw表示I/O模式</li>
<li>ioengine表示I/O引擎，支持同步sync，异步libaio，内存映射mmap，网络net等</li>
<li>bs表示I/O的大小</li>
</ul>
<p>结果报告中</p>
<ul>
<li>slat表示从I/O提交到实际执行I/O的时长。 submission latency</li>
<li>clat表示从I/O提交到I/O完成的时长。 completion latency</li>
<li>lat表示从fio创建IO到IO完成的总时长</li>
</ul>
<p>fio支持I/O的重放，先用blktrace记录磁盘设备的I/O访问情况，然后使用fio重放blktrace的记录。</p>
<pre><code>blktrace /dev/sdb #跟踪磁盘IO
ls #查看blktrace记录的结果
blkparse sdb -d sdb.bin #将结果转化为二进制文件
fio --name=reply --filename=/dev/sdb --direct=1 --read_iolog=sdb.bin #使用fio重放日志
</code></pre><h3 id="I-O性能优化"><a href="#I-O性能优化" class="headerlink" title="I/O性能优化"></a>I/O性能优化</h3><h4 id="应用程序优化"><a href="#应用程序优化" class="headerlink" title="应用程序优化"></a>应用程序优化</h4><ul>
<li>可以用追加写代替随机写，减少寻址开销，加快I/O写的速度</li>
<li>可以借助缓存I/O，充分利用系统缓存，降低实际I/O的次数 </li>
<li>在应用程序内部构建自己的缓存，或者用Redis等外部缓存。一方面能在应用程序内部控制缓存的数据和生命周期，另一方面可以降低其他应用程序使用缓存对自身的影响</li>
<li>需要频繁读写同一块磁盘空间时，可以用mmap代替read/write，减少内存的拷贝次数</li>
<li>在需要写同步的场景中，尽量将写请求合并，即可以用fsync()取代O_SYNC</li>
<li>在多个应用程序共享磁盘时，为了保证I/O不被某个应用完全占用，推荐使用cgroups的I/O子系统来限制进程/进程组的IOPS以及吞吐量</li>
<li>在使用CFQ调度器时，可以用ionice来调整进程的调度优先级，提高核心应用的I/O优先级。</li>
</ul>
<h4 id="文件系统优化"><a href="#文件系统优化" class="headerlink" title="文件系统优化"></a>文件系统优化</h4><ul>
<li>根据实际负载场景不同选择最适合的文件系统</li>
<li>选好文件系统后进一步优化文件系统的配置选项，包括文件系统的特性、日志模式、挂载选项等</li>
<li>优化文件系统的缓存</li>
<li>不需要持久化时可以用内存文件系统tmpfs来获取更好的IO性能。</li>
</ul>
<h4 id="磁盘优化"><a href="#磁盘优化" class="headerlink" title="磁盘优化"></a>磁盘优化</h4><ul>
<li>换用性能更好的磁盘， 如SSD替换HDD</li>
<li>使用RAID将多块磁盘组合成一个逻辑磁盘，构成冗余独立磁盘阵列。既可以提高数据的可靠性，又可以提升数据的访问性能</li>
<li>针对磁盘和应用程序IO模式特征，选择最合适的IO调度算法<ul>
<li>SSD和虚拟机中的磁盘，用noop调度算法</li>
<li>数据库应用，用deadline算法</li>
</ul>
</li>
<li>对应用程序的数据进行磁盘级别的隔离。 为日志、数据库等I/O压力大的应用配置单独的磁盘</li>
<li>顺序读多的场景增大磁盘的预读数据<ul>
<li>调整内核选项/sys/block/sdb/queue/read_ahead_kb， 默认为128KB</li>
<li>blockdev工具设置， blockdev –setra 8192 /dev/sdb， 这里单位为512B</li>
</ul>
</li>
<li>优化块设备的I/O选项<ul>
<li>调整磁盘队列的长度，/sys/block/sdb/queue/nr_requests</li>
</ul>
</li>
</ul>
<p>最后要注意磁盘本身是否存在硬件错误。 可以查看dmesg中是否有硬件I/O故障的日志。还可以用badblocks、smartctl等工具检测磁盘的硬件问题，或者用e2fsck来检测文件系统的错误。 如果发现问题可以用fsck来修复。</p>
<hr>
<h2 id="Lesson-32-答疑-（略）"><a href="#Lesson-32-答疑-（略）" class="headerlink" title="Lesson 32 答疑 （略）"></a>Lesson 32 答疑 （略）</h2><p>捞评论学习：</p>
<ol>
<li>数据写ES，运行一段时间后发现写入很慢，查IO时发现读IO很高写IO很少。用iotop定位es一些写的线程，将线程id转成16进制，用jstack打印出ES的堆栈信息，查处16进程的线程号的堆栈。发现原来时ES会根据doc id查数据，然后选择更新或新插入。ES数据量大时，会占用很多的读IO。 解决方法：写ES时不传入id，让es自动生成来解决。</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2020/06/14/Linux性能优化实战第三周--内存性能篇/" itemprop="url">
                  《Linux 性能优化实战》第三周--内存性能篇
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2020-06-14T10:57:55+08:00" content="2020-06-14">
              2020-06-14
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="个人感悟"><a href="#个人感悟" class="headerlink" title="个人感悟"></a>个人感悟</h2><p>本周主要学习内存性能方面的检测与优化。首先在概念上更加系统的了解了Linux内存的工作原理。进程看到的内存是内核提供的虚拟内存，通过页表映射到实际的物理内存。进程通过malloc申请内存根据页面大小有两种不同的方式，并且内存并不是立即分配而是在首次访问时通过缺页异常在内核态进行分配并更新页表。</p>
<p>通过阅读文档以及实验了解了Buffer和Cache的区别。前者是对磁盘数据的缓存，后者是对文件数据的缓存，且<strong>两者均作用于读写操作</strong>。并掌握cachestat/cachetop/pcstat等工具如何检测系统缓存命中指标，在实验中掌握如何处理缓存异常的场景。</p>
<p>在内存资源紧张时，Linux通过直接回收和定期扫描的方式来释放文件页和匿名页。其中资源是否紧张可以通过内存的三个阈值来判断。另外我们可以手动调整内存资源配置，例如修改 /proc/sys/vm/min_free_kbytes来调整内存阈值，/proc/sys/vm/swappiness来调整文件页和匿名页回收倾向。在NUMA架构下还可以设置/proc/sys/vm/zone_reclaim_node来调整本地内存的回收策略。</p>
<p>当Swap变高时，可以用sar，/proc/zoneinfo，/proc/pid/status等方法查看系统or进程的内存使用情况，进而找到Swap升高的根源和受影响的进程。不过通常我们禁止Swap的使用来提升系统的整体性能：</p>
<ul>
<li>内存足够大时，禁用Swap</li>
<li>实在需要Swap时，可以尝试降低swapiness的值，减少回收时Swap的使用倾向</li>
<li>响应延迟敏感的应用，可以用mlock/mlockall来锁定内存，禁止内存换出</li>
</ul>
<p>之前在搭建组内K8S环境时按照教程都是先关闭Swap，不明所以。现在通过这周的学习才真正了解到缘由。</p>
<p>本周对内存使用情况监测所用的主要工具有：</p>
<ul>
<li>常用性能工具： free/top/ps，vmstat观察内存变化情况</li>
<li>查看缓存命中情况： bcc包中的cachestat和cachetop，基于Linux内核的eBPF(extend Berkeley Packet Filters)来跟踪内核中管理的缓存<ul>
<li>cachestat 查看整个操作系统缓存的读写命中情况</li>
<li>cachetop 提供了每个进程的缓存命中情况 </li>
</ul>
</li>
<li>跟踪内存分配/释放： memleak    </li>
<li>查看内存各个指标变化： sar</li>
</ul>
<p>对于系统内存问题的分析与定位，通常先运行几个覆盖面比较大的性能工具，如free，top，vmstat，pidstat等</p>
<ul>
<li>先用free和top查看系统整体内存使用情况</li>
<li>再用vmstat和pidstat，查看一段时间的趋势，从而判断内存问题的类型</li>
<li>最后进行详细分析，比如内存分配分析，缓存/缓冲区分析，具体进程的内存使用分析等 </li>
</ul>
<p><img src="/2020/06/14/Linux性能优化实战第三周--内存性能篇/analysis.png" alt> </p>
<p>以及一些常见的优化思路：</p>
<ul>
<li>最好禁止Swap，若必须开启则尽量降低swappiness的值</li>
<li>减少内存的动态分配，如可以用内存池，HugePage等</li>
<li>尽量使用缓存和缓冲区来访问数据。如用堆栈明确声明内存空间来存储需要缓存的数据，或者用Redis外部缓存组件来优化数据的访问</li>
<li>cgroups等方式来限制进程的内存使用情况，确保系统内存不被异常进程耗尽</li>
<li>/proc/pid/oom_adj调整核心应用的oom_score，保证即使内存紧张核心应用也不会被OOM杀死 </li>
</ul>
<p>另外，在探索问题的过程中由于性能指标较多，我们不可能记住所有指标的详细含义，网上搜索有时并不能得到真正准确的答案，因此养成查文档的爱好非常重要。</p>
<hr>
<p>接下来是本周读书笔记</p>
<hr>
<h2 id="Lesson-15-Linux内存是怎么工作的"><a href="#Lesson-15-Linux内存是怎么工作的" class="headerlink" title="Lesson 15 Linux内存是怎么工作的"></a>Lesson 15 Linux内存是怎么工作的</h2><h3 id="内存映射"><a href="#内存映射" class="headerlink" title="内存映射"></a>内存映射</h3><p>大多数计算机用的主存都是动态随机访问内存(DRAM)，只有内核才可以直接访问物理内存。Linux内核给每个进程提供了一个独立的虚拟地址空间，并且这个地址空间是连续的。这样进程就可以很方便的访问内存(虚拟内存)。</p>
<p>虚拟地址空间的内部分为内核空间和用户空间两部分，不同字长的处理器地址空间的范围不同。32位系统内核空间占用1G，用户空间占3G。 64位系统内核空间和用户空间都是128T，分别占内存空间的最高和最低处，中间部分为未定义。</p>
<p>并不是所有的虚拟内存都会分配物理内存，只有实际使用的才会。分配后的物理内存通过内存映射管理。为了完成内存映射，内核为每个进程都维护了一个页表，记录虚拟地址和物理地址的映射关系。页表实际存储在CPU的内存管理单元MMU中，处理器可以直接通过硬件找出要访问的内存。</p>
<p>当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入内核空间分配物理内存，更新进程页表，再返回用户空间恢复进程的运行。</p>
<p>MMU以页为单位管理内存，页大小4KB。为了解决页表项过多问题Linux提供了<strong>多级页表</strong>和<strong>HugePage</strong>的机制。</p>
<h3 id="虚拟内存空间分布"><a href="#虚拟内存空间分布" class="headerlink" title="虚拟内存空间分布"></a>虚拟内存空间分布</h3><p>从图中可以看出用户空间内存从低到高是五种不同的内存段：</p>
<ul>
<li><strong>只读段</strong> 代码和常量等</li>
<li><strong>数据段</strong> 全局变量等</li>
<li><strong>堆</strong> 动态分配的内存，从低地址开始向上增长</li>
<li><strong>文件映射</strong> 动态库、共享内存等，从高地址开始向下增长</li>
<li><strong>栈</strong> 包括局部变量和函数调用的上下文等，栈的大小是固定的。一般8MB</li>
</ul>
<h3 id="内存分配与回收"><a href="#内存分配与回收" class="headerlink" title="内存分配与回收"></a>内存分配与回收</h3><h4 id="分配"><a href="#分配" class="headerlink" title="分配"></a>分配</h4><p>malloc对应到系统调用上有两种实现方式：</p>
<ul>
<li><strong>brk()</strong> 针对小块内存(&lt;128K)，通过移动堆顶位置来分配。内存释放后不立即归还内存，而是被缓存起来。</li>
<li><strong>mmap()</strong>针对大块内存(&gt;128K)，直接用内存映射来分配，即在文件映射段找一块空闲内存分配。</li>
</ul>
<p>前者的缓存可以减少缺页异常的发生，提高内存访问效率。但是由于内存没有归还系统，在内存工作繁忙时，频繁的内存分配/释放会造成内存碎片。</p>
<p>后者在释放时直接归还系统，所以每次mmap都会发生缺页异常。在内存工作繁忙时，频繁内存分配会导致大量缺页异常，使内核管理负担增加。</p>
<p>上述两种调用并没有真正分配内存，这些内存只有在首次访问时，才通过缺页异常进入内核中，由内核来分配。</p>
<h4 id="回收"><a href="#回收" class="headerlink" title="回收"></a>回收</h4><p>内存紧张时，系统通过以下方式来回收内存：</p>
<ul>
<li>回收缓存： LRU算法回收最近最少使用的内存页面；</li>
<li>回收不常访问内存： 把不常用的内存通过交换分区写入磁盘</li>
<li><p>杀死进程： OOM内核保护机制 （进程消耗内存越大oom_score越大，占用CPU越多oom_score越小，可以通过/proc手动调整oom_adj） </p>
<pre><code>echo -16 &gt; /proc/$(pidof XXX)/oom_adj
</code></pre></li>
</ul>
<h3 id="如何查看内存使用情况"><a href="#如何查看内存使用情况" class="headerlink" title="如何查看内存使用情况"></a>如何查看内存使用情况</h3><p>free来查看整个系统的内存使用情况</p>
<p>top/ps来查看某个进程的内存使用情况</p>
<ul>
<li><strong>VIRT</strong> 进程的虚拟内存大小</li>
<li><strong>RES</strong> 常驻内存的大小，即进程实际使用的物理内存大小，不包括swap和共享内存</li>
<li><strong>SHR</strong> 共享内存大小，与其他进程共享的内存，加载的动态链接库以及程序代码段</li>
<li><strong>%MEM</strong> 进程使用物理内存占系统总内存的百分比 </li>
</ul>
<hr>
<h2 id="Lesson-16-怎样理解内存中的Buffer和Cache？"><a href="#Lesson-16-怎样理解内存中的Buffer和Cache？" class="headerlink" title="Lesson 16 怎样理解内存中的Buffer和Cache？"></a>Lesson 16 怎样理解内存中的Buffer和Cache？</h2><h3 id="free数据来源"><a href="#free数据来源" class="headerlink" title="free数据来源"></a>free数据来源</h3><p>在free手册中可以看到buffer和cache的定义，但是并不能直观帮助我们理解</p>
<pre><code>buffers： Memory used by kernel buffers (Buffers in /proc/meminfo)
cache: Memory used by the page cache and slabs (Cache and Sreclaimable in /proc/meminfo)
</code></pre><h3 id="proc文件系统"><a href="#proc文件系统" class="headerlink" title="proc文件系统"></a>proc文件系统</h3><p>接着看proc文件系统中的文档可以看到： Buffers是对原始磁盘块的临时存储，也就是用来缓存磁盘的数据(通常不会特别大)。Cached是从磁盘读取文件的页缓存，用来缓存从文件中读取的数据。Slab包括可回收和不可回收两部分。</p>
<pre><code>Buffers %lu: Relatively temporary storage for raw disk blocks that shouldn&apos;t get tremendously large (20MB or so)    

Cached %lu: In-memory cache for files read from the disk(the page cache). Doesn&apos;t include SwapCached.

SReclaimable %lu: Part of Slab, that might be reclaimed, such as ceches.

Sunreclaim %lu: Part of Slab, that cannot bt reclaimed on memory pressure.
</code></pre><h3 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h3><p><strong>该实验对环境要求较高，需要系用配置多块磁盘，并且分区/dev/sdb1处于未使用状态。如果不满足千万不要尝试，否则会对磁盘分区造成损坏</strong></p>
<p>首先安装sysstat包，然后清理系统缓存</p>
<pre><code>echo 3 &gt; /proc/sys/vm/drop_caches
</code></pre><h4 id="场景1-磁盘和文件写案例"><a href="#场景1-磁盘和文件写案例" class="headerlink" title="场景1 磁盘和文件写案例"></a>场景1 磁盘和文件写案例</h4><pre><code>vmstat 1 #空闲情况下查看系统内存使用情况
dd if=/dev/urandom of=/tmp/file bs=1M count=500 #通过读取随机设备，生产一个500MB大小的文件
#此时观察vmstat，发现cache在不断增长，但是Buffer基本保持不变
#Cache开始增长时，块设备IO很少，dd命令结束后cache不再增长，但块设备写还会持续一段时间

echo 3 &gt;/proc/sys/vm/drop_caches
dd if=/dev/urandom of=/dev/sdb1 bs=1M count=2048 #清理缓存后向磁盘分区写入2GB的随机数据
#此时观察vmstat输出，发现写磁盘会时buffer和cache都在增长，但是buffer增长快得多
</code></pre><p>通过该案例可以看出写文件时会用到cache缓存数据，写磁盘时会用到buffer来缓存数据。</p>
<h4 id="场景2-磁盘和文件读案例"><a href="#场景2-磁盘和文件读案例" class="headerlink" title="场景2 磁盘和文件读案例"></a>场景2 磁盘和文件读案例</h4><pre><code>echo 3 &gt; /proc/sys/vm/drop_caches
dd if=/tmp/file of=/dev/null
#观察vmstat输出，发现读取文件时buffer保持不变，cache不停增长

echo 3 &gt;/proc/sys/vm/drop_caches
dd if=/dev/sda1 of=/dev/null bs=1M count=1024
#观察vmstat发现读磁盘时，buffer和cache都在增长，但是buffer增长快得多
</code></pre><p><strong>通过上述实验可以看出buffer是对磁盘数据的缓存，cache是对文件数据的缓存，它们既会用在读请求也会用在写请求中。</strong></p>
<hr>
<h2 id="Lesson-17-如何利用系统缓存优化程序的运行效率"><a href="#Lesson-17-如何利用系统缓存优化程序的运行效率" class="headerlink" title="Lesson 17 如何利用系统缓存优化程序的运行效率"></a>Lesson 17 如何利用系统缓存优化程序的运行效率</h2><h3 id="缓存命中率"><a href="#缓存命中率" class="headerlink" title="缓存命中率"></a>缓存命中率</h3><p><strong>缓存命中率</strong>是指直接通过缓存获取数据的请求次数，占所有请求次数的百分比。<strong>命中率越高说明缓存带来的收益越高，应用程序的性能也就越好。</strong></p>
<p>安装bcc包后可以通过cachestat和cachetop来监测缓存的读写命中情况。</p>
<p>安装pcstat后可以查看文件在内存中的缓存大小以及缓存比例。</p>
<pre><code>#首先安装Go
export GOPATH=~/go
export PATH=~/go/bin:$PATH
go get golang.org/x/sys/unix
go ge github.com/tobert/pcstat/pcstat
</code></pre><h3 id="实验案例一-dd缓存加速"><a href="#实验案例一-dd缓存加速" class="headerlink" title="实验案例一 dd缓存加速"></a>实验案例一 dd缓存加速</h3><pre><code>dd if=/dev/sda1 of=file bs=1M count=512 #生产一个512MB的临时文件
echo 3 &gt; /proc/sys/vm/drop_caches #清理缓存
pcstat file #确定刚才生成文件不在系统缓存中，此时cached和percent都是0
cachetop 5
dd if=file of=/dev/null bs=1M #测试文件读取速度
#此时文件读取性能为30+MB/s，查看cachetop结果发现并不是所有的读都落在磁盘上，读缓存命中率只有50%。
dd if=file of=/dev/null bs=1M #重复上述读文件测试
#此时文件读取性能为4+GB/s，读缓存命中率为100%
pcstat file #查看文件file的缓存情况，100%全部缓存
</code></pre><p>实验表明系统缓存对第二次dd命令有明显的加速效果，大大提高了文件读取的性能。同时要注意如果我们把dd作为性能测试工具时，由于缓存存在会导致测试结果严重失真。</p>
<h3 id="实验案例二-O-DIRECT选项绕过系统缓存"><a href="#实验案例二-O-DIRECT选项绕过系统缓存" class="headerlink" title="实验案例二 O_DIRECT选项绕过系统缓存"></a>实验案例二 O_DIRECT选项绕过系统缓存</h3><pre><code>cachetop 5
sudo docker run --privileged --name=app -itd feisky/app:io-direct
sudo docker logs app #确认案例启动成功
#实验结果表明每读32MB数据都要花0.9s，且cachetop输出中显示1024次缓存全部命中
</code></pre><p>但是凭感觉可知如果缓存命中读速度不应如此慢，读次数时1024，页大小为4K，五秒的时间内读取了1024*4KB数据，即每秒0.8MB，和结果中32MB相差较大。说明该案例没有充分利用缓存，怀疑系统调用设置了直接I/O标志绕过系统缓存。因此接下来观察系统调用</p>
<pre><code>strace -p $(pgrep app)
#strace 结果可以看到openat打开磁盘分区/dev/sdb1，传入参数为O_RDONLY|O_DIRECT
</code></pre><p>这就解释了为什么读32MB数据那么慢，直接从磁盘读写肯定远远慢于缓存。找出问题后我们再看案例的源代码发现flags中指定了直接IO标志。删除该选项后重跑，验证性能变化。</p>
<hr>
<h2 id="Lesson-18-内存泄漏，如何定位和处理？"><a href="#Lesson-18-内存泄漏，如何定位和处理？" class="headerlink" title="Lesson 18 内存泄漏，如何定位和处理？"></a>Lesson 18 内存泄漏，如何定位和处理？</h2><p>对应用程序来说，动态内存的分配和回收是核心又复杂的一个逻辑功能模块。管理内存的过程中会发生各种各样的“事故”：</p>
<ul>
<li>没正确回收分配的内存，导致了泄漏</li>
<li>访问的是已分配内存边界外的地址，导致程序异常退出</li>
<li>…</li>
</ul>
<h3 id="内存的分配与回收"><a href="#内存的分配与回收" class="headerlink" title="内存的分配与回收"></a>内存的分配与回收</h3><p>在Lesson15中我们了解到了虚拟内存分布从低到高分别是<strong>只读段，数据段，堆，内存映射段，栈</strong>五部分。其中会导致内存泄漏的是：</p>
<ul>
<li>堆： 由应用程序自己来分配和管理，除非程序退出这些堆内存不会被系统自动释放。</li>
<li>内存映射段：包括动态链接库和共享内存，其中共享内存由程序自动分配和管理</li>
</ul>
<p><strong>内存泄漏的危害比较大，这些忘记释放的内存，不仅应用程序自己不能访问，系统也不能把它们再次分配给其他应用。</strong> 内存泄漏不断累积甚至会耗尽系统内存。</p>
<h3 id="实验-如何检测内存泄漏"><a href="#实验-如何检测内存泄漏" class="headerlink" title="实验 如何检测内存泄漏"></a>实验 如何检测内存泄漏</h3><p>预先安装systat，docker，bcc</p>
<pre><code>sudo docker run --name=app -itd feisky/app:mem-leak
sudo docker logs app
vmstat 3
</code></pre><p>可以看到free在不断下降，buffer和cache基本保持不变。说明系统的内存一致在升高。但并不能说明存在内存泄漏。此时可以通过memleak工具来跟踪系统或进程的内存分配/释放请求。</p>
<pre><code>/usr/share/bcc/tools/memleak -a -p $(pidof app)
</code></pre><p>从memleak输出可以看到，应用在不停地分配内存，并且这些分配的地址并没有被回收。通过调用栈看到是fibonacci函数分配的内存没有释放。定位到源码后查看源码来修复增加内存释放函数即可。</p>
<p>另外，在该实验中也可以通过将动态分配的内存改为数组来避免内存泄漏的问题，数据放在栈中由系统自动分配与回收。</p>
<hr>
<h2 id="Lesson-19-20-为什么系统的Swap变高"><a href="#Lesson-19-20-为什么系统的Swap变高" class="headerlink" title="Lesson 19/20 为什么系统的Swap变高"></a>Lesson 19/20 为什么系统的Swap变高</h2><p>系统内存资源紧张时通过内存回收和OOM杀死进程来解决。其中可回收内存包括：</p>
<ul>
<li>缓存/缓冲区，属于可回收资源，在文件管理中通常叫做文件页<ul>
<li>被应用程序修改过暂时没写入磁盘的数据(脏页)，要先写入磁盘然后才能内存释放<ul>
<li>在应用程序中通过fsync将脏页同步到磁盘</li>
<li>交给系统，内核线程pdflush负责这些脏页的刷新</li>
</ul>
</li>
</ul>
</li>
<li>内存映射获取的文件映射页，也可以被释放掉，下次访问时从文件重新读取</li>
</ul>
<p>对于程序自动分配的堆内存，也就是我们在内存管理中的匿名页，虽然这些内存不能直接释放，但是Linux提供了Swap机制将不常访问的内存写入到磁盘来释放内存，再次访问时从磁盘读取到内存即可。</p>
<h3 id="Swap原理"><a href="#Swap原理" class="headerlink" title="Swap原理"></a>Swap原理</h3><p>Swap本质就是把一块磁盘空间或者一个本地文件当作内存来使用，包括换入和换出两个过程：</p>
<ul>
<li>换出： 将进程暂时不用的内存数据存储到磁盘中，并释放这些内存</li>
<li>换入： 进程再次访问内存时，将它们从磁盘读到内存中</li>
</ul>
<p>Linux如何衡量内存资源是否紧张？</p>
<ul>
<li><strong>直接内存回收</strong> 新的大块内存分配请求，但剩余内存不足。此时系统会回收一部分内存；</li>
<li><p><strong>kswapd0</strong> 内核线程定期回收内存。为了衡量内存使用情况，定义了pages_min,pages_low,pages_high三个阈值，并根据其来进行内存的回收操作。</p>
<ul>
<li>剩余内存 &lt; pages_min，进程可用内存耗尽了，只有内核才可以分配内存</li>
<li>pages_min &lt; 剩余内存 &lt; pages_low,内存压力较大，kswapd0执行内存回收，直到剩余内存 &gt; pages_high</li>
<li>pages_low &lt; 剩余内存 &lt; pages_high，内存有一定压力，但可以满足新内存请求</li>
<li><p>剩余内存 &gt; pages_high，说明剩余内存较多，无内存压力</p>
<p>pages_low = pages_min <em> 5 / 4<br>pages_high = pages_min </em> 3 / 2</p>
</li>
</ul>
</li>
</ul>
<h3 id="NUMA-与-SWAP"><a href="#NUMA-与-SWAP" class="headerlink" title="NUMA 与 SWAP"></a>NUMA 与 SWAP</h3><p>很多情况下系统剩余内存较多，但SWAP依旧升高，这是由于处理器的NUMA架构。</p>
<p>在NUMA架构下多个处理器划分到不同的Node，每个Node都拥有自己的本地内存空间。在分析内存的使用时应该针对每个Node单独分析。</p>
<pre><code>numactl --hardware #查看处理器在Node的分布情况，以及每个Node的内存使用情况
</code></pre><p>内存三个阈值可以通过/proc/zoneinfo来查看，该文件中还包括活跃和非活跃的匿名页/文件页数。</p>
<p>当某个Node内存不足时，系统可以从其他Node寻找空闲资源，也可以从本地内存中回收内存。 通过/proc/sys/vm/zone_raclaim_mode来调整。</p>
<ul>
<li>0表示既可以从其他Node寻找空闲资源，也可以从本地回收内存</li>
<li>1，2，4表示只回收本地内存，2表示可以会回脏数据回收内存，4表示可以用Swap方式回收内存。</li>
</ul>
<h3 id="swappiness"><a href="#swappiness" class="headerlink" title="swappiness"></a>swappiness</h3><p>在实际回收过程中Linux根据/proc/sys/vm/swapiness选项来调整使用Swap的积极程度，从0-100，数值越大越积极使用Swap，即更倾向于回收匿名页；数值越小越消极使用Swap，即更倾向于回收文件页。</p>
<p><strong>注意：这只是调整Swap积极程度的权重，即使设置为0，当剩余内存+文件页小于页高阈值时，还是会发生Swap。</strong></p>
<h3 id="实验-Swap升高时如何定位分析"><a href="#实验-Swap升高时如何定位分析" class="headerlink" title="实验 Swap升高时如何定位分析"></a>实验 Swap升高时如何定位分析</h3><pre><code>free #首先通过free查看swap使用情况，若swap=0表示未配置Swap
#先创建并开启swap
fallocate -l 8G /mnt/swapfile
chmod 600 /mnt/swapfile
mkswap /mnt/swapfile
swapon /mnt/swapfile

free #再次执行free确保Swap配置成功

dd if=/dev/sda1 of=/dev/null bs=1G count=2048 #模拟大文件读取
sar -r -S 1  #查看内存各个指标变化 -r内存 -S swap
#根据结果可以看出，%memused在不断增长，剩余内存kbmemfress不断减少，缓冲区kbbuffers不断增大，由此可知剩余内存不断分配给了缓冲区
#一段时间之后，剩余内存很小，而缓冲区占用了大部分内存。此时Swap使用之间增大，缓冲区和剩余内存只在小范围波动

停下sar命令
cachetop5 #观察缓存
#可以看到dd进程读写只有50%的命中率，未命中数为4w+页，说明正式dd进程导致缓冲区使用升高
watch -d grep -A 15 ‘Normal’ /proc/zoneinfo #观察内存指标变化
#发现升级内存在一个小范围不停的波动，低于页低阈值时会突然增大到一个大于页高阈值的值
</code></pre><p>说明剩余内存和缓冲区的波动变化正是由于内存回收和缓存再次分配的循环往复。有时候Swap用的多，有时候缓冲区波动更多。此时查看swappiness值为60，是一个相对中和的配置，系统会根据实际运行情况来选去合适的回收类型。</p>
<hr>
<h2 id="Lesson-21-套路篇：如何“快准狠”找到系统内存存在的问题"><a href="#Lesson-21-套路篇：如何“快准狠”找到系统内存存在的问题" class="headerlink" title="Lesson 21 套路篇：如何“快准狠”找到系统内存存在的问题"></a>Lesson 21 套路篇：如何“快准狠”找到系统内存存在的问题</h2><h3 id="内存性能指标"><a href="#内存性能指标" class="headerlink" title="内存性能指标"></a>内存性能指标</h3><p><strong>系统内存指标</strong></p>
<ul>
<li>已用内存/剩余内存</li>
<li>共享内存 （tmpfs实现）</li>
<li>可用内存： 包括剩余内存和可回收内存</li>
<li>缓存：磁盘读取文件的页缓存，slab分配器中的可回收部分</li>
<li>缓冲区： 原始磁盘块的临时存储，缓存将要写入磁盘的数据</li>
</ul>
<p><strong>进程内存指标</strong></p>
<ul>
<li>虚拟内存： 5大部分</li>
<li>常驻内存： 进程实际使用的物理内存，不包括Swap和共享内存</li>
<li>共享内存： 与其他进程共享的内存，以及动态链接库和程序的代码段</li>
<li>Swap内存： 通过Swap换出到磁盘的内存</li>
</ul>
<p><strong>缺页异常</strong></p>
<ul>
<li>可以直接从物理内存中分配，次缺页异常</li>
<li>需要磁盘IO介入(如Swap)，主缺页异常。 此时内存访问会慢很多</li>
</ul>
<h3 id="内存性能工具"><a href="#内存性能工具" class="headerlink" title="内存性能工具"></a>内存性能工具</h3><p>根据不同的性能指标来找合适的工具:<br><img src="/2020/06/14/Linux性能优化实战第三周--内存性能篇/metric_tool.png" alt> </p>
<p>内存分析工具包含的性能指标:<br><img src="/2020/06/14/Linux性能优化实战第三周--内存性能篇/tool_metric.png" alt> </p>
<h3 id="如何迅速分析内存的性能瓶颈"><a href="#如何迅速分析内存的性能瓶颈" class="headerlink" title="如何迅速分析内存的性能瓶颈"></a>如何迅速分析内存的性能瓶颈</h3><p>通常先运行几个覆盖面比较大的性能工具，如free，top，vmstat，pidstat等</p>
<ul>
<li>先用free和top查看系统整体内存使用情况</li>
<li>再用vmstat和pidstat，查看一段时间的趋势，从而判断内存问题的类型</li>
<li>最后进行详细分析，比如内存分配分析，缓存/缓冲区分析，具体进程的内存使用分析等</li>
</ul>
<p>常见的优化思路：</p>
<ul>
<li>最好禁止Swap，若必须开启则尽量降低swappiness的值</li>
<li>减少内存的动态分配，如可以用内存池，HugePage等</li>
<li>尽量使用缓存和缓冲区来访问数据。如用堆栈明确声明内存空间来存储需要缓存的数据，或者用Redis外部缓存组件来优化数据的访问</li>
<li>cgroups等方式来限制进程的内存使用情况，确保系统内存不被异常进程耗尽</li>
<li>/proc/pid/oom_adj调整核心应用的oom_score，保证即使内存紧张核心应用也不会被OOM杀死 </li>
</ul>
<h2 id="Lesson-22-答疑-（略）"><a href="#Lesson-22-答疑-（略）" class="headerlink" title="Lesson 22 答疑 （略）"></a>Lesson 22 答疑 （略）</h2>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2020/06/03/Linux性能优化实战第二周--CPU性能篇(下)/" itemprop="url">
                  《Linux 性能优化实战》第二周--CPU性能篇(下)
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2020-06-03T22:57:55+08:00" content="2020-06-03">
              2020-06-03
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="个人感悟"><a href="#个人感悟" class="headerlink" title="个人感悟"></a>个人感悟</h2><p>这两周主要围绕CPU性能优化相关基础知识进行学习。对于CPU性能问题的处理，首先我们要了解CPU相关性能指标。</p>
<h3 id="CPU性能指标"><a href="#CPU性能指标" class="headerlink" title="CPU性能指标"></a>CPU性能指标</h3><p><strong>平均负载,上下文切换,CPU使用率,CPU缓存命中率</strong>等.</p>
<p><strong>平均负载</strong>是指系统处于可运行状态和不可中断状态的平均进程数（一般平均负载高于CPU数量70%的时候需要注意排查）。 平均负载升高可能是<strong>CPU密集进程</strong>导致,也可能是<strong>I/O</strong>或<strong>进程过多超负载</strong>导致. 可以用<strong>mpstat</strong>和<strong>pidstat</strong>辅助分析.</p>
<pre><code>uptime #查看最近1/5/15分钟平均负载
watch -d uptime #实时查看变化情况
mpstat -P ALL 5 #查看CPU使用率,间隔5秒输出
pidstat -u 5 1  #查看进程CPU使用率/IOwait
</code></pre><p><strong>上下文切换</strong>,主要分为进程上下文切换,线程上下文切换以及中断上下文切换（可以利用多线程替代多进程来提升性能）。可以通过vmstat查看系统总体上下文切换和中断次数. pidstat -w 查看每个进程上下文切换次数, -wt输出线程指标.</p>
<pre><code>watch -d cat /proc/interrupts #查看中断变化具体来源
</code></pre><ul>
<li>系统调用涉及内核态和用户态的切换因此实际发生两次CPU上下文切换,不过不涉及虚拟内存等资源也不切换进程. </li>
<li>进程的切换都在内核态,保存内核状态和CPU寄存器之前,先保存进程的虚拟内存,栈等 </li>
<li>同一进程内的线程切换只需要保存线程的私有数据,寄存器等.</li>
<li>中断上下文切换并不涉及进程的用户态,比进程优先级高</li>
</ul>
<p><strong>CPU使用率</strong>过高时一般都是结合top/pidstat/perf来进行分析定位. 如果定位不到CPU使用率高的进程,可以跟踪top查看是否存在短时进程. 调用pstree分析父进程. </p>
<pre><code>perf record -g
perf report #查看性能报告找到瓶颈

execsnoop #监控短时进程
</code></pre><p><strong>iowait</strong>升高时,可以用dstat观察CPU和I/O的使用情况. </p>
<pre><code>pidstat -d -p XXX n m  #-d输出I/O情况,指定线程号间隔n秒输出m组数据
strace -p XXX #跟踪系统调用
如果定位进程状态为Z,通过perf report查看调用栈
</code></pre><p><strong>僵尸进程</strong>, 通过pstree查看父进程,在父进程中进行解决(子进程创建和清理的地方)</p>
<pre><code>pstree -aps XXX
</code></pre><p><strong>中断处理</strong></p>
<pre><code>/proc/softirqs #查看软中断
/proc/interrupts #查看硬中断
</code></pre><p><strong>网络监测工具</strong></p>
<pre><code>sar -n DEV 1 #网络收发报告, 间隔1秒输出一组数据
tcpdump -i eth0 -n tcp port 80 #指定网卡eth0,tcp协议,端口号80
</code></pre><h3 id="CPU性能分析套路"><a href="#CPU性能分析套路" class="headerlink" title="CPU性能分析套路"></a>CPU性能分析套路</h3><p>通过几组实验分析我们发现对于CPU性能，常用的瓶颈问题有一些套路可以定位问题所在。虽然CPU性能指标很多，但是都不是孤立存在的，很多指标间都存在一定的关联。 再遇到CPU性能问题时我们可以先运行几个支持指标较多的工具(top/vmstat/pidstat)来缩小排查范围，查看是否是因为某个进程导致，找出导致性能问题的进程之后，再用进程分析工具来分析进程的行为。比如strace分析系统调用情况，或者perf分析调用链中各级函数的执行情况。 </p>
<h3 id="CPU性能优化方案"><a href="#CPU性能优化方案" class="headerlink" title="CPU性能优化方案"></a>CPU性能优化方案</h3><p>定位到问题所在之后并不是要立即着手进行优化。在需要优化之前,要先考虑优化到底能提升多少性能(应用程序和系统资源多维度评估),选取哪些性能问题进行优化以及优化方案的取舍. 优化往往会带来复杂度的提升,所以要做好性能和复杂度的平衡.</p>
<p><strong>CPU优化的一些常用方法</strong></p>
<ul>
<li>应用程序优化<ul>
<li>编译器优化</li>
<li>算法优化</li>
<li>异步处理</li>
<li>多线程代替多进程</li>
<li>善用缓存</li>
</ul>
</li>
<li>系统优化<ul>
<li>CPU绑定</li>
<li>CPU独占</li>
<li>优先级调整</li>
<li>为进程设置资源限制</li>
<li>NUMA优化</li>
<li>中断负载均衡</li>
</ul>
</li>
</ul>
<hr>
<p>接下来是本周读书笔记</p>
<hr>
<h2 id="Lesson-9-怎么理解Linux软中断"><a href="#Lesson-9-怎么理解Linux软中断" class="headerlink" title="Lesson 9 怎么理解Linux软中断"></a>Lesson 9 怎么理解Linux软中断</h2><p>本周继续学习CPU性能相关知识点,<a href="http://xiaozhazi.github.io/2020/05/31/Linux性能优化实战第一周--CPU性能篇%28上%29">Linux 性能优化实战第一周</a>第8课提到不可中断状态一般都是短时进程,主要是系统的一种保护机制,保证硬件的交互过程不被意外打断. 但是如果进程长时间处于不可中断状态就需要注意是否存在磁盘I/O问题.</p>
<p>除了iowait,软中断softirq导致CPU使用率增加的场景也比较常见.</p>
<p>为了解决中断处理程序执行时间过长和中断丢失的问题,Linux将中断过程分为两阶段:</p>
<ul>
<li><strong>快速处理中断</strong> (硬中断, 会打断CPU正在执行的任务)</li>
<li><strong>延迟处理上半部未完成的工作, 通常以内核线程的方式运行</strong> (软中断,内核线程执行)</li>
</ul>
<p>以网卡接收数据包为例: 网卡接收到数据包之后,先通过硬中断通知内核新数据到达.此时内核调用中断处理程序来响应. 第一步快速处理中断,将网卡数据读到内存中,然后更新硬件寄存器的状态(表示数据已经读完); 第二步发送软中断信号,内核线程从内存中找到网络数据,按照网络协议栈对数据逐层解析和处理,直到将其发送给应用程序.</p>
<p>软中断不仅包括上述硬件设备中断处理程序的第二阶段,还包含一些内核自定义的事件. 如内核调度,RCU锁等.</p>
<pre><code>~ cat /proc/softirqs   #查看软中断的运行情况　10种不同软中断类型
                CPU0       CPU1       CPU2       CPU3       
      HI:     940848    8695970     929219     958387
   TIMER:    6032528    8523080    6185804    7882723
  NET_TX:         13         18         10      21655
  NET_RX:      81303      81483      74123    5497701
   BLOCK:        112        109    1961852         73
IRQ_POLL:          0          0          0          0
 TASKLET:         40        152      69233      41556
   SCHED:    5262219    6279886    5054733    5849054
 HRTIMER:          0          0          0          0
     RCU:    4615615    5897520    4693046    5749548

➜  ~ ps -aux | grep softirq #一个CPU对应一个软中断内核线程
  root         7  0.0  0.0      0     0 ?        S    Jun01   0:00 [ksoftirqd/0]
  root        16  0.0  0.0      0     0 ?        S    Jun01   0:01 [ksoftirqd/1]
  root        22  0.0  0.0      0     0 ?        S    Jun01   0:01 [ksoftirqd/2]
  root        28  0.0  0.0      0     0 ?        S    Jun01   0:02 [ksoftirqd/3]
</code></pre><hr>
<h2 id="Lesson-10-系统的软中断CPU使用率高，怎么解决"><a href="#Lesson-10-系统的软中断CPU使用率高，怎么解决" class="headerlink" title="Lesson 10 系统的软中断CPU使用率高，怎么解决"></a>Lesson 10 系统的软中断CPU使用率高，怎么解决</h2><h3 id="所需工具"><a href="#所需工具" class="headerlink" title="所需工具"></a>所需工具</h3><table>
<thead>
<tr>
<th>工具</th>
<th>用途</th>
</tr>
</thead>
<tbody>
<tr>
<td>sar</td>
<td>系统报告工具,实时查看当前系统活动,配置保存和报告历史统计</td>
</tr>
<tr>
<td>hping3</td>
<td>构造TCP/IP包, 对系统进行安全审计,防火墙测试等</td>
</tr>
<tr>
<td>tcpdump</td>
<td>网络抓包工具, 用来分析各种网络问题</td>
</tr>
</tbody>
</table>
<h3 id="实验与分析"><a href="#实验与分析" class="headerlink" title="实验与分析"></a>实验与分析</h3><pre><code>sudo docker run -itd --name=nginx -p 81:80 nginx  #启动nginx服务
curl http://localhost:81  #检查nginx服务是否正常运行

hping3 -S -p 81 -i u100 localhost    #每100微秒发送一个网络帧
</code></pre><p>本机测试中并没有监测到系统响应变慢,改为1微秒时数据包全丢, 10微秒时丢包率为80%.</p>
<p>top查看ksoftirqd软中断进程CPU使用率也不高.</p>
<p>继续执行后续指令</p>
<pre><code>watch -d cat /proc/softirqs #观察高亮变化
</code></pre><p>此时发现TIMER/NET_RX/SCHED/RCU都在不停变化,且NET_RX变化速率较快,几K级别的在增加. 其它几种类型的软中断是保证linux调度,时钟,临界区保护等正常工作必须,有变化是正常的. </p>
<p>因此我们着手分析网络接收的软中断,选取sar工具查看网络收发情况</p>
<pre><code>sar -n DEV 1  #每隔1秒输出网络收发报告

07:01:11 PM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s rxcmp/s   txcmp/s  rxmcst/s   %ifutil
07:01:12 PM veth3a2b4de      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
07:01:12 PM        lo  20895.00  20895.00    843.42    843.42      0.00      0.00      0.00      0.00
07:01:12 PM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
07:01:12 PM enp0s31f6      6.00      0.00      0.85      0.00      0.00      0.00      0.00      0.00
07:01:12 PM vethedb691a      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
07:01:12 PM br-1665f3682889      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
</code></pre><ul>
<li>rxpck/s txpck/s　表示每秒接收/发送的网络帧数　　PPS</li>
<li>rxkB/s  txkB/s　　表示每秒接收/发送的千字节数　BPS　</li>
</ul>
<p>看到网卡lo每秒接收的数据明显较多，　843*1024/20895 =41　说明每个网络帧只有41字节，小包问题．</p>
<p>进一步通过tcpdump分析这是什么样的网络帧</p>
<pre><code>tcpdump -i lo -n tcp port 81

18:20:43.273056 IP 127.0.0.1.12537 &gt; 127.0.0.1.81: Flags [R], seq 393134060, win 0, length 0
18:20:43.273184 IP 127.0.0.1.12538 &gt; 127.0.0.1.81: Flags [S], seq 1240632262, win 512, length 0
18:20:43.273193 IP 127.0.0.1.81 &gt; 127.0.0.1.12538: Flags [S.], seq 3698133257, ack 1240632263, win 65495, options [mss 65495], length 0
18:20:43.273198 IP 127.0.0.1.12538 &gt; 127.0.0.1.81: Flags [R], seq 1240632263, win 0, length 0
</code></pre><p>可以看出网络帧是发送到nginx端口，Flags [S]表示这是一个ＳＹＮ包，　可以锁定是SYN FLOOD问题，最简单的解决方法就是防火墙中封锁该来源ＩＰ．</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>如果碰到软中断线程CPU使用率高的情况下, 可以借助sar和tcpdump等工具进一步分析来源.</p>
<hr>
<h2 id="Lesson-11-套路-如何迅速分析出系统CPU的瓶颈在哪里"><a href="#Lesson-11-套路-如何迅速分析出系统CPU的瓶颈在哪里" class="headerlink" title="Lesson 11 [套路] 如何迅速分析出系统CPU的瓶颈在哪里?"></a>Lesson 11 [套路] 如何迅速分析出系统CPU的瓶颈在哪里?</h2><p>要想分析处理CPU性能问题, 首先我们需要了解CPU性能指标.</p>
<h3 id="CPU性能指标-1"><a href="#CPU性能指标-1" class="headerlink" title="CPU性能指标"></a>CPU性能指标</h3><p><img src="/2020/06/03/Linux性能优化实战第二周--CPU性能篇(下)/performance_metric.png" alt> </p>
<ul>
<li>CPU使用率<ul>
<li>用户CPU使用率, 包括用户态(user)和低优先级用户态(nice). 该指标过高说明应用程序比较繁忙.</li>
<li>系统CPU使用率, CPU在内核态运行的时间百分比(不含中断). 该指标高说明内核比较繁忙.</li>
<li>等待I/O的CPU使用率, iowait, 该指标高说明系统与硬件设备I/O交互时间比较长.</li>
<li>软/硬中断CPU使用率, 该指标高说明系统中发生大量中断.</li>
<li>steal CPU / guest CPU, 表示虚拟机占用的CPU百分比.</li>
</ul>
</li>
<li><p>平均负载</p>
<p>  理想情况下平均负载等于逻辑CPU个数,表示每个CPU都被充分利用. 若大于则说明系统负载较重.</p>
</li>
<li><p>进程上下文切换</p>
<p>  包括无法获取资源的自愿切换和系统强制调度时的非自愿切换. 上下文切换本身是保证Linux正常运行的一项核心功能. 过多的切换则会将原本运行进程的CPU时间消耗在寄存器,内核占及虚拟内存等数据保存和恢复上.</p>
</li>
<li><p>CPU缓存命中率</p>
<p>  CPU缓存的复用情况,命中率越高性能越好. 其中L1/L2常用在单核,L3则用在多核中.</p>
</li>
</ul>
<p><img src="/2020/06/03/Linux性能优化实战第二周--CPU性能篇(下)/cache.png" alt>  </p>
<h3 id="性能工具"><a href="#性能工具" class="headerlink" title="性能工具"></a>性能工具</h3><p>回顾之前的几个CPU性能测试场景:</p>
<ul>
<li>平均负载案例<ul>
<li>先用uptime查看系统平均负载</li>
<li>判断负载在升高后再用mpstat和pidstat分别查看每个CPU和每个进程CPU使用情况.找出导致平均负载较高的进程. </li>
</ul>
</li>
<li>上下文切换案例<ul>
<li>先用vmstat查看系统上下文切换和中断次数</li>
<li>再用pidstat观察进程的自愿和非自愿上下文切换情况</li>
<li>最后通过pidstat观察线程的上下文切换情况</li>
</ul>
</li>
<li>进程CPU使用率高案例<ul>
<li>先用top查看系统和进程的CPU使用情况,定位到进程</li>
<li>再用perf top观察进程调用链,定位到具体函数</li>
</ul>
</li>
<li>系统CPU使用率高案例<ul>
<li>先用top查看系统和进程的CPU使用情况,top/pidstat都无法找到CPU使用率高的进程</li>
<li>重新审视top输出</li>
<li>从CPU使用率不高,但是处于Running状态的进程入手</li>
<li>perf record/report发现短时进程导致 (execsnoop工具)</li>
</ul>
</li>
<li>不可中断和僵尸进程案例<ul>
<li>先用top观察iowait升高,发现大量不可中断和僵尸进程</li>
<li>strace无法跟踪进程系统调用</li>
<li>perf分析调用链发现根源来自磁盘直接I/O</li>
</ul>
</li>
<li>软中断案例<ul>
<li>top观察系统软中断CPU使用率高</li>
<li>查看/proc/softirqs找到变化速率较快的几种软中断</li>
<li>sar命令发现是网络小包问题</li>
<li>tcpdump找出网络帧的类型和来源, 确定SYN FLOOD攻击导致</li>
</ul>
</li>
</ul>
<p>根据不同的性能指标来找合适的工具:<br><img src="/2020/06/03/Linux性能优化实战第二周--CPU性能篇(下)/performance_tool.png" alt> </p>
<p>在生产环境中往往开发者没有权限安装新的工具包,只能最大化利用好系统中已经安装好的工具. 因此要了解一些主流工具能够提供哪些指标分析.</p>
<p><img src="/2020/06/03/Linux性能优化实战第二周--CPU性能篇(下)/performance_tool_1.png" alt> </p>
<p>作者给了一个直观的套路, 先运行几个支持指标较多的工具, 如top/vmstat/pidstat,根据它们的输出可以得出是哪种类型的性能问题. 定位到进程后再用strace/perf分析调用情况进一步分析. 如果是软中断导致用/proc/softirqs</p>
<p><img src="/2020/06/03/Linux性能优化实战第二周--CPU性能篇(下)/normal_tool.png" alt> </p>
<hr>
<h2 id="Lesson-12-CPU性能优化的几个思考"><a href="#Lesson-12-CPU性能优化的几个思考" class="headerlink" title="Lesson 12 CPU性能优化的几个思考"></a>Lesson 12 CPU性能优化的几个思考</h2><h3 id="性能优化方法论"><a href="#性能优化方法论" class="headerlink" title="性能优化方法论"></a>性能优化方法论</h3><p>遇到性能问题,优化前首先思考三个问题:</p>
<ul>
<li>首先判断优化是否有效,能提升多少性能?</li>
<li>多种性能问题同时存在情况下,先优化哪一个?</li>
<li>提升性能的方法往往不唯一,如何选取? 是否总选最大程度提升的那一种?</li>
</ul>
<h3 id="怎样评估性能优化效果"><a href="#怎样评估性能优化效果" class="headerlink" title="怎样评估性能优化效果"></a>怎样评估性能优化效果</h3><ul>
<li>确定性能的量化指标<ul>
<li>不要局限在单一维度,至少从应用程序和系统资源两个维度,分别选择不同的指标<ul>
<li>应用程序: 吞吐量和请求延迟</li>
<li>系统资源: CPU使用率</li>
</ul>
</li>
<li>好的应用程序是性能优化的最终目的和结果,系统资源的使用情况是影响应用程序性能的根源.</li>
<li>例如, web程序可以用ab等工具测试并发请求数和响应延迟,同时可以用vmstat/pidstat观察系统和进程的CPU使用率 </li>
</ul>
</li>
<li>测试优化前的性能指标</li>
<li>测试优化后的性能指标<ul>
<li>要避免性能测试工具的干扰</li>
<li>避免外部环境的变化</li>
</ul>
</li>
</ul>
<h3 id="多个性能问题同时存在-如何选择"><a href="#多个性能问题同时存在-如何选择" class="headerlink" title="多个性能问题同时存在,如何选择?"></a>多个性能问题同时存在,如何选择?</h3><p><strong>并不是所有性能问题都值得优化,性能测试也存在二八法则</strong></p>
<ul>
<li>如果是系统资源达到的瓶颈,首先优化系统资源的使用问题.</li>
<li>针对不同类型的指标,首先优化那些由瓶颈导致,性能指标变化幅度较大的问题.</li>
</ul>
<h3 id="多个优化方法-如何选择"><a href="#多个优化方法-如何选择" class="headerlink" title="多个优化方法, 如何选择?"></a>多个优化方法, 如何选择?</h3><p>在提升性能的同时也要考虑优化成本.性能优化通常会带来复杂度的提升,降低程序的可维护性. (balance)</p>
<p>例如DPDK(Data Plane Development Kit)是一种优化网络处理速度的方法,通过绕开内核网络协议栈的方法,提升网络的处理能力. 但是它要求独占一个CPU以及一定数量的内存大页,并且以100%CPU使用率运行. 在CPU核数较少的情况下不适合.</p>
<h3 id="CPU-优化"><a href="#CPU-优化" class="headerlink" title="CPU 优化"></a>CPU 优化</h3><ul>
<li>应用程序优化<ul>
<li>编译器优化: 编译阶段开启优化选项, 如gcc -O2</li>
<li>算法优化</li>
<li>异步处理: 避免程序因为等待某个资源而一直阻塞,提升程序的并发处理能力. (将轮询替换为事件通知)</li>
<li>多线程代替多进程: 减少上下文切换成本</li>
<li>善用缓存: 加快程序处理速度</li>
</ul>
</li>
<li>系统优化<ul>
<li>CPU绑定: 将进程绑定要1个/多个CPU上,提高CPU缓存命中率,减少CPU调度带来的上下文切换</li>
<li>CPU独占: CPU亲和性机制来分配进程</li>
<li>优先级调整:使用nice适当降低非核心应用的优先级</li>
<li>为进程设置资源显示: cgroups设置使用上限,防止由某个应用自身问题耗尽系统资源</li>
<li>NUMA优化: CPU尽可能访问本地内存</li>
<li>中断负载均衡: irpbalance,将中断处理过程自动负载均衡到各个CPU上</li>
</ul>
</li>
</ul>
<h3 id="避免过早优化"><a href="#避免过早优化" class="headerlink" title="避免过早优化"></a>避免过早优化</h3><p>优化可能会带来复杂性的提升,降低可维护性.针对当前情况进行的优化可能不适应快递迭代的新需求. </p>
<p>因此性能优化最好逐步完善,根据性能评估的结果选择最重要的性能问题进行优化.</p>
<h2 id="Lesson-13-14-答疑-略"><a href="#Lesson-13-14-答疑-略" class="headerlink" title="Lesson 13/14 答疑 (略)"></a>Lesson 13/14 答疑 (略)</h2><h2 id="读书群内分享"><a href="#读书群内分享" class="headerlink" title="读书群内分享"></a>读书群内分享</h2><ul>
<li><p><a href="https://blog.csdn.net/u010889616/article/details/83245695" target="_blank" rel="external">TPS QPS 系统吞吐量的区别和理解</a></p>
<ul>
<li>QPS (Queries Per Second)每秒查询率,一台服务器每秒能够响应的查询次数.</li>
<li><p>TPS (Transactions Per Second)每秒事务数,软件测试的结果.</p>
<ul>
<li>用户请求服务器</li>
<li>服务器内部处理</li>
<li><p>服务器返回给客户</p>
<p>QPS类似TPS,但是对于一个页面的访问形成一个TPS,但是一次页面请求可能包含多次对服务器的请求,可能计入多次QPS</p>
</li>
</ul>
</li>
<li><p>系统吞吐量, 包括几个重要参数:</p>
<ul>
<li>QPS(TPS)</li>
<li>并发数</li>
<li><p>响应时间</p>
<p>QPS(TPS)=并发数/平均相应时间</p>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="https://www.cnblogs.com/cute/archive/2011/04/20/2022280.html" target="_blank" rel="external">深入理解Linux系统下proc文件系统内容</a></li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2020/05/31/Linux性能优化实战第一周--CPU性能篇(上)/" itemprop="url">
                  《Linux 性能优化实战》第一周--CPU性能篇(上)
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2020-05-31T22:57:55+08:00" content="2020-05-31">
              2020-05-31
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>首先，非常感谢Go夜读杨文大佬组织了这样一个读书会， 可以让大家在繁忙的工作生活之余抽出时间来一起学习进步。希望能和群里小伙伴共同讨论学习，一起坚持下去。</p>
<p>第一本严格意义上并不是书籍，而是极客时间上倪老师的专栏《Linux性能优化实战》。无论是软件业务逻辑还是底层架构实现，我们在设计时都要尽可能的考虑性能开销，性能优化是软件系统中最有挑战的工作之一，比较考验程序员的综合能力。</p>
<p>在平时工作中我也会经常遇到一些性能相关的问题，不知如何排查和解决。希望读完这个专栏后能真正做到<strong>将性能问题和系统原理关联起来，特别是把系统从应用程序、库函数、系统调用再到内核和硬件等不同的层级贯穿起来</strong>。</p>
<hr>
<h2 id="Lesson-1-如何学习Linux性能优化"><a href="#Lesson-1-如何学习Linux性能优化" class="headerlink" title="Lesson 1 如何学习Linux性能优化"></a>Lesson 1 如何学习Linux性能优化</h2><p>解决性能问题首先需要理解应用程序和系统的少数几个基本原理，再<strong>进行大量的实战练习</strong>，建立起整体性能的全局观。</p>
<h3 id="性能指标"><a href="#性能指标" class="headerlink" title="性能指标"></a>性能指标</h3><p>高并发和响应快对应着性能优化的两个核心指标：<strong>吞吐</strong>和<strong>延时</strong>。</p>
<p><img src="/2020/05/31/Linux性能优化实战第一周--CPU性能篇(上)/week1_1.png" alt>  </p>
<ul>
<li><strong>应用负载</strong>角度：直接影响了产品终端的用户体验</li>
<li><strong>系统资源</strong>角度：资源使用率、饱和度等 </li>
</ul>
<p><strong>性能问题的本质</strong>就是系统资源已经到达瓶颈，但请求的处理还不够快，无法支撑更多的请求。 性能分析实际上就是找出应用或系统的瓶颈，设法去避免或缓解它们。</p>
<ul>
<li>选择指标评估应用程序和系统性能</li>
<li>为应用程序和系统设置性能目标</li>
<li>进行性能基准测试</li>
<li>性能分析定位瓶颈</li>
<li>性能监控和告警</li>
</ul>
<p>对于不同的性能问题要选取不同的性能分析工具。 下面是常用的Linux Performance Tools以及对应分析的性能问题类型。</p>
<p><img src="/2020/05/31/Linux性能优化实战第一周--CPU性能篇(上)/LinuxPerformanceTool.png" alt>  </p>
<h3 id="学习重点"><a href="#学习重点" class="headerlink" title="学习重点"></a>学习重点</h3><p>建立整体系统性能的全局观：</p>
<ul>
<li>理解最基本的几个系统知识原理</li>
<li>掌握必要的性能工具</li>
<li>通过实际的场景演练，贯穿不同的组件。</li>
</ul>
<hr>
<h2 id="Lesson-2-到底应该怎么理解“平均负载”"><a href="#Lesson-2-到底应该怎么理解“平均负载”" class="headerlink" title="Lesson 2 到底应该怎么理解“平均负载”"></a>Lesson 2 到底应该怎么理解“平均负载”</h2><p><strong>平均负载：</strong>单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数。它和我们传统意义上理解的CPU使用率并没有直接关系。</p>
<p>其中不可中断进程是正处于内核态关键流程中的进程（如常见的等待设备的I/O响应）。<strong>不可中断状态实际上是系统对进程和硬件设备的一种保护机制。</strong></p>
<h3 id="平均负载多少时合理"><a href="#平均负载多少时合理" class="headerlink" title="平均负载多少时合理"></a>平均负载多少时合理</h3><p>实际生产环境中将系统的平均负载监控起来，根据历史数据判断负载的变化趋势。当负载存在明显升高趋势时，及时进行分析和调查。 当然也可以当设置阈值（如当平均负载高于CPU数量的70%时）</p>
<p>现实工作中我们会经常混淆平均负载和CPU使用率的概念，其实两者并不完全对等：</p>
<ul>
<li>CPU密集型进程，大量CPU使用会导致平均负载升高，此时两者一致</li>
<li>I/O密集型进程，等待I/O也会导致平均负载升高，此时CPU使用率并不一定高</li>
<li>大量等待CPU的进程调度会导致平均负载升高，此时CPU使用率也会比较高</li>
</ul>
<h3 id="平均负载案例分析"><a href="#平均负载案例分析" class="headerlink" title="平均负载案例分析"></a>平均负载案例分析</h3><p>分别对上述三种场景进行分析，使用的工具为<strong>iostat，mpstat，pidstat</strong></p>
<p>其中还用到了Linux系统压力测试工具<strong>stress</strong></p>
<h4 id="CPU密集型进程"><a href="#CPU密集型进程" class="headerlink" title="CPU密集型进程"></a>CPU密集型进程</h4><pre><code>stress --cpu 1 --timeout 600 #模拟CPU使用率100%
watch -d uptime              #查看平均负载变化情况
mpstat -P ALL 5              #查看CPU使用率的变化情况
</code></pre><p>此实验中，CPU使用率为100%，但是iowait只有0，说明平均负载高是由CPU使用率导致</p>
<pre><code>pidstat -u 5 1               #可以查看具体哪个进程导致了CPU使用率高
</code></pre><h4 id="I-O密集型进程"><a href="#I-O密集型进程" class="headerlink" title="I/O密集型进程"></a>I/O密集型进程</h4><pre><code>stress -i 1 --timeout 600    #模拟I/O压力，不停地执行sync
watch -d uptime              #查看平均负载变化情况
mpstat -P ALL 5 1              #查看CPU使用率的变化情况
</code></pre><p>此实验中，CPU使用率为23%，而iowait高达67%，说明平均负载高是由iowait升高导致</p>
<pre><code>pidstat -u 5 1               #可以查看具体哪个进程导致了iowait高
</code></pre><h4 id="大量进程"><a href="#大量进程" class="headerlink" title="大量进程"></a>大量进程</h4><pre><code>stress -c 8 --timeout 600    #模拟8进程（高于CPU核数）
watch -d uptime              #查看平均负载变化情况
mpstat -P ALL S              #查看CPU使用率的变化情况
</code></pre><p>此实验中，CPU严重过载，8个进程在抢占CPU，导致平均负载升高</p>
<pre><code>pidstat -u 5 1               #可以查看具体哪个进程导致了CPU使用率高
</code></pre><p>###总结<br> <strong>平均负载高时可能是CPU密集型进程导致，也可能是I/O繁忙导致。具体分析时可以结合mpstat/pidstat工具辅助分析负载来源。</strong></p>
<hr>
<h2 id="Lesson-3-经常说的CPU上下文切换是什么意思？-上"><a href="#Lesson-3-经常说的CPU上下文切换是什么意思？-上" class="headerlink" title="Lesson 3 经常说的CPU上下文切换是什么意思？(上)"></a>Lesson 3 经常说的CPU上下文切换是什么意思？(上)</h2><p><strong>CPU上下文切换</strong>，就是把前一个任务的CPU上下文（CPU寄存器和PC）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的位置，运行新任务。其中，保存下来的上下文会存储在系统内核中，待任务重新调度执行时再加载，保证原来的任务状态不受影响。</p>
<p>按照任务类型，CPU上下文切换分为：</p>
<ul>
<li>进程上下文切换</li>
<li>线程上下文切换</li>
<li>中断上下文切换</li>
</ul>
<h3 id="进程上下文切换"><a href="#进程上下文切换" class="headerlink" title="进程上下文切换"></a>进程上下文切换</h3><p>Linux进程按照等级权限将进程的运行空间分为内核空间和用户空间。从用户态向内核态转变时需要通过系统调用来完成。</p>
<p>一次系统调用过程其实进行了两次CPU上下文切换：</p>
<ul>
<li>CPU寄存器中用户态的指令位置先保存起来，CPU寄存器更新为内核态指令的位置，跳转到内核态运行内核任务；</li>
<li>系统调用结束后，CPU寄存器恢复原来保存的用户态数据，再切换到用户空间继续运行。</li>
</ul>
<p>系统调用过程中并不会涉及虚拟内存等进程用户态资源，也不会切换进程。和传统意义上的进程上下文切换不同。因此<strong>系统调用通常称为特权模式切换</strong>。</p>
<p>进程是由内核管理和调度的，进程上下文切换只能发生在内核态。 因此相比系统调用来说，在保存当前进程的内核状态和CPU寄存器之前，需要先把该进程的虚拟内存，栈保存下来。再加载新进程的内核态后，还要刷新进程的虚拟内存和用户栈。</p>
<p>进程只有在调度到CPU上运行时才需要切换上下文，有以下几种场景： CPU时间片轮流分配，系统资源不足导致进程挂起，进程通过sleep函数主动挂起，高优先级进程抢占时间片，硬件中断时CPU上的进程被挂起转而执行内核中的中断服务。</p>
<h3 id="线程上下文切换"><a href="#线程上下文切换" class="headerlink" title="线程上下文切换"></a>线程上下文切换</h3><p>线程上下文切换分为两种：</p>
<ul>
<li>前后线程同属于一个进程，切换时虚拟内存资源不变，只需要切换线程的私有数据，寄存器等；</li>
<li>前后线程属于不同进程，与进程上下文切换相同。</li>
</ul>
<p>同进程的线程切换消耗资源较少，这也是多线程的优势。</p>
<h3 id="中断上下文切换"><a href="#中断上下文切换" class="headerlink" title="中断上下文切换"></a>中断上下文切换</h3><p>中断上下文切换并不涉及到进程的用户态，因此中断上下文只包括内核态中断服务程序执行所必须的状态（CPU寄存器，内核堆栈，硬件中断参数等）。</p>
<p><strong>中断处理优先级比进程高，所以中断上下文切换和进程上下文切换不会同时发生。</strong></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><strong>尽量在程序中使用多线程，因为多线程上下文切换资源消耗较少。</strong></p>
<hr>
<h2 id="Lesson-4-经常说的CPU上下文切换是什么意思？-下"><a href="#Lesson-4-经常说的CPU上下文切换是什么意思？-下" class="headerlink" title="Lesson 4 经常说的CPU上下文切换是什么意思？(下)"></a>Lesson 4 经常说的CPU上下文切换是什么意思？(下)</h2><p>通过vmstat可以查看系统总体的上下文切换情况。</p>
<pre><code>vmstat 5         #每隔5s输出一组数据
</code></pre><ul>
<li>cs （context switch）     每秒上下文切换次数</li>
<li>in （interrupt）          每秒中断次数</li>
<li>r （runnning or runnable）就绪队列的长度，正在运行和等待CPU的进程数</li>
<li>b （Blocked）             处于不可中断睡眠状态的进程数</li>
</ul>
<p>要查看每个进程的详细情况，需要使用pidstat来查看每个进程上下文切换情况</p>
<pre><code>pidstat -w 5
</code></pre><ul>
<li>cswch   每秒自愿上下文切换次数 （进程无法获取所需资源导致的上下文切换）</li>
<li>nvcswch 每秒非自愿上下文切换次数 （时间片轮流等系统强制调度）</li>
</ul>
<h3 id="实验分析"><a href="#实验分析" class="headerlink" title="实验分析"></a>实验分析</h3><pre><code>vmstat 1 1    #首先获取空闲系统的上下文切换次数
sysbench --threads=10 --max-time=300 threads run #模拟多线程切换问题

vmstat 1 1    #新终端观察上下文切换情况
此时发现cs数据明显升高，同时观察其他指标：
r列： 远超系统CPU个数，说明存在大量CPU竞争
us和sy列： sy列占比80%，说明CPU主要被内核占用
in列： 中断次数明显上升，说明中断处理也是潜在问题
</code></pre><p>综合以上分析，说明运行/等待CPU的进程过多，导致大量的上下文切换，上下文切换导致系统的CPU占用率高。</p>
<pre><code>pidstat -w -u 1  #查看到底哪个进程导致的问题
</code></pre><p>从结果中看出是sysbench导致CPU使用率过高，但是pidstat输出的上下文次数加起来也并不多。分析sysbench模拟的是线程的切换，因此需要在pidstat后加-t参数查看线程指标。</p>
<p>另外对于中断次数过多，我们可以通过/proc/interrupts文件读取</p>
<pre><code>watch -d cat /proc/interrupts
</code></pre><p>发现次数变化速度最快的是重调度中断（RES），该中断用来唤醒空闲状态的CPU来调度新的任务运行。分析还是因为过多任务的调度问题，和上下文切换分析一致。</p>
<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p><strong>每秒上下文切换多少才正常呢？</strong><br><strong>经验来说，当每秒上下文切换超过1w次，或者切换次数出现数量级的增长时，系统可能出现了性能问题。此时可以根据上下文切换类型来具体分析是I/O问题还是CPU瓶颈，或者具体哪一类中断导致的异常。</strong></p>
<hr>
<h2 id="Lesson-5-某个应用的CPU使用率达到100-，怎么办？"><a href="#Lesson-5-某个应用的CPU使用率达到100-，怎么办？" class="headerlink" title="Lesson 5 某个应用的CPU使用率达到100%，怎么办？"></a>Lesson 5 某个应用的CPU使用率达到100%，怎么办？</h2><p>Linux作为多任务操作系统，将CPU时间划分为很短的时间片，通过调度器轮流分配给各个任务使用。为了维护CPU时间，Linux通过事先定义的节拍率，触发时间中断，并使用全局变了jiffies记录开机以来的节拍数。时间中断发生一次该值+1.</p>
<p><strong>CPU使用率</strong>，除了空闲时间以外的其他时间占总CPU时间的百分比。可以通过/proc/stat中的数据来计算出CPU使用率。因为/proc/stat时开机以来的节拍数累加值，计算出来的是开机以来的平均CPU使用率，一般意义不大。可以间隔取一段时间的两次值作差来计算该段时间内的平均CPU使用率。 <strong>性能分析工具给出的都是间隔一段时间的平均CPU使用率，要注意间隔时间的设置。</strong></p>
<p>CPU使用率可以通过top 或 ps来查看。分析进程的CPU问题可以通过perf，它以性能事件采样为基础，不仅可以分析系统的各种事件和内核性能，还可以用来分析指定应用程序的性能问题。</p>
<p>perf top / perf record / perf report （-g 开启调用关系的采样）</p>
<h3 id="实验案例"><a href="#实验案例" class="headerlink" title="实验案例"></a>实验案例</h3><pre><code>sudo docker run --name nginx -p 10000:80 -itd feisky/nginx
sudo docker run --name phpfpm -itd --network container:nginx feisky/php-fpm

ab -c 10 -n 100 http://XXX.XXX.XXX.XXX:10000/ #测试Nginx服务性能
</code></pre><p>发现此时每秒可承受请求给长少，此时将测试的请求数从100增加到10000。 在另外一个终端运行top查看每个CPU的使用率。发现系统中几个php-fpm进程导致CPU使用率骤升。</p>
<p>接着用perf来分析具体是php-fpm中哪个函数导致该问题。</p>
<pre><code>perf top -g -p XXXX #对某一个php-fpm进程进行分析
</code></pre><p>发现其中sqrt和add_function占用CPU过多， 此时查看源码找到原来是sqrt中在发布前没有删除测试代码段，存在一个百万次的循环导致。 将该无用代码删除后发现nginx负载能力明显提升。</p>
<h3 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h3><p><strong>在碰到CPU使用率过高问题时，可以借助top pidstat确定引发CPU性能问题的来源，然后用perf来具体定位到引起性能问题的函数。可以用来代码性能进一步优化。</strong></p>
<hr>
<h2 id="Lesson-6-系统的CPU使用率很高，为什么找不到高CPU的应用？"><a href="#Lesson-6-系统的CPU使用率很高，为什么找不到高CPU的应用？" class="headerlink" title="Lesson 6 系统的CPU使用率很高，为什么找不到高CPU的应用？"></a>Lesson 6 系统的CPU使用率很高，为什么找不到高CPU的应用？</h2><p>按照上篇的CPU性能问题分析套路，看起来CPU使用率问题很容易排查，真实场景中却不然。</p>
<h3 id="实验案例分析"><a href="#实验案例分析" class="headerlink" title="实验案例分析"></a>实验案例分析</h3><pre><code>sudo docker run --name nginx -p 10000:80 -itd feisky/nginx:sp
sudo docker run --name phpfpm -itd --network container:nginx feisky/php-fpm:sp
ab -c 100 -n 1000 http://XXX.XXX.XXX.XXX:10000/ #并发100个请求测试
</code></pre><p>实验结果中每秒请求数依旧不高，我们将并发请求数降为5后，nginx负载能力依旧很低。</p>
<p>此时用top和pidstat发现系统CPU使用率过高，但是并没有发现CPU使用率高的进程。</p>
<p>出现这种情况一般时我们分析时遗漏的什么信息，重新运行top命令并观察一会。发现就绪队列中处于Running状态的进行过多，超过了我们的并发请求次数5. 再仔细查看进程运行数据，发现nginx和php-fpm都处于sleep状态，真正处于运行的却是几个stress进程。</p>
<p>下一步就利用pidstat分析这几个stress进程，发现没有任何输出。用ps aux交叉验证发现依旧不存在该进程。说明不是工具的问题。再top查看发现stress进程的进程号变化了，此时有可能时以下两种原因导致：</p>
<ul>
<li>进程不停的崩溃重启（如段错误/配置错误等），此时进程退出后可能又被监控系统重启；</li>
<li>短时进程导致，即其他应用内部通过exec调用的外面命令，这些命令一般只运行很短时间就结束，很难用top这种间隔较长的工具来发现</li>
</ul>
<p>可以通过pstree来查找 stress的父进程，找出调用关系。</p>
<pre><code>pstree | grep stress
</code></pre><p>发现是php-fpm调用的该子进程，此时去查看源码可以看出每个请求都会调用一个stress命令来模拟I/O压力。 之前top显示的结果是CPU使用率升高，是否真的是由该stress命令导致的，还需要继续分析。 代码中给每个请求加了verbose=1的参数后可以查看stress命令的输出，在中断测试该命令结果显示stress命令运行时存在因权限问题导致的文件创建失败的bug。</p>
<p>此时依旧只是猜测，下一步继续通过perf工具来分析。性能报告显示确实时stress占用了大量的CPU，通过修复权限问题来优化解决即可。</p>
<h3 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a>总结</h3><p><strong>对于常规问题无法解释的CPU使用率场景，首先要想到可能时短时应用导致的问题。对于短时进程，还可以用execsnoop工具来进行监控。</strong></p>
<hr>
<h2 id="Lesson-7-8-系统中出现大量不可中断进程和僵尸进程怎么办？"><a href="#Lesson-7-8-系统中出现大量不可中断进程和僵尸进程怎么办？" class="headerlink" title="Lesson 7/8 系统中出现大量不可中断进程和僵尸进程怎么办？"></a>Lesson 7/8 系统中出现大量不可中断进程和僵尸进程怎么办？</h2><h3 id="进程状态"><a href="#进程状态" class="headerlink" title="进程状态"></a>进程状态</h3><ul>
<li>R Running/Runnable，表示进程在CPU的就绪队列中，正在运行或者等待运行；</li>
<li>D Disk Sleep，不可中断状态睡眠，一般表示进程正在跟硬件交互，并且交互过程中不允许被其他进程中断；</li>
<li>Z Zombie，僵尸进程，表示进程实际上已经结束，但是父进程还没有回收它的资源；</li>
<li>S Interruptible Sleep，可中断睡眠状态，表示进程因为等待某个事件而被系统挂起，当等待事件发生则会被唤醒并进入R状态；</li>
<li>I Idle，空闲状态，用在不可中断睡眠的内核线程上。 该状态不会导致平均负载升高；</li>
<li>T Stop/Traced，表示进程处于暂停或跟踪状态（SIGSTOP/SIGCONT， GDB调试）；</li>
<li>X Dead，进程已经消亡，不会在top/ps中看到。</li>
</ul>
<p>对于不可中断状态，一般都是在很短时间内结束，可忽略。但是如果系统或硬件发生故障，进程可能会保持不可中断状态很久，甚至系统中出现大量不可中断状态，此时需注意是否出现了I/O性能问题。</p>
<p>僵尸进程一般多进程应用容易遇到，父进程来不及处理子进程状态时子进程就提前退出，此时子进程就变成了僵尸进程。大量的僵尸进程会用尽PID进程号，导致新进程无法建立。</p>
<h3 id="实验案例分析-1"><a href="#实验案例分析-1" class="headerlink" title="实验案例分析"></a>实验案例分析</h3><h4 id="磁盘O-DIRECT问题"><a href="#磁盘O-DIRECT问题" class="headerlink" title="磁盘O_DIRECT问题"></a>磁盘O_DIRECT问题</h4><pre><code>sudo docker run --privileged --name=app -itd feisky/app:iowait
ps aux | grep &apos;/app&apos;
</code></pre><p>可以看到此时有多个app进程运行，状态分别时Ss+和D+。其中后面s表示进程是一个会话的领导进程，+号表示前台进程组。</p>
<p>其中<strong>进程组</strong>表示一组相互关联的进程，子进程是父进程所在组的组员。 <strong>会话</strong>指共享同一个控制终端的一个或多个进程组。</p>
<p>用top查看系统资源发现：1）平均负载在逐渐增加，且1分钟内平均负载达到了CPU个数，说明系统可能已经有了性能瓶颈；2）僵尸进程比较多且在不停增加；3）us和sys CPU使用率都不高，iowait却比较高；4）每个进程CPU使用率也不高，但有两个进程处于D状态，可能在等待IO。</p>
<p>分析目前数据可知：iowait过高导致系统平均负载升高，僵尸进程不断增长说明有程序没能正确清理子进程资源。</p>
<p>用dstat来分析，因为它可以同时查看CPU和I/O两种资源的使用情况，便于对比分析。</p>
<pre><code>dstat 1 10    #间隔1秒输出10组数据
</code></pre><p>可以看到当wai（iowait）升高时磁盘请求read都会很大，说明iowait的升高和磁盘的读请求有关。接下来分析到底时哪个进程在读磁盘。</p>
<p>之前top查看的处于D状态的进程号，用pidstat -d -p XXX 展示进程的I/O统计数据。发现处于D状态的进程都没有任何读写操作。 在用pidstat -d 查看所有进程的I/O统计数据，看到app进程在进行磁盘读操作，每秒读取32MB的数据。进程访问磁盘必须使用系统调用处于内核态，接下来重点就是找到app进程的系统调用。</p>
<pre><code>sudo strace -p XXX #对app进程调用进行跟踪
</code></pre><p>报错没有权限，因为已经时root权限了。所以遇到这种情况，首先要检查进程状态是否正常。 ps命令查找该进程已经处于Z状态，即僵尸进程。</p>
<p>这种情况下top pidstat之类的工具无法给出更多的信息，此时像第5篇一样，用perf record -d和perf report进行分析，查看app进程调用栈。</p>
<p>看到app确实在通过系统调用sys_read()读取数据，并且从new_sync_read和blkdev_direct_IO看出进程时进行直接读操作，请求直接从磁盘读，没有通过缓存导致iowait升高。</p>
<p>通过层层分析后，root cause是app内部进行了磁盘的直接I/O。然后定位到具体代码位置进行优化即可。</p>
<h4 id="僵尸进程"><a href="#僵尸进程" class="headerlink" title="僵尸进程"></a>僵尸进程</h4><p>上述优化后iowait显著下降，但是僵尸进程数量仍旧在增加。首先要定位僵尸进程的父进程，通过pstree -aps XXX，打印出该僵尸进程的调用树，发现父进程就是app进程。</p>
<p>查看app代码，看看子进程结束的处理是否正确（是否调用wait()/waitpid(),有没有注册SIGCHILD信号的处理函数等）。</p>
<h3 id="总结-4"><a href="#总结-4" class="headerlink" title="总结"></a>总结</h3><p><strong>碰到iowait升高时，先用dstat pidstat等工具确认是否存在磁盘I/O问题，再找是哪些进程导致I/O，不能用strace直接分析进程调用时可以通过perf工具分析。</strong></p>
<p><strong>对于僵尸问题，用pstree找到父进程，然后看源码检查子进程结束的处理逻辑即可。</strong></p>
<p>——————————————————————————————————————————————————————————————————<br>LastModify：2020-05-31</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Frances Hu" />
          <p class="site-author-name" itemprop="name">Frances Hu</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">29</span>
              <span class="site-state-item-name">Artikel</span>
            </a>
          </div>

          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">Tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Frances Hu</span>
</div>

<div class="powered-by">
  Erstellt mit  <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  

  

  

  

</body>
</html>
